Attaching to fastapi, kafka-producer, kafka-producer2, database, zookeeper, kafka, kafka-ui
[33mfastapi            |[0m INFO:     Started server process [1]
[33mfastapi            |[0m INFO:     Waiting for application startup.
[33mfastapi            |[0m INFO:     Application startup complete.
[33mfastapi            |[0m INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
[33mfastapi            |[0m INFO:     ('172.0.0.1', 53356) - "WebSocket /ws" [accepted]
[33mfastapi            |[0m %5|1706099057.574|REQTMOUT|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out LeaveGroupRequest in flight (after 5004ms, timeout #0): possibly held back by preceeding blocking JoinGroupRequest with timeout in 297067ms
[33mfastapi            |[0m %4|1706099057.574|REQTMOUT|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out 1 in-flight, 0 retry-queued, 0 out-queue, 0 partially-sent requests
[33mfastapi            |[0m %3|1706099057.574|FAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: kafka:9092: 1 request(s) timed out: disconnect (after 5959ms in state UP)
[33mfastapi            |[0m ERROR:    Exception in ASGI application
[33mfastapi            |[0m Traceback (most recent call last):
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 255, in run_asgi
[33mfastapi            |[0m     result = await self.app(self.scope, self.asgi_receive, self.asgi_send)
[33mfastapi            |[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[33mfastapi            |[0m     return await self.app(scope, receive, send)
[33mfastapi            |[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/applications.py", line 1054, in __call__
[33mfastapi            |[0m     await super().__call__(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/applications.py", line 123, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/errors.py", line 151, in __call__
[33mfastapi            |[0m     await self.app(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[33mfastapi            |[0m     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 762, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 782, in app
[33mfastapi            |[0m     await route.handle(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 373, in handle
[33mfastapi            |[0m     await self.app(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 96, in app
[33mfastapi            |[0m     await wrap_app_handling_exceptions(app, session)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 94, in app
[33mfastapi            |[0m     await func(session)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/routing.py", line 360, in app
[33mfastapi            |[0m     await dependant.call(**values)
[33mfastapi            |[0m   File "/app/main.py", line 158, in pasweb
[33mfastapi            |[0m     cursor.execute("SELECT id, timestamp, x, y FROM coordinates ORDER BY ASC timestamp LIMIT 2")
[33mfastapi            |[0m psycopg2.errors.SyntaxError: syntax error at or near "ASC"
[33mfastapi            |[0m LINE 1: ...ECT id, timestamp, x, y FROM coordinates ORDER BY ASC timest...
[33mfastapi            |[0m                                                              ^
[33mfastapi            |[0m 
[33mfastapi            |[0m INFO:     connection open
[33mfastapi            |[0m INFO:     connection closed
[33mfastapi            |[0m INFO:     ('172.0.0.1', 40070) - "WebSocket /ws" [accepted]
[33mfastapi            |[0m %5|1706099073.577|REQTMOUT|rdkafka#consumer-2| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out LeaveGroupRequest in flight (after 5005ms, timeout #0): possibly held back by preceeding blocking JoinGroupRequest with timeout in 297010ms
[33mfastapi            |[0m %4|1706099073.577|REQTMOUT|rdkafka#consumer-2| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out 1 in-flight, 0 retry-queued, 0 out-queue, 0 partially-sent requests
[33mfastapi            |[0m %3|1706099073.577|FAIL|rdkafka#consumer-2| [thrd:GroupCoordinator]: GroupCoordinator: 1 request(s) timed out: disconnect (after 5996ms in state UP)
[33mfastapi            |[0m ERROR:    Exception in ASGI application
[33mfastapi            |[0m Traceback (most recent call last):
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 255, in run_asgi
[33mfastapi            |[0m     result = await self.app(self.scope, self.asgi_receive, self.asgi_send)
[33mfastapi            |[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[33mfastapi            |[0m     return await self.app(scope, receive, send)
[33mfastapi            |[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/applications.py", line 1054, in __call__
[33mfastapi            |[0m     await super().__call__(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/applications.py", line 123, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/errors.py", line 151, in __call__
[33mfastapi            |[0m     await self.app(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[33mfastapi            |[0m     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 762, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 782, in app
[33mfastapi            |[0m     await route.handle(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 373, in handle
[33mfastapi            |[0m     await self.app(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 96, in app
[33mfastapi            |[0m     await wrap_app_handling_exceptions(app, session)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 94, in app
[33mfastapi            |[0m     await func(session)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/routing.py", line 360, in app
[33mfastapi            |[0m     await dependant.call(**values)
[33mfastapi            |[0m   File "/app/main.py", line 158, in pasweb
[33mfastapi            |[0m     cursor.execute("SELECT id, timestamp, x, y FROM coordinates ORDER BY ASC timestamp LIMIT 2")
[33mfastapi            |[0m psycopg2.errors.SyntaxError: syntax error at or near "ASC"
[33mfastapi            |[0m LINE 1: ...ECT id, timestamp, x, y FROM coordinates ORDER BY ASC timest...
[33mfastapi            |[0m                                                              ^
[33mfastapi            |[0m 
[33mfastapi            |[0m INFO:     connection open
[33mfastapi            |[0m INFO:     connection closed
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 10:28:31,263] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 10:28:31,596] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 10:28:31,699] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 10:28:31,703] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:28:31,703] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:28:31,726] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,732] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,733] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,733] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,733] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,733] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,735] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:28:31,740] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 10:28:31,747] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:28:31,752] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:28:31,756] INFO Opening socket connection to server zookeeper/172.0.0.5:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:28:31,760] INFO Socket connection established, initiating session, client: /172.0.0.2:44822, server: zookeeper/172.0.0.5:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:28:31,779] INFO Session establishment complete on server zookeeper/172.0.0.5:2181, sessionid = 0x10000a29b160000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:28:31,781] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:28:31,875] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:28:31,886] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[32mkafka              |[0m [2024-01-24 10:28:31,886] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 10:28:32,041] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:28:32,044] WARN No meta.properties file under dir /kafka/kafka-logs-bc369d30dc03/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[32mkafka              |[0m [2024-01-24 10:28:32,093] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[35mkafka-producer     |[0m %3|1706092110.603|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 1ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706092111.602|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706092458.729|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 1ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706092459.727|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %6|1706092465.016|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 2287ms in state APIVERSION_QUERY)
[35mkafka-producer     |[0m %3|1706092465.790|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 62ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706092489.809|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 80ms in state CONNECT, 12 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706092519.850|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 120ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706092674.691|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 1ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706092675.691|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706092933.687|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 3ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706092934.686|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %6|1706092939.650|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 2964ms in state APIVERSION_QUERY)
[35mkafka-producer     |[0m %3|1706092940.731|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 45ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706092964.733|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 44ms in state CONNECT, 12 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706092994.851|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 161ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093026.750|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 59ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093056.771|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 80ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093086.774|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 81ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093116.777|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 83ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093148.773|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 78ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093180.767|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 71ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093210.780|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 83ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093240.800|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 102ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093272.756|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 51ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093302.971|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 271ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093334.783|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 82ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093366.779|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 77ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706093427.936|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 14ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706093428.919|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094066.112|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 2ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094067.107|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:28:32,101] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[35mkafka-producer     |[0m %6|1706094073.360|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 3250ms in state APIVERSION_QUERY)
[35mkafka-producer     |[0m %3|1706094074.231|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 124ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094098.261|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 152ms in state CONNECT, 12 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094130.230|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 121ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094160.274|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 164ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094192.240|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 128ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094224.347|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 235ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094256.258|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 144ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094262.114|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094323.249|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 7ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094324.241|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %6|1706094328.291|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 2049ms in state APIVERSION_QUERY)
[35mkafka-producer     |[0m %3|1706094329.251|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 10ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094347.195|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 2ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094348.197|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094700.764|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 2ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094701.761|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %6|1706094706.975|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 3213ms in state APIVERSION_QUERY)
[35mkafka-producer     |[0m %3|1706094707.819|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 58ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706094731.892|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 129ms in state CONNECT, 12 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094763.811|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 48ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094793.819|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 53ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094825.811|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 42ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094855.827|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 58ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094885.829|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 58ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094917.839|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 67ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094949.829|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 56ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706094981.820|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 45ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706095011.840|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 64ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706095043.839|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 62ms in state CONNECT, 16 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706095073.898|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 119ms in state CONNECT, 15 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1706099042.089|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 5ms in state CONNECT)
[35mkafka-producer     |[0m %3|1706099043.083|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 1ms in state CONNECT, 1 identical error(s) suppressed)
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:28:32,146] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,147] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,148] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,150] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,169] INFO Log directory /kafka/kafka-logs-bc369d30dc03 not found, creating it. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:28:32,194] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:28:32,199] INFO Attempting recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:28:32,227] INFO Loaded 0 logs in 33ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:28:32,227] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:28:32,230] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:28:32,681] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:28:32,685] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:28:32,735] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:28:32,736] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:28:32,736] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:28:32,746] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:28:32,774] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:28:32,790] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,791] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,792] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,792] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,817] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:28:32,845] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:28:32,862] INFO Stat of the created znode at /brokers/ids/1001 is: 26,26,1706092112856,1706092112856,1,0,0,72058292424540160,237,0,26
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:28:32,863] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 26 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:28:32,922] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,929] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,930] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:32,931] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:28:32,946] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[32mkafka              |[0m [2024-01-24 10:28:32,947] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:28:32,951] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:28:32,976] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 10:28:32,977] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-24 10:28:32,978] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 10:28:32,981] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-24 10:28:32,982] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 10:28:33,012] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:28:33,034] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-24 10:28:33,054] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:28:33,061] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:28:33,063] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:28:33,063] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:28:33,071] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:28:33,073] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:28:33,073] INFO Kafka startTimeMs: 1706092113064 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:28:33,075] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:28:33,190] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:28:33,620] INFO Creating topic coordinates with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[32mkafka              |[0m [2024-01-24 10:28:33,696] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(coordinates-0) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:28:33,748] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:28:33,754] INFO Created log for partition coordinates-0 in /kafka/kafka-logs-bc369d30dc03/coordinates-0 with properties {} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:28:33,755] INFO [Partition coordinates-0 broker=1001] No checkpointed highwatermark is found for partition coordinates-0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:28:33,756] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-24 10:29:43,240] INFO Unable to read additional data from server sessionid 0x10000a29b160000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:29:44,479] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:45,218] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:46,319] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:46,808] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:47,908] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:48,414] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:49,515] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:49,901] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:51,002] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:51,075] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:52,176] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:52,973] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:54,074] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:55,059] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:56,293] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:56,664] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:57,767] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:29:58,762] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:29:59,863] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:30:00,049] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:30:01,149] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:30:01,298] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:30:02,399] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[36mdatabase           |[0m The files belonging to this database system will be owned by user "postgres".
[36mdatabase           |[0m This user must also own the server process.
[36mdatabase           |[0m 
[36mdatabase           |[0m The database cluster will be initialized with locale "en_US.utf8".
[36mdatabase           |[0m The default database encoding has accordingly been set to "UTF8".
[36mdatabase           |[0m The default text search configuration will be set to "english".
[36mdatabase           |[0m 
[36mdatabase           |[0m Data page checksums are disabled.
[36mdatabase           |[0m 
[36mdatabase           |[0m fixing permissions on existing directory /var/lib/postgresql/data ... ok
[36mdatabase           |[0m creating subdirectories ... ok
[36mdatabase           |[0m selecting dynamic shared memory implementation ... posix
[36mdatabase           |[0m selecting default max_connections ... 100
[36mdatabase           |[0m selecting default shared_buffers ... 128MB
[36mdatabase           |[0m selecting default time zone ... Etc/UTC
[36mdatabase           |[0m creating configuration files ... ok
[36mdatabase           |[0m running bootstrap script ... ok
[36mdatabase           |[0m performing post-bootstrap initialization ... ok
[36mdatabase           |[0m syncing data to disk ... ok
[36mdatabase           |[0m 
[36mdatabase           |[0m 
[36mdatabase           |[0m initdb: warning: enabling "trust" authentication for local connections
[36mdatabase           |[0m Success. You can now start the database server using:
[36mdatabase           |[0m 
[36mdatabase           |[0m initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
[36mdatabase           |[0m     pg_ctl -D /var/lib/postgresql/data -l logfile start
[36mdatabase           |[0m 
[36mdatabase           |[0m waiting for server to start....2024-01-24 10:29:58.226 UTC [47] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 10:29:58.227 UTC [47] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 10:29:58.230 UTC [50] LOG:  database system was shut down at 2024-01-24 10:29:58 UTC
[36mdatabase           |[0m 2024-01-24 10:29:58.235 UTC [47] LOG:  database system is ready to accept connections
[36mdatabase           |[0m  done
[36mdatabase           |[0m server started
[36mdatabase           |[0m CREATE DATABASE
[36mdatabase           |[0m 
[36mdatabase           |[0m 
[36mdatabase           |[0m /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init.sql
[36mdatabase           |[0m You are now connected to database "pg" as user "pg".
[36mdatabase           |[0m CREATE TABLE
[36mdatabase           |[0m 
[36mdatabase           |[0m 
[36mdatabase           |[0m waiting for server to shut down...2024-01-24 10:29:58.445 UTC [47] LOG:  received fast shutdown request
[36mdatabase           |[0m .2024-01-24 10:29:58.446 UTC [47] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 10:29:58.448 UTC [47] LOG:  background worker "logical replication launcher" (PID 53) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 10:29:58.448 UTC [48] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 10:29:58.448 UTC [48] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 10:29:58.478 UTC [48] LOG:  checkpoint complete: wrote 923 buffers (5.6%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.014 s, sync=0.014 s, total=0.030 s; sync files=302, longest=0.001 s, average=0.001 s; distance=4262 kB, estimate=4262 kB; lsn=0/1914480, redo lsn=0/1914480
[36mdatabase           |[0m 2024-01-24 10:29:58.483 UTC [47] LOG:  database system is shut down
[36mdatabase           |[0m  done
[36mdatabase           |[0m server stopped
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL init process complete; ready for start up.
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 10:29:58.561 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 10:29:58.561 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 10:29:58.561 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 10:29:58.563 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 10:29:58.566 UTC [66] LOG:  database system was shut down at 2024-01-24 10:29:58 UTC
[36mdatabase           |[0m 2024-01-24 10:29:58.570 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 10:32:15.713 UTC [1] LOG:  server process (PID 458) exited with exit code 15
[36mdatabase           |[0m 2024-01-24 10:32:15.713 UTC [1] LOG:  terminating any other active server processes
[36mdatabase           |[0m 2024-01-24 10:32:15.715 UTC [1] LOG:  all server processes terminated; reinitializing
[36mdatabase           |[0m 2024-01-24 10:32:15.733 UTC [504] LOG:  database system was interrupted; last known up at 2024-01-24 10:29:58 UTC
[36mdatabase           |[0m 2024-01-24 10:32:15.791 UTC [504] LOG:  database system was not properly shut down; automatic recovery in progress
[36mdatabase           |[0m 2024-01-24 10:32:15.792 UTC [504] LOG:  redo starts at 0/19144F8
[36mdatabase           |[0m 2024-01-24 10:32:15.793 UTC [504] LOG:  invalid record length at 0/1966C58: expected at least 24, got 0
[36mdatabase           |[0m 2024-01-24 10:32:15.793 UTC [504] LOG:  redo done at 0/1966C30 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s
[36mdatabase           |[0m 2024-01-24 10:32:15.797 UTC [505] LOG:  checkpoint starting: end-of-recovery immediate wait
[36mdatabase           |[0m 2024-01-24 10:32:15.804 UTC [505] LOG:  checkpoint complete: wrote 51 buffers (0.3%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.003 s, sync=0.002 s, total=0.008 s; sync files=18, longest=0.001 s, average=0.001 s; distance=329 kB, estimate=329 kB; lsn=0/1966C58, redo lsn=0/1966C58
[36mdatabase           |[0m 2024-01-24 10:32:15.806 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 10:32:59.769 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 10:32:59.770 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 10:32:59.772 UTC [1] LOG:  background worker "logical replication launcher" (PID 509) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 10:32:59.772 UTC [505] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 10:32:59.773 UTC [505] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 10:32:59.776 UTC [505] LOG:  checkpoint complete: wrote 4 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.005 s; sync files=3, longest=0.001 s, average=0.001 s; distance=15 kB, estimate=298 kB; lsn=0/196AB38, redo lsn=0/196AB38
[36mdatabase           |[0m 2024-01-24 10:32:59.782 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 10:34:18.451 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 10:34:18.452 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 10:34:18.452 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 10:34:18.453 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 10:34:18.459 UTC [28] LOG:  database system was shut down at 2024-01-24 10:32:59 UTC
[36mdatabase           |[0m 2024-01-24 10:34:18.463 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 10:35:12.591 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 10:35:12.592 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 10:35:12.593 UTC [1] LOG:  background worker "logical replication launcher" (PID 31) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 10:35:12.595 UTC [26] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 10:35:12.595 UTC [26] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 10:35:12.603 UTC [26] LOG:  checkpoint complete: wrote 11 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.003 s, sync=0.002 s, total=0.008 s; sync files=5, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/196ABE8, redo lsn=0/196ABE8
[36;1mkafka-ui           |[0m 10:28:30,967 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 10:28:31,014 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 10:28:31,015 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 10:28:31,022 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 10:28:31,714 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 10:28:31,820 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 10:28:31,820 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 10:28:31,855 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 10:28:31,855 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 10:28:31,855 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 10:28:31,856 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 10:28:31,856 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 10:28:31,857 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 10:28:31,857 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 10:28:31,857 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:31,925[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:32,016[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:32,021[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:32,022[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:32,023[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:34,680[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:35,388[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:35,423[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: c545f294-251b-46a9-85ea-591472058b41
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:35,574[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:35,930[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:35,945[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 4.67 seconds (process running for 5.835)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:36,825[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:36,838[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706092116-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[32mkafka              |[0m [2024-01-24 10:30:02,521] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:30:03,621] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:30:03,719] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:30:04,820] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:30:05,729] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:30:05,831] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:30:06,963] INFO Opening socket connection to server zookeeper/172.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:30:06,964] INFO Socket connection established, initiating session, client: /172.0.0.2:56694, server: zookeeper/172.0.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:30:06,983] INFO Session establishment complete on server zookeeper/172.0.0.4:2181, sessionid = 0x10000a29b160000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:30:06,984] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:30:23,431] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1001), 1 -> ArrayBuffer(1001), 2 -> ArrayBuffer(1001), 3 -> ArrayBuffer(1001), 4 -> ArrayBuffer(1001), 5 -> ArrayBuffer(1001), 6 -> ArrayBuffer(1001), 7 -> ArrayBuffer(1001), 8 -> ArrayBuffer(1001), 9 -> ArrayBuffer(1001), 10 -> ArrayBuffer(1001), 11 -> ArrayBuffer(1001), 12 -> ArrayBuffer(1001), 13 -> ArrayBuffer(1001), 14 -> ArrayBuffer(1001), 15 -> ArrayBuffer(1001), 16 -> ArrayBuffer(1001), 17 -> ArrayBuffer(1001), 18 -> ArrayBuffer(1001), 19 -> ArrayBuffer(1001), 20 -> ArrayBuffer(1001), 21 -> ArrayBuffer(1001), 22 -> ArrayBuffer(1001), 23 -> ArrayBuffer(1001), 24 -> ArrayBuffer(1001), 25 -> ArrayBuffer(1001), 26 -> ArrayBuffer(1001), 27 -> ArrayBuffer(1001), 28 -> ArrayBuffer(1001), 29 -> ArrayBuffer(1001), 30 -> ArrayBuffer(1001), 31 -> ArrayBuffer(1001), 32 -> ArrayBuffer(1001), 33 -> ArrayBuffer(1001), 34 -> ArrayBuffer(1001), 35 -> ArrayBuffer(1001), 36 -> ArrayBuffer(1001), 37 -> ArrayBuffer(1001), 38 -> ArrayBuffer(1001), 39 -> ArrayBuffer(1001), 40 -> ArrayBuffer(1001), 41 -> ArrayBuffer(1001), 42 -> ArrayBuffer(1001), 43 -> ArrayBuffer(1001), 44 -> ArrayBuffer(1001), 45 -> ArrayBuffer(1001), 46 -> ArrayBuffer(1001), 47 -> ArrayBuffer(1001), 48 -> ArrayBuffer(1001), 49 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[32mkafka              |[0m [2024-01-24 10:30:23,573] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:30:23,580] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,582] INFO Created log for partition __consumer_offsets-3 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[36mdatabase           |[0m 2024-01-24 10:35:12.609 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 10:37:54.295 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 10:37:54.336 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 10:37:54.336 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 10:37:54.338 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 10:37:54.343 UTC [29] LOG:  database system was shut down at 2024-01-24 10:35:12 UTC
[36mdatabase           |[0m 2024-01-24 10:37:54.350 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 10:38:47.382 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 10:38:47.384 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 10:38:47.386 UTC [1] LOG:  background worker "logical replication launcher" (PID 32) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 10:38:47.386 UTC [27] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 10:38:47.387 UTC [27] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 10:38:47.396 UTC [27] LOG:  checkpoint complete: wrote 4 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.002 s, total=0.010 s; sync files=3, longest=0.001 s, average=0.001 s; distance=15 kB, estimate=15 kB; lsn=0/196E9E0, redo lsn=0/196E9E0
[36mdatabase           |[0m 2024-01-24 10:38:47.402 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 10:42:13.076 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 10:42:13.087 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 10:42:13.087 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 10:42:13.088 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 10:42:13.091 UTC [27] LOG:  database system was shut down at 2024-01-24 10:38:47 UTC
[36mdatabase           |[0m 2024-01-24 10:42:13.094 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 10:43:37.020 UTC [1] LOG:  server process (PID 40) exited with exit code 15
[36mdatabase           |[0m 2024-01-24 10:43:37.026 UTC [1] LOG:  terminating any other active server processes
[36mdatabase           |[0m 2024-01-24 10:43:37.028 UTC [1] LOG:  all server processes terminated; reinitializing
[36mdatabase           |[0m 2024-01-24 10:43:37.043 UTC [71] LOG:  database system was interrupted; last known up at 2024-01-24 10:42:13 UTC
[36mdatabase           |[0m 2024-01-24 10:43:37.099 UTC [71] LOG:  database system was not properly shut down; automatic recovery in progress
[36mdatabase           |[0m 2024-01-24 10:43:37.101 UTC [71] LOG:  redo starts at 0/196EA58
[36mdatabase           |[0m 2024-01-24 10:43:37.101 UTC [71] LOG:  invalid record length at 0/1971648: expected at least 24, got 0
[36mdatabase           |[0m 2024-01-24 10:43:37.101 UTC [71] LOG:  redo done at 0/1971610 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s
[36mdatabase           |[0m 2024-01-24 10:43:37.103 UTC [72] LOG:  checkpoint starting: end-of-recovery immediate wait
[36mdatabase           |[0m 2024-01-24 10:43:37.108 UTC [72] LOG:  checkpoint complete: wrote 6 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.002 s, total=0.006 s; sync files=4, longest=0.001 s, average=0.001 s; distance=11 kB, estimate=11 kB; lsn=0/1971648, redo lsn=0/1971648
[36mdatabase           |[0m 2024-01-24 10:43:37.110 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 10:49:38.945 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 10:49:38.946 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 10:49:38.951 UTC [1] LOG:  background worker "logical replication launcher" (PID 76) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 10:49:38.954 UTC [72] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 10:49:38.955 UTC [72] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 10:49:38.961 UTC [72] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.007 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=10 kB; lsn=0/19716F8, redo lsn=0/19716F8
[36mdatabase           |[0m 2024-01-24 10:49:38.969 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 10:50:27.475 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 10:50:27.495 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 10:50:27.495 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 10:50:27.507 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 10:50:27.512 UTC [28] LOG:  database system was shut down at 2024-01-24 10:49:38 UTC
[36mdatabase           |[0m 2024-01-24 10:50:27.519 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 10:55:27.617 UTC [26] LOG:  checkpoint starting: time
[36mdatabase           |[0m 2024-01-24 10:55:29.031 UTC [26] LOG:  checkpoint complete: wrote 18 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=1.407 s, sync=0.002 s, total=1.421 s; sync files=7, longest=0.001 s, average=0.001 s; distance=114 kB, estimate=114 kB; lsn=0/1993FE8, redo lsn=0/198E208
[36mdatabase           |[0m 2024-01-24 10:55:30.831 UTC [1] LOG:  server process (PID 593) exited with exit code 15
[36mdatabase           |[0m 2024-01-24 10:55:30.832 UTC [1] LOG:  terminating any other active server processes
[36mdatabase           |[0m 2024-01-24 10:55:30.835 UTC [1] LOG:  all server processes terminated; reinitializing
[36mdatabase           |[0m 2024-01-24 10:55:30.850 UTC [774] LOG:  database system was interrupted; last known up at 2024-01-24 10:55:29 UTC
[36mdatabase           |[0m 2024-01-24 10:55:30.907 UTC [774] LOG:  database system was not properly shut down; automatic recovery in progress
[36mdatabase           |[0m 2024-01-24 10:55:30.909 UTC [774] LOG:  redo starts at 0/198E208
[36mdatabase           |[0m 2024-01-24 10:55:30.909 UTC [774] LOG:  invalid record length at 0/1994168: expected at least 24, got 0
[36mdatabase           |[0m 2024-01-24 10:55:30.909 UTC [774] LOG:  redo done at 0/1994140 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s
[36mdatabase           |[0m 2024-01-24 10:55:30.910 UTC [775] LOG:  checkpoint starting: end-of-recovery immediate wait
[36mdatabase           |[0m 2024-01-24 10:55:30.916 UTC [775] LOG:  checkpoint complete: wrote 9 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.002 s, total=0.007 s; sync files=6, longest=0.001 s, average=0.001 s; distance=23 kB, estimate=23 kB; lsn=0/1994168, redo lsn=0/1994168
[36mdatabase           |[0m 2024-01-24 10:55:30.920 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 11:00:12.188 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 11:00:12.190 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 11:00:12.194 UTC [1] LOG:  background worker "logical replication launcher" (PID 779) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 11:00:12.196 UTC [775] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 11:00:12.197 UTC [775] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 11:00:12.206 UTC [775] LOG:  checkpoint complete: wrote 11 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.002 s, total=0.010 s; sync files=5, longest=0.001 s, average=0.001 s; distance=99 kB, estimate=99 kB; lsn=0/19AD008, redo lsn=0/19AD008
[32mkafka              |[0m [2024-01-24 10:30:23,582] INFO [Partition __consumer_offsets-3 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,583] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,597] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,598] INFO Created log for partition __consumer_offsets-18 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,598] INFO [Partition __consumer_offsets-18 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,598] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,606] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,607] INFO Created log for partition __consumer_offsets-41 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,607] INFO [Partition __consumer_offsets-41 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,607] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,613] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,614] INFO Created log for partition __consumer_offsets-10 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,614] INFO [Partition __consumer_offsets-10 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,614] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,621] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,622] INFO Created log for partition __consumer_offsets-33 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,622] INFO [Partition __consumer_offsets-33 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,622] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,628] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,629] INFO Created log for partition __consumer_offsets-48 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,630] INFO [Partition __consumer_offsets-48 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,630] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,637] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,638] INFO Created log for partition __consumer_offsets-19 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,638] INFO [Partition __consumer_offsets-19 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,638] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,642] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,643] INFO Created log for partition __consumer_offsets-34 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,644] INFO [Partition __consumer_offsets-34 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,644] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,650] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,650] INFO Created log for partition __consumer_offsets-4 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,650] INFO [Partition __consumer_offsets-4 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,650] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,661] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,662] INFO Created log for partition __consumer_offsets-11 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,662] INFO [Partition __consumer_offsets-11 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,662] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,671] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,672] INFO Created log for partition __consumer_offsets-26 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,672] INFO [Partition __consumer_offsets-26 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,672] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,678] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,679] INFO Created log for partition __consumer_offsets-49 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,679] INFO [Partition __consumer_offsets-49 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,679] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,685] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,686] INFO Created log for partition __consumer_offsets-39 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,686] INFO [Partition __consumer_offsets-39 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,686] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,690] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,692] INFO Created log for partition __consumer_offsets-9 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,692] INFO [Partition __consumer_offsets-9 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,693] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,698] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,699] INFO Created log for partition __consumer_offsets-24 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,699] INFO [Partition __consumer_offsets-24 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,699] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,705] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,706] INFO Created log for partition __consumer_offsets-31 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,706] INFO [Partition __consumer_offsets-31 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,706] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,712] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,713] INFO Created log for partition __consumer_offsets-46 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,713] INFO [Partition __consumer_offsets-46 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,713] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,718] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,719] INFO Created log for partition __consumer_offsets-1 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,720] INFO [Partition __consumer_offsets-1 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,720] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,726] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,728] INFO Created log for partition __consumer_offsets-16 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,728] INFO [Partition __consumer_offsets-16 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,728] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,736] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,740] INFO Created log for partition __consumer_offsets-2 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,740] INFO [Partition __consumer_offsets-2 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,740] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,749] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,751] INFO Created log for partition __consumer_offsets-25 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,751] INFO [Partition __consumer_offsets-25 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,751] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,757] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,757] INFO Created log for partition __consumer_offsets-40 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,758] INFO [Partition __consumer_offsets-40 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,758] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,764] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,765] INFO Created log for partition __consumer_offsets-47 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,765] INFO [Partition __consumer_offsets-47 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,765] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,773] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,773] INFO Created log for partition __consumer_offsets-17 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,773] INFO [Partition __consumer_offsets-17 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,774] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,781] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,782] INFO Created log for partition __consumer_offsets-32 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,782] INFO [Partition __consumer_offsets-32 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,782] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,787] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,788] INFO Created log for partition __consumer_offsets-37 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,788] INFO [Partition __consumer_offsets-37 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,788] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,791] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,792] INFO Created log for partition __consumer_offsets-7 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,792] INFO [Partition __consumer_offsets-7 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,793] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,797] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,798] INFO Created log for partition __consumer_offsets-22 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,798] INFO [Partition __consumer_offsets-22 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,798] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,801] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,802] INFO Created log for partition __consumer_offsets-29 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,802] INFO [Partition __consumer_offsets-29 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,802] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,805] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,806] INFO Created log for partition __consumer_offsets-44 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,806] INFO [Partition __consumer_offsets-44 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,806] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,810] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,811] INFO Created log for partition __consumer_offsets-14 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,811] INFO [Partition __consumer_offsets-14 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,811] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,817] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,817] INFO Created log for partition __consumer_offsets-23 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,817] INFO [Partition __consumer_offsets-23 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,817] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,821] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,822] INFO Created log for partition __consumer_offsets-38 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,822] INFO [Partition __consumer_offsets-38 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,822] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,826] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,827] INFO Created log for partition __consumer_offsets-8 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,827] INFO [Partition __consumer_offsets-8 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,827] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,833] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,834] INFO Created log for partition __consumer_offsets-45 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,834] INFO [Partition __consumer_offsets-45 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,834] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,840] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,841] INFO Created log for partition __consumer_offsets-15 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,841] INFO [Partition __consumer_offsets-15 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,841] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,847] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,847] INFO Created log for partition __consumer_offsets-30 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,847] INFO [Partition __consumer_offsets-30 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,847] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,851] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,852] INFO Created log for partition __consumer_offsets-0 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,852] INFO [Partition __consumer_offsets-0 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,852] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,856] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,857] INFO Created log for partition __consumer_offsets-35 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,857] INFO [Partition __consumer_offsets-35 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,858] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:36,929[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:36,929[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:36,929[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1706092116927
[36;1mkafka-ui           |[0m [30m2024-01-24 10:28:37,596[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:05,944[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:05,988[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:33,228[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092116-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.admin.client for kafka-ui-admin-1706092116-1 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:33,234[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092116-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:33,234[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092116-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:33,234[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092116-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m 10:29:57,937 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 10:29:57,973 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 10:29:57,974 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 10:29:57,981 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 10:29:58,642 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 10:29:58,743 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 10:29:58,743 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 10:29:58,778 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 10:29:58,778 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 10:29:58,778 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 10:29:58,778 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 10:29:58,778 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 10:29:58,779 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 10:29:58,779 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 10:29:58,779 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:58,840[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:58,947[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:58,953[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:58,953[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 10:29:58,954[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:01,531[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:02,446[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:02,500[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: b8e47e69-f0cb-4de7-add2-65a77ac2a8ce
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:02,657[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:03,075[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:03,100[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 4.878 seconds (process running for 5.963)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:04,091[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:04,105[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706092204-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36mdatabase           |[0m 2024-01-24 11:00:12.211 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 11:01:05.794 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 11:01:05.795 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 11:01:05.795 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 11:01:05.797 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 11:01:05.802 UTC [29] LOG:  database system was shut down at 2024-01-24 11:00:12 UTC
[36mdatabase           |[0m 2024-01-24 11:01:05.809 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 11:04:08.747 UTC [1] LOG:  server process (PID 88) exited with exit code 15
[36mdatabase           |[0m 2024-01-24 11:04:08.747 UTC [1] LOG:  terminating any other active server processes
[36mdatabase           |[0m 2024-01-24 11:04:08.750 UTC [114] LOG:  could not send data to client: Broken pipe
[36mdatabase           |[0m 2024-01-24 11:04:08.751 UTC [1] LOG:  all server processes terminated; reinitializing
[36mdatabase           |[0m 2024-01-24 11:04:08.768 UTC [141] LOG:  database system was interrupted; last known up at 2024-01-24 11:01:05 UTC
[36mdatabase           |[0m 2024-01-24 11:04:08.823 UTC [141] LOG:  database system was not properly shut down; automatic recovery in progress
[36mdatabase           |[0m 2024-01-24 11:04:08.824 UTC [141] LOG:  redo starts at 0/19AD080
[36mdatabase           |[0m 2024-01-24 11:04:08.824 UTC [141] LOG:  invalid record length at 0/19AD0B8: expected at least 24, got 0
[36mdatabase           |[0m 2024-01-24 11:04:08.824 UTC [141] LOG:  redo done at 0/19AD080 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s
[36mdatabase           |[0m 2024-01-24 11:04:08.826 UTC [142] LOG:  checkpoint starting: end-of-recovery immediate wait
[36mdatabase           |[0m 2024-01-24 11:04:08.830 UTC [142] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.001 s, total=0.005 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/19AD0B8, redo lsn=0/19AD0B8
[36mdatabase           |[0m 2024-01-24 11:04:08.833 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 11:04:52.037 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 11:04:52.038 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 11:04:52.040 UTC [1] LOG:  background worker "logical replication launcher" (PID 146) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 11:04:52.041 UTC [142] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 11:04:52.042 UTC [142] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 11:04:52.045 UTC [142] LOG:  checkpoint complete: wrote 6 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.005 s; sync files=3, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/19AD168, redo lsn=0/19AD168
[36mdatabase           |[0m 2024-01-24 11:04:52.051 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 11:05:22.597 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 11:05:22.635 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 11:05:22.635 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 11:05:22.636 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 11:05:22.639 UTC [28] LOG:  database system was shut down at 2024-01-24 11:04:52 UTC
[36mdatabase           |[0m 2024-01-24 11:05:22.642 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 11:05:33.248 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 11:05:33.249 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 11:05:33.253 UTC [1] LOG:  background worker "logical replication launcher" (PID 31) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 11:05:33.254 UTC [26] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 11:05:33.255 UTC [26] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 11:05:33.261 UTC [26] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.003 s, sync=0.001 s, total=0.007 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/19AD1E0, redo lsn=0/19AD1E0
[36mdatabase           |[0m 2024-01-24 11:05:33.264 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 11:05:47.103 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 11:05:47.104 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 11:05:47.104 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 11:05:47.106 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 11:05:47.115 UTC [29] LOG:  database system was shut down at 2024-01-24 11:05:33 UTC
[36mdatabase           |[0m 2024-01-24 11:05:47.121 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 11:10:26.347 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 11:10:26.349 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 11:10:26.353 UTC [1] LOG:  background worker "logical replication launcher" (PID 32) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 11:10:26.354 UTC [27] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 11:10:26.354 UTC [27] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 11:10:26.363 UTC [27] LOG:  checkpoint complete: wrote 14 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.002 s, total=0.010 s; sync files=7, longest=0.001 s, average=0.001 s; distance=97 kB, estimate=97 kB; lsn=0/19C5898, redo lsn=0/19C5898
[36mdatabase           |[0m 2024-01-24 11:10:26.367 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 11:11:40.045 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 11:11:40.087 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 11:11:40.087 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 11:11:40.089 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 11:11:40.094 UTC [28] LOG:  database system was shut down at 2024-01-24 11:10:26 UTC
[36mdatabase           |[0m 2024-01-24 11:11:40.097 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 11:16:40.191 UTC [26] LOG:  checkpoint starting: time
[36mdatabase           |[0m 2024-01-24 11:16:40.812 UTC [26] LOG:  checkpoint complete: wrote 9 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.604 s, sync=0.008 s, total=0.622 s; sync files=5, longest=0.007 s, average=0.002 s; distance=19 kB, estimate=19 kB; lsn=0/19CA628, redo lsn=0/19CA5F0
[36mdatabase           |[0m 2024-01-24 11:17:28.977 UTC [1] LOG:  server process (PID 47) was terminated by signal 15: Terminated
[36mdatabase           |[0m 2024-01-24 11:17:28.978 UTC [1] LOG:  terminating any other active server processes
[36mdatabase           |[0m 2024-01-24 11:17:28.981 UTC [1] LOG:  all server processes terminated; reinitializing
[36mdatabase           |[0m 2024-01-24 11:17:29.014 UTC [222] LOG:  database system was interrupted; last known up at 2024-01-24 11:16:40 UTC
[34mkafka-producer2    |[0m %3|1706092110.573|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 1ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706092111.571|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706092458.670|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 1ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706092459.669|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %6|1706092465.016|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 2344ms in state APIVERSION_QUERY)
[34mkafka-producer2    |[0m %3|1706092465.790|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 120ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706092489.809|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 138ms in state CONNECT, 12 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706092674.624|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 16ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706092675.607|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706092933.616|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706092934.616|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %6|1706092939.650|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 3034ms in state APIVERSION_QUERY)
[34mkafka-producer2    |[0m %3|1706092940.731|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 115ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706092964.733|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 115ms in state CONNECT, 12 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706092996.695|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 76ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093026.749|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 129ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093056.771|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 150ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093086.774|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 151ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093116.777|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 153ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093148.773|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 148ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093180.767|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 140ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093210.780|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 152ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093240.799|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 170ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093272.756|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 119ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093302.971|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 339ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093334.783|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 138ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093366.779|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 133ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706093428.040|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706093429.040|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094066.128|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 8ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094067.119|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %6|1706094073.360|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 3237ms in state APIVERSION_QUERY)
[34mkafka-producer2    |[0m %3|1706094074.231|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 111ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094098.261|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 140ms in state CONNECT, 12 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094130.230|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 108ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094160.274|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 152ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094192.240|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 116ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094224.347|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 222ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094256.258|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 132ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094262.126|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094323.151|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 29ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094324.122|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %6|1706094328.291|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 2168ms in state APIVERSION_QUERY)
[34mkafka-producer2    |[0m %3|1706094329.251|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 128ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094347.415|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094348.414|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094700.683|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094701.683|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.4:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %6|1706094706.975|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 3291ms in state APIVERSION_QUERY)
[34mkafka-producer2    |[0m %3|1706094707.819|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 135ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706094731.759|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 74ms in state CONNECT, 12 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094761.829|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 144ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094791.841|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 154ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094823.811|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 123ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094855.827|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 138ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094885.829|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 139ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094917.839|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 147ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094949.829|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 136ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706094981.820|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 125ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706095011.839|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 143ms in state CONNECT, 15 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706095043.839|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 142ms in state CONNECT, 16 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1706099042.086|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 0ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1706099043.101|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.5:9092 failed: Connection refused (after 2ms in state CONNECT, 1 identical error(s) suppressed)
[36mdatabase           |[0m 2024-01-24 11:17:29.080 UTC [222] LOG:  database system was not properly shut down; automatic recovery in progress
[36mdatabase           |[0m 2024-01-24 11:17:29.082 UTC [222] LOG:  redo starts at 0/19CA5F0
[36mdatabase           |[0m 2024-01-24 11:17:29.082 UTC [222] LOG:  invalid record length at 0/19CA6D8: expected at least 24, got 0
[36mdatabase           |[0m 2024-01-24 11:17:29.082 UTC [222] LOG:  redo done at 0/19CA6A0 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s
[36mdatabase           |[0m 2024-01-24 11:17:29.084 UTC [223] LOG:  checkpoint starting: end-of-recovery immediate wait
[36mdatabase           |[0m 2024-01-24 11:17:29.089 UTC [223] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.001 s, total=0.006 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/19CA6D8, redo lsn=0/19CA6D8
[36mdatabase           |[0m 2024-01-24 11:17:29.092 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 11:17:50.858 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-24 11:17:50.859 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-24 11:17:50.865 UTC [1] LOG:  background worker "logical replication launcher" (PID 227) exited with exit code 1
[36mdatabase           |[0m 2024-01-24 11:17:50.865 UTC [223] LOG:  shutting down
[36mdatabase           |[0m 2024-01-24 11:17:50.866 UTC [223] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-24 11:17:50.868 UTC [223] LOG:  checkpoint complete: wrote 0 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.003 s; sync files=0, longest=0.000 s, average=0.000 s; distance=0 kB, estimate=0 kB; lsn=0/19CA788, redo lsn=0/19CA788
[36mdatabase           |[0m 2024-01-24 11:17:50.871 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-24 12:24:01.111 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-24 12:24:01.127 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-24 12:24:01.127 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-24 12:24:01.129 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-24 12:24:01.133 UTC [29] LOG:  database system was shut down at 2024-01-24 11:17:50 UTC
[36mdatabase           |[0m 2024-01-24 12:24:01.141 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-24 12:24:17.618 UTC [33] ERROR:  syntax error at or near "ASC" at character 54
[36mdatabase           |[0m 2024-01-24 12:24:17.618 UTC [33] STATEMENT:  SELECT id, timestamp, x, y FROM coordinates ORDER BY ASC timestamp LIMIT 2
[36mdatabase           |[0m 2024-01-24 12:24:33.596 UTC [34] ERROR:  syntax error at or near "ASC" at character 54
[36mdatabase           |[0m 2024-01-24 12:24:33.596 UTC [34] STATEMENT:  SELECT id, timestamp, x, y FROM coordinates ORDER BY ASC timestamp LIMIT 2
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:04,185[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:04,185[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:04,185[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1706092204184
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:06,995[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:33,105[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:30:33,134[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:31:03,097[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:31:03,127[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:31:33,097[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:31:33,122[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:03,097[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:03,122[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:33,097[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:33,121[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:49,389[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092204-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.admin.client for kafka-ui-admin-1706092204-1 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:49,396[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092204-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:49,397[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092204-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-24 10:32:49,397[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092204-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m 10:34:19,305 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 10:34:19,363 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 10:34:19,365 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 10:34:19,390 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 10:34:20,245 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 10:34:20,386 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 10:34:20,386 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 10:34:20,419 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 10:34:20,419 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 10:34:20,419 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 10:34:20,420 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 10:34:20,420 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[32mkafka              |[0m [2024-01-24 10:30:23,866] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,866] INFO Created log for partition __consumer_offsets-5 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,866] INFO [Partition __consumer_offsets-5 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,866] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,870] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,871] INFO Created log for partition __consumer_offsets-20 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,871] INFO [Partition __consumer_offsets-20 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,871] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,874] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,875] INFO Created log for partition __consumer_offsets-27 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,876] INFO [Partition __consumer_offsets-27 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,876] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,881] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,882] INFO Created log for partition __consumer_offsets-42 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,882] INFO [Partition __consumer_offsets-42 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,882] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,886] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,887] INFO Created log for partition __consumer_offsets-12 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,887] INFO [Partition __consumer_offsets-12 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,887] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,892] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,893] INFO Created log for partition __consumer_offsets-21 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,893] INFO [Partition __consumer_offsets-21 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,893] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,898] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,898] INFO Created log for partition __consumer_offsets-36 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,898] INFO [Partition __consumer_offsets-36 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,898] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,903] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,903] INFO Created log for partition __consumer_offsets-6 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,903] INFO [Partition __consumer_offsets-6 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,903] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,911] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,912] INFO Created log for partition __consumer_offsets-43 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,912] INFO [Partition __consumer_offsets-43 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,912] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,918] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,918] INFO Created log for partition __consumer_offsets-13 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[36;1mkafka-ui           |[0m 10:34:20,421 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 10:34:20,421 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 10:34:20,421 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:20,490[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:20,583[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:20,588[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:20,589[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:20,589[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:24,972[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:25,768[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:25,808[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 8373cf4d-157a-40e5-8cdb-e20f39c16dd6
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:25,958[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:26,365[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:26,387[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 6.668 seconds (process running for 8.062)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:27,205[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:27,215[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706092467-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:32,254[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:32,265[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[32mkafka              |[0m [2024-01-24 10:30:23,918] INFO [Partition __consumer_offsets-13 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,918] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,926] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:30:23,927] INFO Created log for partition __consumer_offsets-28 in /kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:30:23,927] INFO [Partition __consumer_offsets-28 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,927] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:30:23,931] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,933] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,936] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:32,270[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:56,386[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:34:56,388[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706092496-2
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:35:01,391[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:35:01,392[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,937] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,735 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,748 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,748 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,749 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,749 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,762 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,763 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,770 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,780 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,780 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,781 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,781 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,781 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,781 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,781 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,781 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,783 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,783 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,783 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,783 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,783 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,783 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,783 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,785 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,786 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,786 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,797 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 10:28:30,804 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 10:28:31,761 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.2:44822
[33;1mzookeeper          |[0m 2024-01-24 10:28:31,766 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.2:44822
[33;1mzookeeper          |[0m 2024-01-24 10:28:31,768 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.1
[33;1mzookeeper          |[0m 2024-01-24 10:28:31,777 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000a29b160000 with negotiated timeout 18000 for client /172.0.0.2:44822
[33;1mzookeeper          |[0m 2024-01-24 10:28:31,838 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a29b160000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
[33;1mzookeeper          |[0m 2024-01-24 10:28:31,845 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a29b160000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[33;1mzookeeper          |[0m 2024-01-24 10:28:31,851 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a29b160000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[33;1mzookeeper          |[0m 2024-01-24 10:28:32,036 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a29b160000 type:create cxid:0x18 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[33;1mzookeeper          |[0m 2024-01-24 10:28:33,093 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000a29b160000 type:multi cxid:0x40 zxid:0x1f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-24 10:28:33,627 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a29b160000 type:setData cxid:0x45 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/coordinates Error:KeeperErrorCode = NoNode for /config/topics/coordinates
[33;1mzookeeper          |[0m 2024-01-24 10:28:41,075 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.2:53788
[33;1mzookeeper          |[0m 2024-01-24 10:28:41,077 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.2:53788
[33;1mzookeeper          |[0m 2024-01-24 10:28:41,078 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000a29b160001 with negotiated timeout 30000 for client /172.0.0.2:53788
[33;1mzookeeper          |[0m 2024-01-24 10:28:41,220 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000a29b160001
[33;1mzookeeper          |[0m 2024-01-24 10:28:41,222 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.2:53788 which had sessionid 0x10000a29b160001
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,649 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,654 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,654 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,655 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,655 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,665 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,678 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,678 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,685 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,687 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,687 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,687 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,687 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,687 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,687 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,688 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,690 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,690 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,690 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,697 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 10:29:57,701 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 10:30:06,968 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.2:56694
[33;1mzookeeper          |[0m 2024-01-24 10:30:06,978 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@942] - Client attempting to renew session 0x10000a29b160000 at /172.0.0.2:56694
[33;1mzookeeper          |[0m 2024-01-24 10:30:06,983 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@694] - Established session 0x10000a29b160000 with negotiated timeout 18000 for client /172.0.0.2:56694
[33;1mzookeeper          |[0m 2024-01-24 10:30:23,435 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a29b160000 type:setData cxid:0x54 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
[33;1mzookeeper          |[0m 2024-01-24 10:30:23,436 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.28
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,920 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,926 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,926 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,927 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,927 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,937 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,941 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,941 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,950 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,950 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,950 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,951 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,951 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,951 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:23,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,944] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,945] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:23,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:30:25,491] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member rdkafka-25c8d075-d354-4891-8ab9-6c285035751e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:25,497] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 1 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:30:25,503] INFO [GroupCoordinator 1001]: Assignment received from leader for group web_consumer_group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:32:59,387] INFO Unable to read additional data from server sessionid 0x10000a29b160000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:33:00,611] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:00,613] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:01,714] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:02,350] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:03,451] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:04,158] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,951 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,951 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,952 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,952 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,952 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,952 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,952 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,952 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,952 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,954 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,954 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,954 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,964 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 10:34:18,971 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,200 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.3:55274
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,206 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.3:55274
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,206 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.90
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,210 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000a7eb530000 with negotiated timeout 18000 for client /172.0.0.3:55274
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,276 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x1 zxid:0x91 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,289 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x2 zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,293 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x3 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,295 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x4 zxid:0x94 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,300 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x5 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,302 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x6 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,306 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x7 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,308 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x8 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,313 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0x9 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,318 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0xa zxid:0x9a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,320 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0xb zxid:0x9b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,322 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0xc zxid:0x9c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,324 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0xd zxid:0x9d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 10:34:20,326 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:create cxid:0xe zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 10:34:22,652 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000a7eb530000 type:multi cxid:0x19 zxid:0x9f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/1001 Error:KeeperErrorCode = NodeExists for /brokers/ids/1001
[33;1mzookeeper          |[0m 2024-01-24 10:34:23,396 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000a7eb530000
[33;1mzookeeper          |[0m 2024-01-24 10:34:23,400 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.3:55274 which had sessionid 0x10000a7eb530000
[33;1mzookeeper          |[0m 2024-01-24 10:34:38,280 [myid:] - INFO  [SessionTracker:ZooKeeperServer@355] - Expiring session 0x10000a29b160000, timeout of 18000ms exceeded
[33;1mzookeeper          |[0m 2024-01-24 10:34:38,280 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000a29b160000
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:05,259] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:06,056] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:07,157] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:07,382] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:08,482] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:09,129] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:09,977] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 10:33:09,981] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:33:09,981] INFO [KafkaServer id=1001] Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:33:10,231] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:10,865] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:10,966] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:33:12,098] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,656 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,660 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,661 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,661 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,662 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,672 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,673 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,676 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,682 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,682 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,682 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,682 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,682 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,683 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,683 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,683 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,685 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,685 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,685 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,685 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,685 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,685 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,685 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,713 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,713 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,713 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,725 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 10:37:54,730 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,670 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.2:34666
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,675 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.2:34666
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,676 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.a2
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,681 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000ab36280000 with negotiated timeout 18000 for client /172.0.0.2:34666
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,729 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x1 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,737 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x2 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,739 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x3 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,741 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x4 zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,742 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x5 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,744 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x6 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,745 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x7 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,747 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x8 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,748 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0x9 zxid:0xab txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,750 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0xa zxid:0xac txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,752 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0xb zxid:0xad txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,753 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0xc zxid:0xae txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,754 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0xd zxid:0xaf txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 10:37:55,756 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:create cxid:0xe zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 10:37:57,788 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000ab36280000 type:multi cxid:0x6b zxid:0xb4 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-24 10:38:05,010 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.2:34676
[33;1mzookeeper          |[0m 2024-01-24 10:38:05,012 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.2:34676
[33;1mzookeeper          |[0m 2024-01-24 10:38:05,013 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000ab36280001 with negotiated timeout 30000 for client /172.0.0.2:34676
[33;1mzookeeper          |[0m 2024-01-24 10:38:05,190 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000ab36280001
[33;1mzookeeper          |[0m 2024-01-24 10:38:05,193 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.2:34676 which had sessionid 0x10000ab36280001
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,428 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,432 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,432 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,433 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,433 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,442 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,444 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,446 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,454 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,454 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,454 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,455 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,455 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,455 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,455 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,455 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,457 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,457 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,457 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,457 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,457 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,457 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,457 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,459 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,460 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,460 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,471 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 10:42:13,475 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,879 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.2:54632
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,882 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.2:54632
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,882 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.b7
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,888 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000af28c10000 with negotiated timeout 18000 for client /172.0.0.2:54632
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,948 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x1 zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,958 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x2 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,959 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x3 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,961 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x4 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,962 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x5 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,964 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x6 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,965 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x7 zxid:0xbe txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,966 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x8 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,967 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0x9 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,968 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0xa zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,970 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0xb zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,971 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0xc zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,972 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0xd zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 10:42:14,973 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:create cxid:0xe zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 10:42:16,566 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000af28c10000 type:multi cxid:0x19 zxid:0xc6 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/1001 Error:KeeperErrorCode = NodeExists for /brokers/ids/1001
[33;1mzookeeper          |[0m 2024-01-24 10:42:17,285 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000af28c10000
[33;1mzookeeper          |[0m 2024-01-24 10:42:17,287 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.2:54632 which had sessionid 0x10000af28c10000
[33;1mzookeeper          |[0m 2024-01-24 10:42:32,280 [myid:] - INFO  [SessionTracker:ZooKeeperServer@355] - Expiring session 0x10000ab36280000, timeout of 18000ms exceeded
[33;1mzookeeper          |[0m 2024-01-24 10:42:32,281 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000ab36280000
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,753 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,759 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,760 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,761 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,767 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,772 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,773 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,774 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,778 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,778 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,778 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,778 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,779 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,779 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,779 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,779 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,780 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:12,790] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:13,891] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:14,107] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:15,208] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:15,370] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:16,471] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:16,907] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:18,008] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:33:18,684] WARN Session 0x10000a29b160000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:33:19,785] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 10:34:19,558] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 10:34:19,985] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 10:34:20,123] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 10:34:20,126] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:34:20,126] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:34:20,161] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:34:20,168] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,168] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:35:01,393[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m 10:37:55,115 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 10:37:55,180 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 10:37:55,181 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 10:37:55,192 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 10:37:56,025 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 10:37:56,180 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 10:37:56,180 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 10:37:56,230 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 10:37:56,230 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 10:37:56,230 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 10:37:56,231 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 10:37:56,231 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 10:37:56,233 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 10:37:56,233 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 10:37:56,233 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:37:56,315[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 10:37:56,429[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 10:37:56,438[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:37:56,438[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 10:37:56,440[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:00,111[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:01,356[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:01,459[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 1e23eaa4-e16b-4cc4-87d1-73f6b925e14f
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:01,925[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:02,415[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:02,434[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 6.974 seconds (process running for 7.997)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:03,316[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:03,328[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706092683-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,781 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,781 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,781 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,781 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,781 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,781 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,782 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,783 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,783 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,790 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 10:50:27,794 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,172 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.3:56600
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,185 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.3:56600
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,186 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.c9
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,190 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000b6b3b90000 with negotiated timeout 18000 for client /172.0.0.3:56600
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,266 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x1 zxid:0xca txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,276 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x2 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,278 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x3 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,282 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x4 zxid:0xcd txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,285 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x5 zxid:0xce txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,289 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x6 zxid:0xcf txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,291 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x7 zxid:0xd0 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,294 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x8 zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,296 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0x9 zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,299 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0xa zxid:0xd3 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,303 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0xb zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,308 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0xc zxid:0xd5 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,310 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0xd zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 10:50:29,314 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:create cxid:0xe zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 10:50:31,562 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000b6b3b90000 type:multi cxid:0x6b zxid:0xdb txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-24 10:50:38,433 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.3:36176
[33;1mzookeeper          |[0m 2024-01-24 10:50:38,435 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.3:36176
[33;1mzookeeper          |[0m 2024-01-24 10:50:38,436 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000b6b3b90001 with negotiated timeout 30000 for client /172.0.0.3:36176
[33;1mzookeeper          |[0m 2024-01-24 10:50:38,636 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000b6b3b90001
[33;1mzookeeper          |[0m 2024-01-24 10:50:38,637 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.3:36176 which had sessionid 0x10000b6b3b90001
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,320 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,327 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,327 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,328 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,328 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,337 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,340 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,342 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,350 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,351 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,351 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,351 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,351 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,351 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,351 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,351 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,353 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,353 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,353 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,353 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,353 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,353 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,353 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,356 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,356 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,356 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,368 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 11:01:06,374 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,579 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.4:47906
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,584 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.4:47906
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,584 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.de
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,590 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c0723f0000 with negotiated timeout 18000 for client /172.0.0.4:47906
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,645 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x1 zxid:0xdf txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,654 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x2 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,655 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x3 zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,657 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x4 zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,658 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x5 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,660 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x6 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,662 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x7 zxid:0xe5 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,664 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x8 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,668 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0x9 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,670 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0xa zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,673 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0xb zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,675 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0xc zxid:0xea txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,677 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0xd zxid:0xeb txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 11:01:07,679 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:create cxid:0xe zxid:0xec txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 11:01:10,026 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000c0723f0000 type:multi cxid:0x19 zxid:0xed txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/1001 Error:KeeperErrorCode = NodeExists for /brokers/ids/1001
[33;1mzookeeper          |[0m 2024-01-24 11:01:10,936 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c0723f0000
[33;1mzookeeper          |[0m 2024-01-24 11:01:10,942 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.4:47906 which had sessionid 0x10000c0723f0000
[33;1mzookeeper          |[0m 2024-01-24 11:01:26,279 [myid:] - INFO  [SessionTracker:ZooKeeperServer@355] - Expiring session 0x10000b6b3b90000, timeout of 18000ms exceeded
[33;1mzookeeper          |[0m 2024-01-24 11:01:26,280 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000b6b3b90000
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,037 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.4:59690
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,039 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.4:59690
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,046 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c0723f0001 with negotiated timeout 18000 for client /172.0.0.4:59690
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,078 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x1 zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,084 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x2 zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,085 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x3 zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,086 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x4 zxid:0xf4 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,088 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x5 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,089 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x6 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,090 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x7 zxid:0xf7 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,091 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x8 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,092 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0x9 zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,093 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0xa zxid:0xfa txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,094 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0xb zxid:0xfb txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,095 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0xc zxid:0xfc txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,096 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0xd zxid:0xfd txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 11:04:22,097 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:create cxid:0xe zxid:0xfe txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 11:04:23,166 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000c0723f0001 type:multi cxid:0x6b zxid:0x102 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-24 11:04:31,954 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.4:52402
[33;1mzookeeper          |[0m 2024-01-24 11:04:31,956 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.4:52402
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:03,408[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:03,408[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:03,408[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1706092683406
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:03,932[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:32,433[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:32,475[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:36,998[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092683-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.admin.client for kafka-ui-admin-1706092683-1 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:37,002[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092683-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:37,002[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092683-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-24 10:38:37,002[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706092683-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m 10:42:13,938 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 10:42:13,989 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 10:42:13,990 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 10:42:13,996 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 10:42:14,934 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 10:42:15,049 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 10:42:15,049 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 10:42:15,085 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 10:42:15,085 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 10:42:15,085 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 10:42:15,085 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 10:42:15,085 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 10:42:15,086 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 10:42:15,086 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 10:42:15,086 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:15,171[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:15,328[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:15,336[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:15,336[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:15,338[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,169] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,173] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:20,178] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 10:34:20,184] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:34:20,186] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:34:20,194] INFO Opening socket connection to server zookeeper/172.0.0.5:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:34:20,198] INFO Socket connection established, initiating session, client: /172.0.0.3:55274, server: zookeeper/172.0.0.5:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:34:20,212] INFO Session establishment complete on server zookeeper/172.0.0.5:2181, sessionid = 0x10000a7eb530000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:34:20,215] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:34:20,337] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:34:20,499] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 10:34:20,504] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:34:20,556] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:34:20,566] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[33;1mzookeeper          |[0m 2024-01-24 11:04:31,957 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c0723f0002 with negotiated timeout 30000 for client /172.0.0.4:52402
[33;1mzookeeper          |[0m 2024-01-24 11:04:32,109 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c0723f0002
[33;1mzookeeper          |[0m 2024-01-24 11:04:32,110 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.4:52402 which had sessionid 0x10000c0723f0002
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,768 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,773 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,773 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,776 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,776 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,786 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,789 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,789 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,798 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,801 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,801 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,801 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,801 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,801 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,801 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,801 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,802 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,803 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,803 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,803 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,803 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,803 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,803 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,813 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,814 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,814 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,823 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 11:05:22,827 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,530 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.5:52796
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,534 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.5:52796
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,535 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.105
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,540 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c45c0c0000 with negotiated timeout 18000 for client /172.0.0.5:52796
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,577 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x1 zxid:0x106 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,585 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x2 zxid:0x107 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,587 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x3 zxid:0x108 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,588 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x4 zxid:0x109 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,590 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x5 zxid:0x10a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,591 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x6 zxid:0x10b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,593 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x7 zxid:0x10c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,595 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x8 zxid:0x10d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,597 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0x9 zxid:0x10e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,598 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0xa zxid:0x10f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,600 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0xb zxid:0x110 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,602 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0xc zxid:0x111 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,603 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0xd zxid:0x112 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 11:05:24,605 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:create cxid:0xe zxid:0x113 txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 11:05:26,260 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000c45c0c0000 type:multi cxid:0x19 zxid:0x114 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/1001 Error:KeeperErrorCode = NodeExists for /brokers/ids/1001
[33;1mzookeeper          |[0m 2024-01-24 11:05:26,976 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c45c0c0000
[33;1mzookeeper          |[0m 2024-01-24 11:05:26,978 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.5:52796 which had sessionid 0x10000c45c0c0000
[33;1mzookeeper          |[0m 2024-01-24 11:05:42,279 [myid:] - INFO  [SessionTracker:ZooKeeperServer@355] - Expiring session 0x10000c0723f0001, timeout of 18000ms exceeded
[33;1mzookeeper          |[0m 2024-01-24 11:05:42,280 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c0723f0001
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,264 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,271 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,271 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,272 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,275 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,290 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,290 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,291 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,300 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,300 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,300 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,300 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,301 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,301 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,301 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,301 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,302 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,302 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,302 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,302 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,302 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,302 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,302 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,304 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,304 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,304 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,314 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 11:05:47,319 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,580 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.4:45936
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,583 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.4:45936
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,584 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.117
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,596 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c4bbaf0000 with negotiated timeout 18000 for client /172.0.0.4:45936
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,649 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x1 zxid:0x118 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,659 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x2 zxid:0x119 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,661 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x3 zxid:0x11a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,663 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x4 zxid:0x11b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,665 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x5 zxid:0x11c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,667 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x6 zxid:0x11d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,669 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x7 zxid:0x11e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,671 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x8 zxid:0x11f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,673 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0x9 zxid:0x120 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,675 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0xa zxid:0x121 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,677 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0xb zxid:0x122 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,678 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0xc zxid:0x123 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,680 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0xd zxid:0x124 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 11:05:48,682 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:create cxid:0xe zxid:0x125 txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 11:05:50,643 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000c4bbaf0000 type:multi cxid:0x6b zxid:0x129 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-24 11:05:57,630 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.4:60922
[33;1mzookeeper          |[0m 2024-01-24 11:05:57,632 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.4:60922
[33;1mzookeeper          |[0m 2024-01-24 11:05:57,633 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c4bbaf0001 with negotiated timeout 30000 for client /172.0.0.4:60922
[33;1mzookeeper          |[0m 2024-01-24 11:05:57,775 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c4bbaf0001
[33;1mzookeeper          |[0m 2024-01-24 11:05:57,777 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.4:60922 which had sessionid 0x10000c4bbaf0001
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,729 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,734 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,735 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,735 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,735 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,749 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,767 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,768 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,778 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,779 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,779 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,779 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,779 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,780 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,780 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,780 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,783 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,784 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,784 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,784 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,784 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,784 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,784 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,787 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,787 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,787 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,797 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 11:11:40,803 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,148 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.4:43104
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,152 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.4:43104
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,153 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.12c
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,159 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000ca20980000 with negotiated timeout 18000 for client /172.0.0.4:43104
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,196 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x1 zxid:0x12d txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,221 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x2 zxid:0x12e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,223 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x3 zxid:0x12f txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,225 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x4 zxid:0x130 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,226 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x5 zxid:0x131 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,228 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x6 zxid:0x132 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,229 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x7 zxid:0x133 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,231 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x8 zxid:0x134 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,234 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0x9 zxid:0x135 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,236 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0xa zxid:0x136 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,237 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0xb zxid:0x137 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,239 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0xc zxid:0x138 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,240 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0xd zxid:0x139 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 11:11:42,241 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:create cxid:0xe zxid:0x13a txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 11:11:43,964 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000ca20980000 type:multi cxid:0x19 zxid:0x13b txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/1001 Error:KeeperErrorCode = NodeExists for /brokers/ids/1001
[33;1mzookeeper          |[0m 2024-01-24 11:11:44,472 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000ca20980000
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:18,439[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:19,293[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:19,341[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 3ebece5e-60dd-4886-88fb-4cb20bce9b5a
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:19,511[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:20,120[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:20,160[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 5.727 seconds (process running for 7.016)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:21,082[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:21,096[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706092941-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:26,124[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:26,134[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[33;1mzookeeper          |[0m 2024-01-24 11:11:44,474 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.4:43104 which had sessionid 0x10000ca20980000
[33;1mzookeeper          |[0m 2024-01-24 11:12:00,279 [myid:] - INFO  [SessionTracker:ZooKeeperServer@355] - Expiring session 0x10000c4bbaf0000, timeout of 18000ms exceeded
[33;1mzookeeper          |[0m 2024-01-24 11:12:00,281 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c4bbaf0000
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,877 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,884 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,884 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,886 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,886 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,901 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,902 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,904 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,919 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,920 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=0d642accc763
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,921 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,921 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,921 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,921 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,922 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,922 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,923 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,926 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,926 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,926 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,926 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,927 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,927 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,930 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,930 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,930 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,945 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-24 12:24:01,953 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,562 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.5:43444
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,569 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.5:43444
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,570 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.13e
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,574 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100010c5e840000 with negotiated timeout 18000 for client /172.0.0.5:43444
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,628 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x1 zxid:0x13f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,639 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x2 zxid:0x140 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,641 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x3 zxid:0x141 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,642 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x4 zxid:0x142 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,643 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x5 zxid:0x143 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,644 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x6 zxid:0x144 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,645 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x7 zxid:0x145 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,647 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x8 zxid:0x146 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:26,137[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:50,153[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:50,154[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706092970-2
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:55,155[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:55,156[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,650 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0x9 zxid:0x147 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,653 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0xa zxid:0x148 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,654 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0xb zxid:0x149 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,655 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0xc zxid:0x14a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,656 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0xd zxid:0x14b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-24 12:24:04,657 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:create cxid:0xe zxid:0x14c txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-24 12:24:06,599 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x100010c5e840000 type:multi cxid:0x6b zxid:0x150 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-24 12:24:13,175 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.5:45822
[33;1mzookeeper          |[0m 2024-01-24 12:24:13,178 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.5:45822
[33;1mzookeeper          |[0m 2024-01-24 12:24:13,181 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100010c5e840001 with negotiated timeout 30000 for client /172.0.0.5:45822
[33;1mzookeeper          |[0m 2024-01-24 12:24:13,474 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x100010c5e840001
[33;1mzookeeper          |[0m 2024-01-24 12:24:13,476 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.5:45822 which had sessionid 0x100010c5e840001
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:34:20,612] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:20,612] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:20,614] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:20,615] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:20,705] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,709] INFO Attempting recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,781] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,783] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,810] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,816] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 96ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,818] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,818] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,820] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,823] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,825] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,825] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,831] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,835] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,837] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,838] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:42:55,157[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:20,153[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:20,154[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093000-3
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:25,159[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:25,159[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[32mkafka              |[0m [2024-01-24 10:34:20,840] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,843] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,845] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,845] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,848] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,850] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,852] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,853] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,855] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,858] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,861] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,861] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,864] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,867] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,869] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,870] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,872] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,874] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,877] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,877] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,880] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,895] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,899] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,901] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,939] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:34:20,978] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,981] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000031.snapshot,31)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:34:20,990] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=31) with 1 segments in 94ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:20,993] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,994] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:20,998] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,003] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,006] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,011] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,017] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:25,160[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:50,153[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:50,154[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093030-4
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:55,158[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:55,158[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[32mkafka              |[0m [2024-01-24 10:34:21,024] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,026] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,028] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,039] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,047] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,052] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,053] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,058] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,061] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,063] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,063] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,066] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,070] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,073] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,073] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,076] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,079] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,087] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,090] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,096] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,098] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,103] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,103] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,108] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,109] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,110] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,110] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,113] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,118] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,122] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,123] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,127] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,129] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,131] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,131] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,138] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,141] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,145] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,145] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,178] INFO [ProducerStateManager partition=coordinates-0] Writing producer snapshot at offset 512 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:34:21,184] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 512 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,185] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000000512.snapshot,512)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:34:21,190] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=512) with 1 segments in 47ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,193] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,193] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,197] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,201] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,204] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,205] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,210] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,212] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,215] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,217] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,222] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,225] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,228] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,228] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,231] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,240] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,243] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,244] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,247] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,253] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,257] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,260] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,262] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,264] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,270] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,271] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,275] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,277] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,279] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,279] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,285] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:43:55,159[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:20,152[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:20,153[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093060-5
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:25,159[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:25,159[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:25,160[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:50,153[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:50,153[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093090-6
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:55,155[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:55,156[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:44:55,168[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:20,152[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:20,153[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093120-7
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m [2024-01-24 10:34:21,289] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,291] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,291] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,294] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,295] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,297] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,297] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,300] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,303] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,306] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,307] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,309] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,310] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,312] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,313] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,315] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,319] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,320] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,321] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,324] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,326] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,328] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,329] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,331] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,332] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,336] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,336] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,339] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,341] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,343] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,344] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,346] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,349] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,353] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,353] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,357] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:25,155[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:25,155[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:25,156[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:50,153[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:50,154[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093150-8
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m [2024-01-24 10:34:21,360] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,363] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,363] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,366] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,370] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,373] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,374] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,376] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,379] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,385] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,386] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,390] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,394] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,397] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,400] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,413] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,419] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,424] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,425] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,430] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,441] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,443] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,444] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,446] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,449] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,455] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,456] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,460] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,462] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,470] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,471] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,479] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,483] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,487] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,489] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,503] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,508] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,512] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,513] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,524] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,530] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,546] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,547] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,559] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,563] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,570] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,570] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,576] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:34:21,580] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,597] INFO Loaded 51 logs in 892ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,601] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:21,604] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:22,060] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:34:22,067] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:34:22,209] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:34:22,210] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:34:22,210] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:34:22,228] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:34:22,300] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:34:22,379] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,424] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,429] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,395] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,479] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:34:22,615] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:34:22,671] ERROR Error while creating ephemeral at /brokers/ids/1001, node already exists and owner '72058292424540160' does not match current session '72058315245551616' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[32mkafka              |[0m [2024-01-24 10:34:22,679] ERROR [KafkaServer id=1001] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
[32mkafka              |[0m 	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
[32mkafka              |[0m 	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
[32mkafka              |[0m 	at kafka.Kafka$.main(Kafka.scala:109)
[32mkafka              |[0m 	at kafka.Kafka.main(Kafka.scala)
[32mkafka              |[0m [2024-01-24 10:34:22,688] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:34:22,689] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopping socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:34:22,698] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopped socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:34:22,709] INFO [ReplicaManager broker=1001] Shutting down (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 10:34:22,712] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:34:22,715] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:34:22,724] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:34:22,729] INFO [ReplicaFetcherManager on broker 1001] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:34:22,735] INFO [ReplicaFetcherManager on broker 1001] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:34:22,737] INFO [ReplicaAlterLogDirsManager on broker 1001] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 10:34:22,740] INFO [ReplicaAlterLogDirsManager on broker 1001] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 10:34:22,741] INFO [ExpirationReaper-1001-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,827] INFO [ExpirationReaper-1001-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:55,159[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:55,159[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:45:55,160[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:20,152[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:20,154[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093180-9
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m [2024-01-24 10:34:22,827] INFO [ExpirationReaper-1001-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,828] INFO [ExpirationReaper-1001-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,982] INFO [ExpirationReaper-1001-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,982] INFO [ExpirationReaper-1001-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:22,983] INFO [ExpirationReaper-1001-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,031] INFO [ExpirationReaper-1001-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,031] INFO [ExpirationReaper-1001-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,033] INFO [ExpirationReaper-1001-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,231] INFO [ExpirationReaper-1001-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,231] INFO [ExpirationReaper-1001-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,250] INFO [ReplicaManager broker=1001] Shut down completely (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 10:34:23,254] INFO [broker-1001-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:34:23,263] INFO [broker-1001-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:34:23,264] INFO [broker-1001-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:34:23,272] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[32mkafka              |[0m [2024-01-24 10:34:23,277] INFO Shutting down. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:23,391] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:34:23,392] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:34:23,392] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:34:23,392] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:34:23,394] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:34:23,507] INFO Session: 0x10000a7eb530000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:34:23,507] INFO EventThread shut down for session: 0x10000a7eb530000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:34:23,509] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:34:23,510] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,621] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,621] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:23,621] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,614] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,614] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,615] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,616] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,616] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,617] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,619] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,621] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:34:24,623] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutting down socket server (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:34:24,656] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutdown completed (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:34:24,659] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 10:34:24,659] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 10:34:24,660] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 10:34:24,663] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[32mkafka              |[0m [2024-01-24 10:34:24,675] INFO App info kafka.server for 1001 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:34:24,677] INFO [KafkaServer id=1001] shut down completed (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:34:24,678] ERROR Exiting Kafka. (kafka.Kafka$)
[32mkafka              |[0m [2024-01-24 10:34:24,678] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 10:37:55,161] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 10:37:55,508] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 10:37:55,607] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 10:37:55,612] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:37:55,613] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:37:55,633] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:25,155[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:25,155[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:25,157[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:50,152[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:50,153[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093210-10
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[32mkafka              |[0m [2024-01-24 10:37:55,639] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,639] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,639] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,639] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,639] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,639] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,640] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,644] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:37:55,649] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 10:37:55,655] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:37:55,659] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:37:55,663] INFO Opening socket connection to server zookeeper/172.0.0.5:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:37:55,668] INFO Socket connection established, initiating session, client: /172.0.0.2:34666, server: zookeeper/172.0.0.5:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:37:55,683] INFO Session establishment complete on server zookeeper/172.0.0.5:2181, sessionid = 0x10000ab36280000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:37:55,686] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:37:55,762] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:37:55,877] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 10:37:55,882] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:37:55,937] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:55,160[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:55,160[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:46:55,161[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:20,159[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:20,160[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093240-11
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:37:55,946] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:25,167[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:25,167[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:25,168[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:50,152[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:50,153[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093270-12
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:55,155[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:55,162[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:47:55,163[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:20,152[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:20,154[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093300-13
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:37:55,979] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:37:55,980] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:37:55,983] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:37:55,986] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:37:56,053] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,056] INFO Skipping recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,122] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,131] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,134] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,137] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,139] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,142] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,145] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,148] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,151] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,153] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,156] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,159] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,161] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,163] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,166] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,168] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,171] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,174] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,190] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,192] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000031.snapshot,31)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:37:56,204] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=31) with 1 segments in 30ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,206] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,208] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,211] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,213] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,215] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,217] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,219] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,221] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,223] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,224] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,226] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,228] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,230] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,231] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,233] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,235] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,237] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,239] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,241] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,242] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,245] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,246] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,250] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 512 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,250] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000000512.snapshot,512)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:37:56,252] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=512) with 1 segments in 6ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,254] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,255] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,257] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,259] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:25,159[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:25,159[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:25,160[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:50,153[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:50,160[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093330-14
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:55,169[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:55,169[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:48:55,170[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:49:20,153[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:49:20,154[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093360-15
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:49:25,158[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 10:49:25,158[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[32mkafka              |[0m [2024-01-24 10:37:56,261] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,263] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,266] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,268] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,270] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,272] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,274] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,276] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,278] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,280] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,283] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,285] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,287] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,289] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,291] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,293] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,295] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,297] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,300] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,301] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,304] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,305] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,307] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,309] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,311] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,312] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,315] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,317] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,319] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,320] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,322] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,324] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,326] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,328] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,331] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,333] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,335] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,336] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,338] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,340] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,342] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,344] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,347] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,348] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,350] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,351] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,353] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,354] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,356] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,358] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,360] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,361] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,364] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:37:56,365] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,368] INFO Loaded 51 logs in 314ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,368] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,369] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:37:56,752] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:37:56,763] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:37:56,841] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:37:56,843] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:37:56,844] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:37:56,854] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:37:56,917] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:37:56,953] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:37:56,957] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:37:56,958] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 10:49:25,159[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m 10:50:28,321 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 10:50:28,367 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 10:50:28,369 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 10:50:28,377 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 10:50:29,160 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 10:50:29,312 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 10:50:29,312 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 10:50:29,350 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 10:50:29,350 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 10:50:29,350 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 10:50:29,350 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 10:50:29,351 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 10:50:29,351 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 10:50:29,351 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 10:50:29,351 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:29,410[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:29,514[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:29,520[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:29,521[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:29,522[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:34,320[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:34,985[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:35,020[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 932cbadb-1616-463f-b134-b8b48dab9ba0
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:35,173[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:35,546[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:35,565[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 6.927 seconds (process running for 7.93)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:36,485[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[32mkafka              |[0m [2024-01-24 10:37:56,964] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:37:56,995] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:37:57,106] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:37:57,139] INFO Stat of the created znode at /brokers/ids/1001 is: 177,177,1706092677123,1706092677123,1,0,0,72058329385926656,237,0,177
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:37:57,141] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 177 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:37:57,227] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:37:57,243] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:37:57,247] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:37:57,268] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:57,295] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:57,339] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-24 10:37:57,342] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:57,350] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:57,352] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-24 10:37:57,400] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:37:57,600] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-24 10:37:57,680] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:37:57,698] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:37:57,715] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:37:57,715] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:37:57,728] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:37:57,729] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:37:57,729] INFO Kafka startTimeMs: 1706092677715 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:37:57,731] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:37:57,884] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:37:57,902] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, coordinates-0, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:37:57,915] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,925] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,933] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,946] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,948] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 512 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,949] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,954] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,959] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,964] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,974] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,981] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,992] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,997] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:57,999] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,002] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:36,495[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706093436-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:36,560[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:36,560[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:36,560[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1706093436559
[36;1mkafka-ui           |[0m [30m2024-01-24 10:50:36,987[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:51:05,562[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:51:05,606[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:51:35,562[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:51:35,597[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:52:05,562[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:52:05,593[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:52:35,562[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:52:35,591[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:53:05,562[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:53:05,591[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:53:35,569[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:53:35,596[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:54:05,562[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:54:05,587[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:54:35,562[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:54:35,584[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[32mkafka              |[0m [2024-01-24 10:37:58,004] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,008] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,009] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,012] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,015] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,017] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,028] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,033] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,038] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,045] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,048] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,051] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,058] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,060] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,063] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,065] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,069] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,078] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,084] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,086] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,089] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,092] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,099] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,101] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,103] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 31 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,104] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,122] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,137] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,140] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,150] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,153] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,164] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,169] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,173] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,175] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,178] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:37:58,185] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,197] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,206] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,206] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,206] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,207] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[36;1mkafka-ui           |[0m [30m2024-01-24 10:55:05,566[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:55:05,585[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:55:35,562[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:55:35,585[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:55:36,873[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706093436-1[0;39m] [33mo.a.k.c.NetworkClient[0;39m: [AdminClient clientId=kafka-ui-admin-1706093436-1] Node -1 disconnected.
[36;1mkafka-ui           |[0m [30m2024-01-24 10:56:05,562[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:56:05,589[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:56:35,562[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:56:35,584[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:57:05,562[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:57:05,584[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:57:35,562[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:57:35,595[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:58:05,569[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:58:05,588[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:58:35,569[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:58:35,591[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:59:05,562[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:59:05,578[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:59:35,562[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 10:59:35,585[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:00:01,810[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706093436-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.admin.client for kafka-ui-admin-1706093436-1 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-24 11:00:01,816[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706093436-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-24 11:00:01,816[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706093436-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-24 11:00:01,816[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706093436-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m 11:01:06,400 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 11:01:06,452 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 11:01:06,453 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 11:01:06,461 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 11:01:07,436 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 11:01:07,602 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 11:01:07,602 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 11:01:07,645 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 11:01:07,645 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 11:01:07,645 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 11:01:07,645 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 11:01:07,646 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 11:01:07,647 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 11:01:07,647 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 11:01:07,647 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:07,722[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:07,837[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:07,843[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[32mkafka              |[0m [2024-01-24 10:37:58,208] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,208] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,209] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,210] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:07,844[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:07,845[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:12,230[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:12,887[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:12,920[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: c5ce054f-532d-4e69-9dcb-1b55c416522f
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:13,082[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:13,467[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:13,495[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 6.579 seconds (process running for 8.06)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:14,439[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:14,449[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094074-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:19,489[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:19,500[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:19,504[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:43,492[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:43,494[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094103-2
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:48,499[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:48,499[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,211] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,212] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,232] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 34 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,246] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 40 milliseconds for epoch 0, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,247] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 40 milliseconds for epoch 0, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,250] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 41 milliseconds for epoch 0, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,251] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 42 milliseconds for epoch 0, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,251] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 42 milliseconds for epoch 0, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,251] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 42 milliseconds for epoch 0, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,253] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 43 milliseconds for epoch 0, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,253] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 43 milliseconds for epoch 0, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,253] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 42 milliseconds for epoch 0, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,255] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 44 milliseconds for epoch 0, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,258] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 47 milliseconds for epoch 0, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,258] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 47 milliseconds for epoch 0, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 48 milliseconds for epoch 0, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 48 milliseconds for epoch 0, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 48 milliseconds for epoch 0, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 48 milliseconds for epoch 0, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 48 milliseconds for epoch 0, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 49 milliseconds for epoch 0, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:01:48,500[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:13,493[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:13,494[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094133-3
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:18,499[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:18,500[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[32mkafka              |[0m [2024-01-24 10:37:58,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 50 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 50 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 50 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 50 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 49 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 50 milliseconds for epoch 0, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 50 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 50 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 50 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,313] INFO Loaded member MemberMetadata(memberId=rdkafka-25c8d075-d354-4891-8ab9-6c285035751e, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 1. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 10:37:58,334] INFO [GroupCoordinator 1001]: Loading group metadata for web_consumer_group with generation 1 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:37:58,350] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 138 milliseconds for epoch 0, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,351] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 139 milliseconds for epoch 0, of which 139 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,352] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 140 milliseconds for epoch 0, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,352] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 140 milliseconds for epoch 0, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,352] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 140 milliseconds for epoch 0, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,352] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 140 milliseconds for epoch 0, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,352] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 140 milliseconds for epoch 0, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,353] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 141 milliseconds for epoch 0, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,353] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 141 milliseconds for epoch 0, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,353] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 141 milliseconds for epoch 0, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:18,501[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:43,493[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:43,494[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094163-4
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:48,495[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:48,495[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:02:48,496[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:13,493[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:13,494[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094193-5
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:18,498[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:18,498[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:18,499[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:43,492[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:43,493[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094223-6
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:48,498[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:48,499[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[32mkafka              |[0m [2024-01-24 10:37:58,353] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 141 milliseconds for epoch 0, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:37:58,353] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 141 milliseconds for epoch 0, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:38:01,185] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: Adding new member rdkafka-930344d8-a90c-4e41-91e5-752c480865d2 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-24 10:38:43,343] INFO [GroupCoordinator 1001]: Member rdkafka-25c8d075-d354-4891-8ab9-6c285035751e in group web_consumer_group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,352] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 2 (__consumer_offsets-35) with 7 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,364] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-e73f7d91-2c66-43ba-ad9f-03ee7bb9c196] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,364] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 2 (__consumer_offsets-35) (reason: removing member rdkafka-e73f7d91-2c66-43ba-ad9f-03ee7bb9c196 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,366] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-8982ef33-db5d-4da5-b402-a6209512b983] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,367] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-fce31ea3-8cba-4286-baae-261a03563795] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,367] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-930344d8-a90c-4e41-91e5-752c480865d2] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,368] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-64cd746e-060b-426b-b324-d31e4cdbfe2f] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:43,368] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-c93d782e-44d3-43aa-a7b2-865e8a6063cc] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:44,252] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-99ec42ef-9238-4e4b-924b-5a8714103b40] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:44,253] INFO [GroupCoordinator 1001]: Group web_consumer_group with generation 3 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:45,290] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 3 (__consumer_offsets-35) (reason: Adding new member rdkafka-70f9fa21-70b9-431f-8ddb-e627d77cd73c with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:45,291] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 4 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:45,298] INFO [GroupCoordinator 1001]: Assignment received from leader for group web_consumer_group for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:38:47,007] INFO Unable to read additional data from server sessionid 0x10000ab36280000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:38:48,251] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:48,809] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:49,910] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:50,303] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:51,404] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:51,701] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:52,802] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:53,322] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:54,422] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:54,503] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:55,604] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:55,739] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:56,839] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:56,915] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:57,565] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:03:48,500[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:04:13,492[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:04:13,494[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094253-7
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:04:18,499[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:04:18,501[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:04:18,502[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m 11:05:23,588 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 11:05:23,644 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 11:05:23,646 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 11:05:23,663 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 11:05:24,609 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 11:05:24,711 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 11:05:24,711 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 11:05:24,748 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[32mkafka              |[0m [2024-01-24 10:38:57,567] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:38:57,569] INFO [KafkaServer id=1001] Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:38:58,015] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:38:58,439] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:38:58,542] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:38:59,677] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:39:00,432] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:39:01,533] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:39:02,453] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:39:03,554] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:39:03,851] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:39:04,952] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:39:05,578] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 10:39:06,679] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 10:39:06,869] WARN Session 0x10000ab36280000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 10:42:14,463] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 10:42:14,755] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 10:42:14,827] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 10:42:14,830] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:42:14,831] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:42:14,850] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:42:14,854] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[36;1mkafka-ui           |[0m 11:05:24,748 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 11:05:24,748 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 11:05:24,748 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 11:05:24,748 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 11:05:24,749 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 11:05:24,750 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 11:05:24,750 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:24,840[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:24,956[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:24,962[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:24,962[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:24,963[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:28,193[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:29,183[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:29,247[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 7db18407-ea74-4b5e-a0a3-65877e60e251
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:29,435[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:29,934[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:29,952[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 5.865 seconds (process running for 7.257)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:30,874[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:30,884[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094330-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:32,875[0;39m [1;31mERROR[0;39m [[34mscheduling-1[0;39m] [33mo.s.s.s.TaskUtils$LoggingErrorHandler[0;39m: Unexpected error occurred in scheduled task
[36;1mkafka-ui           |[0m reactor.core.Exceptions$ReactiveException: java.lang.InterruptedException
[36;1mkafka-ui           |[0m 	at reactor.core.Exceptions.propagate(Exceptions.java:408)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.BlockingSingleSubscriber.blockingGet(BlockingSingleSubscriber.java:91)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.block(Mono.java:1710)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.ClustersStatisticsScheduler.updateStatistics(ClustersStatisticsScheduler.java:30)
[36;1mkafka-ui           |[0m 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,855] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,857] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:14,861] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 10:42:14,866] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:42:14,868] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:42:14,873] INFO Opening socket connection to server zookeeper/172.0.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:42:14,878] INFO Socket connection established, initiating session, client: /172.0.0.2:54632, server: zookeeper/172.0.0.3:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:42:14,889] INFO Session establishment complete on server zookeeper/172.0.0.3:2181, sessionid = 0x10000af28c10000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:42:14,892] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:42:14,981] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:42:15,116] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 10:42:15,122] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:42:15,183] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36;1mkafka-ui           |[0m 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
[36;1mkafka-ui           |[0m 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
[36;1mkafka-ui           |[0m 	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
[36;1mkafka-ui           |[0m 	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: java.lang.InterruptedException: null
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1048)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.CountDownLatch.await(CountDownLatch.java:230)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.BlockingSingleSubscriber.blockingGet(BlockingSingleSubscriber.java:87)
[36;1mkafka-ui           |[0m 	... 14 common frames omitted
[36;1mkafka-ui           |[0m 11:05:47,753 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 11:05:47,807 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 11:05:47,808 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 11:05:47,820 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 11:05:48,744 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 11:05:48,861 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 11:05:48,861 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 11:05:48,906 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 11:05:48,906 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 11:05:48,906 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 11:05:48,907 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 11:05:48,907 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 11:05:48,908 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 11:05:48,908 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 11:05:48,908 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:48,979[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:49,103[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:49,107[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:49,108[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:49,109[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:53,321[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:54,800[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:54,863[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: a94e8fb9-f631-45cb-88ec-0934b18842a4
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:55,229[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:55,736[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:55,754[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 7.515 seconds (process running for 8.873)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:56,568[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:56,582[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094356-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:56,652[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:56,653[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:56,653[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1706094356651
[36;1mkafka-ui           |[0m [30m2024-01-24 11:05:57,254[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:06:25,753[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:06:25,788[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:06:55,752[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:06:55,783[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:07:25,752[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:07:25,771[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:07:55,752[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:07:55,777[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:08:25,753[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:08:25,795[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:08:55,753[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:08:55,783[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:09:25,752[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:09:25,779[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:09:55,756[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:09:55,777[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:10:15,885[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706094356-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.admin.client for kafka-ui-admin-1706094356-1 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-24 11:10:15,890[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706094356-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-24 11:10:15,890[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706094356-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-24 11:10:15,890[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1706094356-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m 11:11:41,087 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 11:11:41,153 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 11:11:41,154 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 11:11:41,164 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 11:11:42,064 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 11:11:42,194 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 11:11:42,194 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 11:11:42,229 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 11:11:42,229 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 11:11:42,229 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 11:11:42,230 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[36;1mkafka-ui           |[0m 11:11:42,230 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 11:11:42,231 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 11:11:42,231 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 11:11:42,231 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:42,323[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:42,455[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:42,464[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:42,465[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:42,466[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:45,851[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:46,840[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:46,881[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: d8a36751-ba78-4d0a-a3a1-cb57842207e8
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:47,109[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:47,674[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:47,699[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 6.099 seconds (process running for 7.42)
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:49,007[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:49,041[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094709-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:54,104[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:54,115[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:42:15,193] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:11:54,119[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:17,697[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:17,698[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094737-2
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:22,704[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:22,704[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:22,705[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:47,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:47,698[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094767-3
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:52,699[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:52,699[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:42:15,253] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:15,254] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:15,259] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:15,263] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:15,338] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,344] INFO Attempting recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,408] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,410] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,438] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,447] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,450] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,450] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,457] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,460] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,462] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,463] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,466] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,468] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,470] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,471] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,473] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,475] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,477] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,477] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,480] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,483] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,486] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,487] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,490] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,493] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,495] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,496] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,499] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,503] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,505] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,506] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,510] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,518] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,522] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,522] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,526] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,537] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,542] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,544] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,564] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 33 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:42:15,577] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 33 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,579] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000033.snapshot,33)' (kafka.log.ProducerStateManager)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:12:52,700[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:17,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:17,697[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094797-4
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:22,699[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:22,700[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[32mkafka              |[0m [2024-01-24 10:42:15,584] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=33) with 1 segments in 46ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,586] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,586] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,589] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,591] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,593] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,593] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,596] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,599] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,601] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,601] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,602] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,604] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,606] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,607] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,609] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,612] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,614] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,614] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,617] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,620] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,623] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,623] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,626] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,628] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,629] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,630] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,632] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,634] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,637] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,637] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,640] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,642] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,645] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,645] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,647] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:22,701[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:47,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:47,697[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094827-5
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:52,699[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:52,699[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:13:52,700[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:17,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:17,697[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094857-6
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:22,702[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:22,703[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:22,704[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:47,695[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:47,696[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094887-7
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:52,700[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:52,700[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:14:52,701[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:17,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:17,697[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094917-8
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:22,703[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:22,703[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:22,704[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:47,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:47,697[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094947-9
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:52,699[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:52,699[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:15:52,700[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:17,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:17,698[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706094977-10
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[32mkafka              |[0m [2024-01-24 10:42:15,649] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,651] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,652] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,654] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,656] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,658] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,658] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,661] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,663] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,665] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,665] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,687] INFO [ProducerStateManager partition=coordinates-0] Writing producer snapshot at offset 620 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:42:15,691] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 620 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,691] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000000620.snapshot,620)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:42:15,694] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=620) with 1 segments in 31ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,696] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,696] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,698] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,700] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,703] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,703] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,705] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,708] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,710] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,710] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,713] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,716] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,719] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,720] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,723] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,724] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,727] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,728] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,731] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,733] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,735] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,735] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,738] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,740] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,742] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,742] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,745] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,747] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,749] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,749] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,752] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,754] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,756] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,756] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,758] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,761] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,763] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,763] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,766] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,768] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,770] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,770] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,772] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,773] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,775] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,775] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,778] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,780] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,784] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,785] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,787] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,788] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,789] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,790] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,792] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,793] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,797] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,797] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,801] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,804] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,806] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,806] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,808] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,809] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,811] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,812] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,815] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,816] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,817] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,819] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,821] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,823] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,824] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,824] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,828] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,829] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,831] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,831] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,833] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,834] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,836] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,836] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,839] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,840] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,843] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,843] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,846] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,848] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,850] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,850] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,853] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,855] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,856] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,857] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,861] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,863] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,866] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,866] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,868] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,869] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,870] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,870] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,872] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,873] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,875] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,875] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,879] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,881] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,882] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,883] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,885] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,886] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,888] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,889] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,891] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:42:15,892] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,895] INFO Loaded 51 logs in 556ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,896] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:15,897] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:16,261] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:42:16,266] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:42:16,343] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:42:16,344] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:42:16,346] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:42:16,360] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:42:16,394] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:42:16,424] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:16,425] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:16,426] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:16,427] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:16,463] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:42:16,546] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:42:16,593] ERROR Error while creating ephemeral at /brokers/ids/1001, node already exists and owner '72058329385926656' does not match current session '72058346340941824' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[32mkafka              |[0m [2024-01-24 10:42:16,605] ERROR [KafkaServer id=1001] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
[32mkafka              |[0m 	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
[32mkafka              |[0m 	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
[32mkafka              |[0m 	at kafka.Kafka$.main(Kafka.scala:109)
[32mkafka              |[0m 	at kafka.Kafka.main(Kafka.scala)
[32mkafka              |[0m [2024-01-24 10:42:16,609] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:42:16,609] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopping socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:42:16,617] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopped socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:42:16,622] INFO [ReplicaManager broker=1001] Shutting down (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 10:42:16,627] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:42:16,629] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:42:16,629] INFO [ReplicaFetcherManager on broker 1001] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:42:16,630] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:42:16,632] INFO [ReplicaFetcherManager on broker 1001] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:42:16,632] INFO [ReplicaAlterLogDirsManager on broker 1001] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 10:42:16,634] INFO [ReplicaAlterLogDirsManager on broker 1001] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 10:42:16,634] INFO [ExpirationReaper-1001-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:16,833] INFO [ExpirationReaper-1001-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:16,833] INFO [ExpirationReaper-1001-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:16,834] INFO [ExpirationReaper-1001-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,027] INFO [ExpirationReaper-1001-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,027] INFO [ExpirationReaper-1001-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,027] INFO [ExpirationReaper-1001-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,227] INFO [ExpirationReaper-1001-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,227] INFO [ExpirationReaper-1001-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,228] INFO [ExpirationReaper-1001-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,229] INFO [ExpirationReaper-1001-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,229] INFO [ExpirationReaper-1001-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:42:17,233] INFO [ReplicaManager broker=1001] Shut down completely (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 10:42:17,234] INFO [broker-1001-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:42:17,235] INFO [broker-1001-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:42:17,235] INFO [broker-1001-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:42:17,238] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[32mkafka              |[0m [2024-01-24 10:42:17,239] INFO Shutting down. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:17,282] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:42:17,283] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:42:17,283] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:42:17,283] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:42:17,284] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:42:17,388] INFO EventThread shut down for session: 0x10000af28c10000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:42:17,389] INFO Session: 0x10000af28c10000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:42:17,391] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:42:17,393] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:18,255] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:18,255] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:18,255] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:18,264] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:18,264] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:18,264] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:19,264] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:19,264] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:19,265] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:19,265] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:19,265] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:42:19,268] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutting down socket server (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:42:19,291] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutdown completed (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:42:19,293] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 10:42:19,293] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 10:42:19,293] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 10:42:19,295] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[32mkafka              |[0m [2024-01-24 10:42:19,301] INFO App info kafka.server for 1001 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:42:19,301] INFO [KafkaServer id=1001] shut down completed (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:42:19,301] ERROR Exiting Kafka. (kafka.Kafka$)
[32mkafka              |[0m [2024-01-24 10:42:19,302] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 10:50:28,753] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 10:50:29,034] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 10:50:29,110] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 10:50:29,113] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:50:29,113] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:50:29,128] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:22,703[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:22,704[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:22,705[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:47,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:47,697[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706095007-11
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,132] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,134] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 10:50:29,138] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 10:50:29,142] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:50:29,147] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:50:29,160] INFO Opening socket connection to server zookeeper/172.0.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:50:29,172] INFO Socket connection established, initiating session, client: /172.0.0.3:56600, server: zookeeper/172.0.0.2:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:50:29,192] INFO Session establishment complete on server zookeeper/172.0.0.2:2181, sessionid = 0x10000b6b3b90000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 10:50:29,203] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 10:50:29,322] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 10:50:29,476] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 10:50:29,481] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:50:29,530] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:52,701[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:52,701[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:16:52,701[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:17:17,696[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 11:17:17,698[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706095037-12
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 11:17:22,703[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-24 11:17:22,703[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-24 11:17:22,704[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m 12:24:02,742 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 12:24:02,896 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 12:24:02,897 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 12:24:02,920 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 12:24:04,490 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 12:24:04,629 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 12:24:04,629 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 12:24:04,670 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 12:24:04,670 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 12:24:04,670 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 12:24:04,671 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 12:24:04,671 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 12:24:04,672 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 12:24:04,672 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 12:24:04,672 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:50:29,538] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:04,742[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:04,855[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:04,862[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:04,862[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:04,863[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:08,827[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:10,138[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:10,178[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: faf7a2ca-6676-41dc-8567-6b65723fa3c5
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:10,418[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:10,957[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:10,981[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 7.42 seconds (process running for 9.752)
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:12,538[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:12,594[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1706099052-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:12,772[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:12,772[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:12,772[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1706099052769
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:13,397[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:40,979[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-24 12:24:41,038[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 10:50:29,583] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:50:29,585] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:50:29,587] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:50:29,588] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 10:50:29,685] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,688] INFO Skipping recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,769] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,780] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,784] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,788] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,792] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,794] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,797] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,800] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,803] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,805] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,808] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,810] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,813] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,816] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,818] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,821] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,822] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,825] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,847] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 33 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,849] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000033.snapshot,33)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:50:29,860] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=33) with 1 segments in 36ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,863] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,865] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,867] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,870] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,872] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,876] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,879] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,883] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,885] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,888] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,891] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,893] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,895] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,897] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,900] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,902] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,905] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,907] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,910] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,912] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,916] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,918] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,923] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 620 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,923] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000000620.snapshot,620)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 10:50:29,926] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=620) with 1 segments in 8ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,929] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,931] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,933] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,936] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,938] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,940] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,942] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,943] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,945] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,946] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,948] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,950] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,953] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,954] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,957] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,959] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,962] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,965] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,968] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,969] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,972] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,973] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,976] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,978] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,981] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,983] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,985] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,987] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,989] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,991] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,994] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:29,996] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:29,999] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,000] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,003] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,006] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,009] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,011] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,016] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,018] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,021] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,023] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,029] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,031] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,035] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,037] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,040] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,043] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,047] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,049] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,053] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,057] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,062] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,064] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,069] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,072] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,080] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 10:50:30,084] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,089] INFO Loaded 51 logs in 404ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,091] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,094] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 10:50:30,573] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:50:30,581] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:50:30,636] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:50:30,637] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 10:50:30,637] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 10:50:30,665] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:50:30,702] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:50:30,729] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:30,731] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:30,734] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:30,734] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:30,753] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 10:50:30,874] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:50:30,913] INFO Stat of the created znode at /brokers/ids/1001 is: 216,216,1706093430895,1706093430895,1,0,0,72058378737221632,237,0,216
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:50:30,916] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 216 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 10:50:31,043] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:31,058] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:31,061] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:31,096] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,138] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,243] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-24 10:50:31,245] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,250] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-24 10:50:31,250] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,367] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 10:50:31,461] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-24 10:50:31,518] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:50:31,524] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:50:31,538] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:50:31,539] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 10:50:31,557] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:50:31,557] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:50:31,557] INFO Kafka startTimeMs: 1706093431539 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 10:50:31,558] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 10:50:31,632] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 10:50:31,673] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, coordinates-0, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 10:50:31,693] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,705] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,712] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,716] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,721] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 620 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,722] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,725] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,728] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,729] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,735] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,738] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,740] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,742] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,744] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,746] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,749] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,754] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,761] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,762] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,765] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,768] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,770] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,772] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,775] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,779] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,782] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,785] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,787] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,792] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,803] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,805] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,809] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,812] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,814] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,821] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,829] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,849] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,855] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,858] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,861] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 33 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,862] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,864] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,869] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,873] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,876] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,879] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,898] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,908] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,910] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,912] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,914] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 10:50:31,937] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,938] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,942] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,943] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,943] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,943] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,943] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,943] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,944] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,944] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,945] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,945] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,945] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,945] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,945] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,945] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,945] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,946] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,947] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,952] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 11 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,960] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,961] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 16 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,961] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,961] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,962] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 16 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,962] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,963] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 17 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,963] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,964] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,964] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,965] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,966] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,966] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,966] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,966] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,966] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,967] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,966] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,967] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,967] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,967] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,970] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,971] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,971] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,971] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,971] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,972] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,973] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,974] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,975] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,975] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,975] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,975] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,975] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,975] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,976] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,976] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,976] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,976] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,976] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,976] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,975] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 4 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,981] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,982] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,982] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,983] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,983] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,983] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,983] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,983] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,983] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,983] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,984] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,985] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,986] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,986] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,986] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 15 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,986] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,986] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,986] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,987] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,987] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,988] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,989] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,989] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,989] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,989] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,990] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,990] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,990] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,990] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,988] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 14 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,990] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,992] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,993] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,991] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,994] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,994] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,994] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,994] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,994] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:31,995] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:31,996] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,006] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 31 milliseconds for epoch 0, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,008] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 33 milliseconds for epoch 0, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,009] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 34 milliseconds for epoch 0, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,011] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 35 milliseconds for epoch 0, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,012] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 36 milliseconds for epoch 0, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,013] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 37 milliseconds for epoch 0, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,014] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,014] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 32 milliseconds for epoch 0, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,015] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 32 milliseconds for epoch 0, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,015] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 32 milliseconds for epoch 0, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,015] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 32 milliseconds for epoch 0, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,016] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 33 milliseconds for epoch 0, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,016] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 31 milliseconds for epoch 0, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,077] INFO Loaded member MemberMetadata(memberId=rdkafka-25c8d075-d354-4891-8ab9-6c285035751e, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 1. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 10:50:32,091] INFO Loaded member MemberMetadata(memberId=rdkafka-70f9fa21-70b9-431f-8ddb-e627d77cd73c, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 4. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 10:50:32,100] INFO [GroupCoordinator 1001]: Loading group metadata for web_consumer_group with generation 4 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:50:32,109] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 122 milliseconds for epoch 0, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,110] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 124 milliseconds for epoch 0, of which 124 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 124 milliseconds for epoch 0, of which 123 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 122 milliseconds for epoch 0, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 122 milliseconds for epoch 0, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 122 milliseconds for epoch 0, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 121 milliseconds for epoch 0, of which 121 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 121 milliseconds for epoch 0, of which 121 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 117 milliseconds for epoch 0, of which 117 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 117 milliseconds for epoch 0, of which 117 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,112] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 117 milliseconds for epoch 0, of which 116 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,114] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 118 milliseconds for epoch 0, of which 118 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 10:50:32,495] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 4 (__consumer_offsets-35) (reason: Adding new member rdkafka-09292019-e7af-4736-8a73-a38360ada2c2 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-24 10:51:17,109] INFO [GroupCoordinator 1001]: Member rdkafka-70f9fa21-70b9-431f-8ddb-e627d77cd73c in group web_consumer_group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,115] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 5 (__consumer_offsets-35) with 7 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,122] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-876531ff-b126-4fec-9f61-71e28cd265cd] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,124] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 5 (__consumer_offsets-35) (reason: removing member rdkafka-876531ff-b126-4fec-9f61-71e28cd265cd on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,127] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-7b257e2b-e690-4851-a162-21cb963acabb] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,129] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-37d553a1-0347-4fea-9558-2d439f335029] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,129] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-d61f3fd5-6259-438d-8724-186f9e261a16] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,130] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-09292019-e7af-4736-8a73-a38360ada2c2] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,130] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-c6f25981-ba5e-412f-b5a8-10b89b275331] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,131] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-a47926df-cc7f-4dc8-bc58-b53a3c4b4b11] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:17,131] INFO [GroupCoordinator 1001]: Group web_consumer_group with generation 6 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:18,154] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 6 (__consumer_offsets-35) (reason: Adding new member rdkafka-20334c10-f900-42d7-8b25-e110938a58b8 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:18,156] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 7 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 10:51:18,162] INFO [GroupCoordinator 1001]: Assignment received from leader for group web_consumer_group for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:00:11,817] INFO Unable to read additional data from server sessionid 0x10000b6b3b90000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:00:13,067] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:13,455] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:14,556] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:14,953] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:16,053] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:16,767] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:17,868] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:18,727] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:19,827] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:20,752] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:21,853] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:22,390] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:00:22,391] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:00:22,397] INFO [KafkaServer id=1001] Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:00:22,738] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:22,841] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:00:23,990] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:24,459] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:25,560] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:25,836] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:26,937] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:27,072] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:28,173] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:28,900] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:30,001] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:30,274] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:00:31,375] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:00:32,305] WARN Session 0x10000b6b3b90000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 11:01:07,078] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 11:01:07,409] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 11:01:07,495] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:01:07,499] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:01:07,499] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:01:07,525] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,538] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,539] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,541] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:07,551] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 11:01:07,558] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:01:07,562] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:01:07,572] INFO Opening socket connection to server zookeeper/172.0.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:01:07,578] INFO Socket connection established, initiating session, client: /172.0.0.4:47906, server: zookeeper/172.0.0.3:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:01:07,592] INFO Session establishment complete on server zookeeper/172.0.0.3:2181, sessionid = 0x10000c0723f0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:01:07,595] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:01:07,693] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:01:07,862] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 11:01:07,867] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:01:07,926] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:01:07,941] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:01:07,990] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:07,990] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:07,993] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:07,993] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:08,097] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,099] INFO Attempting recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,160] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,163] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,204] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,224] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 116ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,229] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,230] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,237] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,267] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 43ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,270] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,271] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,275] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,279] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,283] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,284] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,288] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,294] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,297] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,297] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,300] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,304] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,307] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,308] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,311] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,317] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,319] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,320] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,322] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,327] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,330] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,331] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,334] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,340] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,345] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,345] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,348] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,351] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,355] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,355] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,378] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 141 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:01:08,392] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 141 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,393] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000141.snapshot,141)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:01:08,400] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=141) with 1 segments in 49ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,402] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,402] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,409] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,412] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,414] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,415] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,417] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,423] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,426] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,427] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,430] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,433] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,436] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,436] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,441] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,443] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,445] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,445] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,447] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,449] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,451] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,451] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,455] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,457] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,458] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,458] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,460] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,463] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,465] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,465] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,469] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,472] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,475] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,475] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,478] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,480] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,481] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,482] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,484] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,485] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,487] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,487] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,489] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,490] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,492] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,492] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,525] INFO [ProducerStateManager partition=coordinates-0] Writing producer snapshot at offset 1786 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:01:08,529] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 1786 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,529] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000001786.snapshot,1786)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:01:08,532] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1786) with 1 segments in 42ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,534] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,535] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,538] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,541] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,548] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,550] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,556] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,558] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,561] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,561] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,564] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,565] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,567] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,568] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,571] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,573] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,576] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,578] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,581] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,583] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,585] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,585] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,587] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,589] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,591] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,591] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,593] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,595] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,597] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,597] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,599] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,600] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,602] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,603] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,605] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,614] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,617] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,617] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,621] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,624] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,630] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,632] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,635] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,639] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,642] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,643] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,646] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,650] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,654] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,655] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,659] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,664] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,667] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,668] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,671] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,674] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,678] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,679] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,682] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,685] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,688] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,688] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,690] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,692] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,695] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,696] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,699] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,701] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,707] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,707] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,710] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,713] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,716] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,717] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,720] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,721] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,724] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,724] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,726] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,729] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,733] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,734] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,738] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,739] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,742] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,742] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,746] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,749] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,752] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,752] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,756] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,757] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,759] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,759] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,762] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,765] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,769] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,770] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,772] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,773] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,775] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,775] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,778] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,782] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,784] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,784] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,785] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,787] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,788] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,789] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,790] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,791] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,793] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,793] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,798] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:01:08,800] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,803] INFO Loaded 51 logs in 706ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,804] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:08,805] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:09,528] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:01:09,541] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:01:09,626] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:01:09,627] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:01:09,628] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:01:09,638] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:01:09,683] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:01:09,733] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:09,734] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:09,735] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:09,736] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:09,789] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:01:09,978] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:01:10,046] ERROR Error while creating ephemeral at /brokers/ids/1001, node already exists and owner '72058378737221632' does not match current session '72058420588380160' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[32mkafka              |[0m [2024-01-24 11:01:10,060] ERROR [KafkaServer id=1001] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
[32mkafka              |[0m 	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
[32mkafka              |[0m 	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
[32mkafka              |[0m 	at kafka.Kafka$.main(Kafka.scala:109)
[32mkafka              |[0m 	at kafka.Kafka.main(Kafka.scala)
[32mkafka              |[0m [2024-01-24 11:01:10,070] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:01:10,072] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopping socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:01:10,081] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopped socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:01:10,095] INFO [ReplicaManager broker=1001] Shutting down (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 11:01:10,096] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:01:10,103] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:01:10,105] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:01:10,106] INFO [ReplicaFetcherManager on broker 1001] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:01:10,111] INFO [ReplicaFetcherManager on broker 1001] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:01:10,112] INFO [ReplicaAlterLogDirsManager on broker 1001] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 11:01:10,114] INFO [ReplicaAlterLogDirsManager on broker 1001] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 11:01:10,114] INFO [ExpirationReaper-1001-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,136] INFO [ExpirationReaper-1001-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,138] INFO [ExpirationReaper-1001-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,141] INFO [ExpirationReaper-1001-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,339] INFO [ExpirationReaper-1001-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,340] INFO [ExpirationReaper-1001-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,340] INFO [ExpirationReaper-1001-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,538] INFO [ExpirationReaper-1001-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,539] INFO [ExpirationReaper-1001-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,540] INFO [ExpirationReaper-1001-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,738] INFO [ExpirationReaper-1001-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,740] INFO [ExpirationReaper-1001-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:01:10,780] INFO [ReplicaManager broker=1001] Shut down completely (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 11:01:10,781] INFO [broker-1001-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:01:10,783] INFO [broker-1001-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:01:10,784] INFO [broker-1001-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:01:10,795] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[32mkafka              |[0m [2024-01-24 11:01:10,799] INFO Shutting down. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:10,920] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:01:10,928] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:01:10,930] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:01:10,930] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:01:10,933] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:01:11,046] INFO EventThread shut down for session: 0x10000c0723f0000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:01:11,047] INFO Session: 0x10000c0723f0000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:01:11,050] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:01:11,050] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,996] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,996] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,996] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,996] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,997] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,997] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,998] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,998] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:11,998] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:12,997] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:12,997] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:01:12,998] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutting down socket server (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:01:13,013] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutdown completed (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:01:13,014] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:01:13,014] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:01:13,014] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:01:13,015] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[32mkafka              |[0m [2024-01-24 11:01:13,019] INFO App info kafka.server for 1001 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:01:13,019] INFO [KafkaServer id=1001] shut down completed (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:01:13,020] ERROR Exiting Kafka. (kafka.Kafka$)
[32mkafka              |[0m [2024-01-24 11:01:13,020] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 11:04:21,731] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 11:04:21,943] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 11:04:22,000] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:04:22,003] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:04:22,003] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:04:22,016] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,019] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,021] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:04:22,024] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 11:04:22,027] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:04:22,029] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:04:22,034] INFO Opening socket connection to server zookeeper/172.0.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:04:22,037] INFO Socket connection established, initiating session, client: /172.0.0.4:59690, server: zookeeper/172.0.0.3:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:04:22,047] INFO Session establishment complete on server zookeeper/172.0.0.3:2181, sessionid = 0x10000c0723f0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:04:22,049] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:04:22,102] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:04:22,198] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 11:04:22,201] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:04:22,236] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:04:22,242] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:04:22,266] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,266] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,267] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,268] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,310] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,313] INFO Skipping recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,362] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,368] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,370] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,371] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,373] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,375] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,377] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,378] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,380] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,381] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,383] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,384] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,385] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,387] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,388] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,390] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,391] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,392] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,409] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 141 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,410] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000141.snapshot,141)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:04:22,417] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=141) with 1 segments in 25ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,419] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,420] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,423] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,425] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,426] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,427] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,428] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,430] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,431] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,432] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,434] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,435] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,436] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,437] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,439] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,440] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,441] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,442] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,443] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,444] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,446] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,447] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,450] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 1786 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,451] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000001786.snapshot,1786)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:04:22,453] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1786) with 1 segments in 6ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,456] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,458] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,461] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,462] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,464] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,466] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,468] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,469] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,471] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,472] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,474] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,475] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,477] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,479] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,481] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,482] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,485] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,486] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,488] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,489] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,491] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,493] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,495] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,496] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,498] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,500] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,504] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,505] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,507] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,508] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,510] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,511] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,512] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,513] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,514] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,517] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,518] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,519] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,521] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,522] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,523] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,524] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,526] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,527] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,528] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,529] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,532] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,533] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,535] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,535] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,537] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,538] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,539] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,540] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,541] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,542] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,544] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:04:22,544] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,546] INFO Loaded 51 logs in 236ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,546] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,547] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:04:22,824] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:04:22,827] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:04:22,858] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:04:22,859] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:04:22,859] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:04:22,864] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:04:22,890] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:04:22,904] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,905] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,905] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,906] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:22,918] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:04:22,952] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:04:22,964] INFO Stat of the created znode at /brokers/ids/1001 is: 255,255,1706094262959,1706094262959,1,0,0,72058420588380161,237,0,255
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:04:22,965] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 255 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:04:23,024] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:23,031] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:23,032] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:23,044] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,055] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,080] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-24 11:04:23,080] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,083] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-24 11:04:23,084] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,114] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:04:23,141] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-24 11:04:23,161] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:04:23,164] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:04:23,169] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:04:23,169] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:04:23,177] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:04:23,178] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:04:23,178] INFO Kafka startTimeMs: 1706094263169 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:04:23,179] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:04:23,200] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:04:23,232] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, coordinates-0, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:04:23,237] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,241] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,242] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,243] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,243] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 1786 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,244] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,244] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,245] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,246] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,247] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,247] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,248] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,249] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,250] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,251] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,251] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,252] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,253] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,254] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,255] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,256] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,256] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,257] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,258] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,259] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,259] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,260] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,261] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,262] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,263] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,263] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,264] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,265] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,266] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,267] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,268] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,270] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,271] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,272] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,272] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 141 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,273] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,273] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,274] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,275] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,276] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,276] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,277] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,278] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,279] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,280] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,281] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:04:23,285] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,286] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,287] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,288] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,289] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,289] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,292] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,292] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,292] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,292] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,293] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 6 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,293] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,293] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,293] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,293] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,293] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,293] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,294] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,295] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,296] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,297] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,297] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,314] INFO Loaded member MemberMetadata(memberId=rdkafka-25c8d075-d354-4891-8ab9-6c285035751e, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 1. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 11:04:23,319] INFO Loaded member MemberMetadata(memberId=rdkafka-70f9fa21-70b9-431f-8ddb-e627d77cd73c, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 4. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 11:04:23,320] INFO Loaded member MemberMetadata(memberId=rdkafka-20334c10-f900-42d7-8b25-e110938a58b8, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 7. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 11:04:23,323] INFO [GroupCoordinator 1001]: Loading group metadata for web_consumer_group with generation 7 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:04:23,326] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 38 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,326] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,326] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,326] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 39 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,327] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:04:23,492] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 7 (__consumer_offsets-35) (reason: Adding new member rdkafka-6dc27e33-a0dc-49fc-9014-1579186e6e2d with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-24 11:04:51,677] INFO Unable to read additional data from server sessionid 0x10000c0723f0001, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:04:52,904] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:04:53,512] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:04:54,613] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:04:55,575] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:04:56,676] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:04:57,157] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:04:58,258] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:04:59,155] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:00,256] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:05:00,901] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:02,003] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:05:02,023] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:02,247] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:05:02,248] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:02,249] INFO [KafkaServer id=1001] Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:03,260] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:05:03,549] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:03,652] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:04,652] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:05:05,311] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:06,412] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:05:07,234] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:08,330] INFO [GroupCoordinator 1001]: Member rdkafka-20334c10-f900-42d7-8b25-e110938a58b8 in group web_consumer_group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:08,335] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:05:08,339] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 8 (__consumer_offsets-35) with 5 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:08,345] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-6dc27e33-a0dc-49fc-9014-1579186e6e2d] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:08,347] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 8 (__consumer_offsets-35) (reason: removing member rdkafka-6dc27e33-a0dc-49fc-9014-1579186e6e2d on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:08,348] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-2e53aed6-8502-4524-afb8-78096da09134] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:08,348] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-954e182d-29a6-45c4-abbe-257c8e568bb2] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:08,349] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-7bec4bf7-061a-4060-861e-16edfd1235a3] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:09,120] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:10,221] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:05:10,901] WARN Session 0x10000c0723f0001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:05:12,002] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 11:05:24,050] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 11:05:24,394] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 11:05:24,478] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:05:24,481] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:24,481] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:24,501] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:24,506] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,506] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,506] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,506] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,506] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,506] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,507] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,509] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:24,513] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 11:05:24,518] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:24,521] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:24,525] INFO Opening socket connection to server zookeeper/172.0.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:24,529] INFO Socket connection established, initiating session, client: /172.0.0.5:52796, server: zookeeper/172.0.0.2:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:24,543] INFO Session establishment complete on server zookeeper/172.0.0.2:2181, sessionid = 0x10000c45c0c0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:24,547] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:24,627] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:05:24,755] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 11:05:24,763] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:24,832] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:05:24,844] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:05:24,894] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:24,898] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:24,903] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:24,907] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:24,977] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:24,980] INFO Attempting recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,046] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,048] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,075] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,083] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 94ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,086] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,086] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,089] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,093] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,094] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,095] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,097] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,099] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,101] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,101] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,103] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,105] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,107] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,107] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,110] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,114] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,116] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,117] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,119] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,122] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,125] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,125] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,128] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,133] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,137] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,137] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,140] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,144] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,146] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,147] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,150] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,157] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,159] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,160] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,181] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 141 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:05:25,195] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 141 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,197] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000141.snapshot,141)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:05:25,204] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=141) with 1 segments in 47ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,206] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,206] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,208] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,210] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,212] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,212] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,216] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,219] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,221] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,221] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,224] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,227] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,230] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,230] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,233] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,235] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,237] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,237] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,244] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,246] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,249] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,250] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,253] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,255] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,257] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,257] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,259] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,261] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,264] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,264] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,267] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,269] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,271] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,272] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,275] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,278] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,281] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,281] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,285] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,288] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,290] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,290] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,292] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,294] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,296] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,297] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,330] INFO [ProducerStateManager partition=coordinates-0] Writing producer snapshot at offset 1852 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:05:25,340] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 1852 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,341] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000001852.snapshot,1852)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:05:25,342] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1852) with 1 segments in 48ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,345] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,346] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,350] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,354] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,358] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,358] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,361] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,364] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,366] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,367] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,370] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,372] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,375] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,375] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,378] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,380] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,382] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,382] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,385] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,387] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,389] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,389] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,394] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,396] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,398] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,398] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,401] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,403] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,406] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,406] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,408] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,411] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,413] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,414] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,417] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,420] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,424] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,424] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,427] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,428] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,432] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,432] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,435] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,440] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,442] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,443] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,445] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,447] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,449] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,449] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,455] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,457] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,460] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,461] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,464] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,465] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,468] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,468] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,470] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,472] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,473] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,474] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,476] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,477] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,479] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,479] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,481] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,482] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,485] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,485] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,488] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,489] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,491] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,491] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,493] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,494] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,495] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,496] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,498] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,499] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,501] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,501] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,503] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,506] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,508] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,508] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,513] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,516] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,518] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,518] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,520] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,521] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,523] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,524] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,526] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,527] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,530] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,530] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,534] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,536] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,538] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,538] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,540] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,542] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,544] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,544] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,548] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,549] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,551] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,551] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,552] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,553] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,554] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,555] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,557] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:25,570] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,572] INFO Loaded 51 logs in 595ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,573] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,574] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:25,956] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:05:25,961] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:05:26,025] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:26,026] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:05:26,026] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:05:26,036] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:26,073] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:05:26,097] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,099] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,100] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,106] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,125] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:05:26,225] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:05:26,289] ERROR Error while creating ephemeral at /brokers/ids/1001, node already exists and owner '72058420588380161' does not match current session '72058437395808256' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[32mkafka              |[0m [2024-01-24 11:05:26,298] ERROR [KafkaServer id=1001] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
[32mkafka              |[0m 	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
[32mkafka              |[0m 	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
[32mkafka              |[0m 	at kafka.Kafka$.main(Kafka.scala:109)
[32mkafka              |[0m 	at kafka.Kafka.main(Kafka.scala)
[32mkafka              |[0m [2024-01-24 11:05:26,304] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:26,305] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopping socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:26,311] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopped socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:26,319] INFO [ReplicaManager broker=1001] Shutting down (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 11:05:26,320] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:05:26,322] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:05:26,322] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:05:26,323] INFO [ReplicaFetcherManager on broker 1001] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:05:26,324] INFO [ReplicaFetcherManager on broker 1001] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:05:26,324] INFO [ReplicaAlterLogDirsManager on broker 1001] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 11:05:26,325] INFO [ReplicaAlterLogDirsManager on broker 1001] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 11:05:26,325] INFO [ExpirationReaper-1001-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,503] INFO [ExpirationReaper-1001-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,503] INFO [ExpirationReaper-1001-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,504] INFO [ExpirationReaper-1001-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,701] INFO [ExpirationReaper-1001-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,701] INFO [ExpirationReaper-1001-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,702] INFO [ExpirationReaper-1001-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,901] INFO [ExpirationReaper-1001-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,901] INFO [ExpirationReaper-1001-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,902] INFO [ExpirationReaper-1001-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,907] INFO [ExpirationReaper-1001-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,907] INFO [ExpirationReaper-1001-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:26,912] INFO [ReplicaManager broker=1001] Shut down completely (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 11:05:26,912] INFO [broker-1001-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:05:26,912] INFO [broker-1001-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:05:26,912] INFO [broker-1001-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:05:26,923] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[32mkafka              |[0m [2024-01-24 11:05:26,924] INFO Shutting down. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:26,974] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:26,974] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:05:26,975] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:05:26,975] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:05:26,975] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:27,080] INFO Session: 0x10000c45c0c0000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:27,080] INFO EventThread shut down for session: 0x10000c45c0c0000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:27,082] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:27,082] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,896] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,896] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,896] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,900] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,900] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,900] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,903] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,903] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,904] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,908] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,908] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:27,909] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutting down socket server (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:27,930] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutdown completed (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:27,930] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:05:27,931] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:05:27,931] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:05:27,933] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[32mkafka              |[0m [2024-01-24 11:05:27,938] INFO App info kafka.server for 1001 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:05:27,938] INFO [KafkaServer id=1001] shut down completed (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:27,938] ERROR Exiting Kafka. (kafka.Kafka$)
[32mkafka              |[0m [2024-01-24 11:05:27,939] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 11:05:48,028] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 11:05:48,445] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 11:05:48,525] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:05:48,528] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:48,528] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:48,543] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,549] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,552] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:05:48,556] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 11:05:48,562] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:48,564] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:48,574] INFO Opening socket connection to server zookeeper/172.0.0.5:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:48,579] INFO Socket connection established, initiating session, client: /172.0.0.4:45936, server: zookeeper/172.0.0.5:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:48,598] INFO Session establishment complete on server zookeeper/172.0.0.5:2181, sessionid = 0x10000c4bbaf0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:05:48,602] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:05:48,707] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:05:48,832] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 11:05:48,837] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:48,891] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:05:48,900] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:05:48,937] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:48,938] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:48,940] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:48,942] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:05:49,031] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,035] INFO Skipping recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,131] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,139] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,142] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,144] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,147] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,149] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,151] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,158] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,161] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,163] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,164] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,166] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,168] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,170] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,172] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,174] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,176] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,179] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,204] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 141 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,206] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000141.snapshot,141)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:05:49,220] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=141) with 1 segments in 41ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,224] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,226] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,228] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,231] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,233] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,235] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,237] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,238] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,240] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,242] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,244] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,246] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,248] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,250] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,253] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,255] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,257] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,259] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,262] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,264] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,267] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,270] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,274] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 1852 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,274] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000001852.snapshot,1852)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:05:49,276] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1852) with 1 segments in 6ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,278] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,279] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,283] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,285] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,288] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,290] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,292] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,293] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,295] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,298] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,302] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,303] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,306] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,308] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,310] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,312] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,314] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,315] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,319] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,321] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,323] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,325] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,327] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,329] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,332] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,333] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,336] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,337] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,339] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,341] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,343] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,344] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,346] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,348] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,350] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,352] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,354] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,356] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,358] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,360] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,363] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,366] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,369] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,370] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,373] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,374] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,376] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,377] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,379] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,380] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,383] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,385] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,387] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,389] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,391] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,392] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,395] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:05:49,396] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,399] INFO Loaded 51 logs in 368ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,399] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,400] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:05:49,863] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:05:49,868] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:05:49,967] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:49,969] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:05:49,970] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:05:49,981] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:50,061] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:05:50,100] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,103] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,105] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,111] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,127] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:05:50,193] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:05:50,221] INFO Stat of the created znode at /brokers/ids/1001 is: 294,294,1706094350208,1706094350208,1,0,0,72058439000326144,237,0,294
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:05:50,222] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 294 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:05:50,287] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,291] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,292] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,313] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,330] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,364] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-24 11:05:50,366] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,375] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,382] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-24 11:05:50,431] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:05:50,523] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-24 11:05:50,558] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:50,572] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:50,582] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:50,582] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:05:50,603] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:05:50,603] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:05:50,603] INFO Kafka startTimeMs: 1706094350582 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:05:50,605] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:05:50,686] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:05:50,709] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, coordinates-0, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:05:50,718] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,724] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,725] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,727] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,729] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 1852 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,730] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,732] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,734] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,736] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,739] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,740] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,742] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,744] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,746] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,748] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,749] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,750] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,752] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,753] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,755] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,758] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,760] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,762] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,764] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,769] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,771] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,775] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,776] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,777] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,779] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,781] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,783] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,785] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,786] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,788] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,790] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,792] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,799] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,801] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,804] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 141 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,806] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,809] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,810] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,812] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,815] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,816] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,817] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,819] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,821] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,822] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,823] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 11:05:50,833] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,835] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,849] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 12 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,851] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,851] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,852] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,852] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,852] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,853] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,853] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,853] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,853] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,854] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,854] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,854] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,854] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,855] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,855] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,855] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,855] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,855] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,856] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,863] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,864] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,864] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,864] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,864] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,866] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,866] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,866] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,866] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,902] INFO Loaded member MemberMetadata(memberId=rdkafka-25c8d075-d354-4891-8ab9-6c285035751e, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 1. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 11:05:50,911] INFO Loaded member MemberMetadata(memberId=rdkafka-70f9fa21-70b9-431f-8ddb-e627d77cd73c, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 4. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 11:05:50,912] INFO Loaded member MemberMetadata(memberId=rdkafka-20334c10-f900-42d7-8b25-e110938a58b8, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 7. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 11:05:50,917] INFO [GroupCoordinator 1001]: Loading group metadata for web_consumer_group with generation 7 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:05:50,922] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 78 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 77 milliseconds for epoch 0, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,923] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,924] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,924] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:50,924] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 11:05:53,650] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 7 (__consumer_offsets-35) (reason: Adding new member rdkafka-72a4e152-2a35-48ae-9654-1d1fac243ac1 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-24 11:06:35,927] INFO [GroupCoordinator 1001]: Member rdkafka-20334c10-f900-42d7-8b25-e110938a58b8 in group web_consumer_group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,935] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 8 (__consumer_offsets-35) with 7 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,946] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-830cd2b7-ea13-49e8-86ff-5ec78e46b6a8] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,947] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 8 (__consumer_offsets-35) (reason: removing member rdkafka-830cd2b7-ea13-49e8-86ff-5ec78e46b6a8 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,948] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-4cc40fd3-8fd0-4612-8779-a03ae2afe033] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,949] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-02959bd2-b430-451c-9ff3-911cfa6a1b68] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,949] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-722c47af-4617-4ef3-90fa-c1a6f7372eeb] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,950] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-72a4e152-2a35-48ae-9654-1d1fac243ac1] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:35,950] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-2d02f6ac-4c38-446a-9c2f-69c04fdc705a] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:36,674] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-5b8db6d9-8c42-464b-987f-3f409c3dfa18] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:36,675] INFO [GroupCoordinator 1001]: Group web_consumer_group with generation 9 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:37,716] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 9 (__consumer_offsets-35) (reason: Adding new member rdkafka-21d424a9-698c-4806-978c-5a59e17c9281 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:37,719] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 10 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:06:37,723] INFO [GroupCoordinator 1001]: Assignment received from leader for group web_consumer_group for generation 10. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 11:10:25,903] INFO Unable to read additional data from server sessionid 0x10000c4bbaf0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:10:27,166] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:27,255] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:28,356] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:28,510] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:29,611] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:30,432] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:31,532] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:32,069] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:33,170] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:34,085] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:35,185] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:35,695] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:36,541] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:10:36,543] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:10:36,544] INFO [KafkaServer id=1001] Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:10:36,796] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:37,460] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:37,561] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:10:38,759] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:39,624] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:40,725] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:41,418] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:42,519] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:43,145] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:44,246] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:44,666] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-24 11:10:45,767] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-24 11:10:46,060] WARN Session 0x10000c4bbaf0000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 11:11:41,591] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 11:11:41,994] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 11:11:42,096] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 11:11:42,099] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:11:42,099] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:11:42,117] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,122] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,123] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,125] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:42,129] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 11:11:42,135] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:11:42,137] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:11:42,141] INFO Opening socket connection to server zookeeper/172.0.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:11:42,146] INFO Socket connection established, initiating session, client: /172.0.0.4:43104, server: zookeeper/172.0.0.3:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:11:42,161] INFO Session establishment complete on server zookeeper/172.0.0.3:2181, sessionid = 0x10000ca20980000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:11:42,165] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:11:42,249] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:11:42,458] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 11:11:42,473] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:11:42,530] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:11:42,537] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 11:11:42,588] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:42,590] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:42,592] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:42,593] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:42,670] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,675] INFO Attempting recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,739] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,740] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,774] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,786] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 101ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,789] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,789] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,791] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,795] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,797] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,798] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,801] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,805] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,808] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,810] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,815] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,818] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,822] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,822] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,824] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,827] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,828] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,828] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,831] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,834] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,836] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,836] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,839] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,842] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,847] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,847] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,850] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,852] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,853] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,854] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,856] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,858] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,861] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,862] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,881] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 188 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:11:42,895] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 188 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,897] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000188.snapshot,188)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:11:42,903] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=188) with 1 segments in 45ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,905] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,906] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,908] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,910] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,912] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,912] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,915] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,917] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,919] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,919] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,923] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,926] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,928] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,928] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,930] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,932] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,934] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,935] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,937] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,939] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,941] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,941] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,943] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,946] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,948] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,948] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,950] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,952] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,955] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,956] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,959] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,961] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,964] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,964] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,967] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,968] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,971] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,971] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,973] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,975] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,977] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,978] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,980] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,983] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:42,986] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:42,987] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,030] INFO [ProducerStateManager partition=coordinates-0] Writing producer snapshot at offset 2411 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:11:43,034] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 2411 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,034] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000002411.snapshot,2411)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 11:11:43,036] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2411) with 1 segments in 53ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,038] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,039] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,041] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,043] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,045] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,046] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,049] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,052] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,054] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,055] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,057] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,059] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,062] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,063] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,067] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,070] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,072] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,072] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,074] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,076] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,083] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,084] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,087] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,090] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,092] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,093] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,098] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,101] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,105] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,105] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,108] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,110] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,112] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,112] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,114] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,116] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,118] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,119] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,121] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,122] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,124] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,125] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,128] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,130] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,132] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,132] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,135] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,136] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,137] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,137] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,139] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,140] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,142] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,142] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,145] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,146] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,147] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,148] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,150] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,151] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,154] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,155] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,157] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,158] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,160] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,160] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,162] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,163] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,164] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,164] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,166] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,167] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,169] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,169] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,171] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,172] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,174] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,174] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,176] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,178] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,180] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,180] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,182] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,183] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,184] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,184] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,187] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,188] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,190] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,190] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,193] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,194] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,196] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,196] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,198] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,200] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,201] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,202] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,203] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,205] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,206] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,206] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,208] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,209] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,210] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,210] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,212] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,213] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,215] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,215] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,217] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,218] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,220] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,220] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,222] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 11:11:43,223] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,225] INFO Loaded 51 logs in 554ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,226] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,226] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:43,628] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:11:43,635] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:11:43,716] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:11:43,721] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 11:11:43,722] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 11:11:43,732] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:11:43,779] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:11:43,804] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:43,807] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:43,806] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:43,815] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:43,847] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:11:43,947] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 11:11:43,981] ERROR Error while creating ephemeral at /brokers/ids/1001, node already exists and owner '72058439000326144' does not match current session '72058462168154112' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[32mkafka              |[0m [2024-01-24 11:11:43,989] ERROR [KafkaServer id=1001] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
[32mkafka              |[0m 	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
[32mkafka              |[0m 	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
[32mkafka              |[0m 	at kafka.Kafka$.main(Kafka.scala:109)
[32mkafka              |[0m 	at kafka.Kafka.main(Kafka.scala)
[32mkafka              |[0m [2024-01-24 11:11:43,992] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:11:43,994] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopping socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:11:44,001] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopped socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:11:44,015] INFO [ReplicaManager broker=1001] Shutting down (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 11:11:44,016] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:11:44,016] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:11:44,016] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 11:11:44,017] INFO [ReplicaFetcherManager on broker 1001] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:11:44,018] INFO [ReplicaFetcherManager on broker 1001] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 11:11:44,019] INFO [ReplicaAlterLogDirsManager on broker 1001] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 11:11:44,019] INFO [ReplicaAlterLogDirsManager on broker 1001] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-24 11:11:44,019] INFO [ExpirationReaper-1001-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,210] INFO [ExpirationReaper-1001-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,210] INFO [ExpirationReaper-1001-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,211] INFO [ExpirationReaper-1001-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,410] INFO [ExpirationReaper-1001-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,410] INFO [ExpirationReaper-1001-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,411] INFO [ExpirationReaper-1001-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,411] INFO [ExpirationReaper-1001-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,411] INFO [ExpirationReaper-1001-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,411] INFO [ExpirationReaper-1001-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,419] INFO [ExpirationReaper-1001-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,419] INFO [ExpirationReaper-1001-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,429] INFO [ReplicaManager broker=1001] Shut down completely (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-24 11:11:44,429] INFO [broker-1001-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:11:44,430] INFO [broker-1001-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:11:44,430] INFO [broker-1001-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 11:11:44,435] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[32mkafka              |[0m [2024-01-24 11:11:44,436] INFO Shutting down. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:44,469] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 11:11:44,470] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:11:44,470] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:11:44,470] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 11:11:44,471] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:11:44,576] INFO Session: 0x10000ca20980000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 11:11:44,576] INFO EventThread shut down for session: 0x10000ca20980000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 11:11:44,577] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 11:11:44,577] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,591] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,591] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:44,591] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:45,590] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:45,590] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:45,591] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:45,595] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:45,595] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:45,595] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:46,595] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:46,595] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 11:11:46,597] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutting down socket server (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:11:46,621] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutdown completed (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 11:11:46,621] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:11:46,622] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:11:46,622] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-24 11:11:46,624] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[32mkafka              |[0m [2024-01-24 11:11:46,631] INFO App info kafka.server for 1001 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 11:11:46,631] INFO [KafkaServer id=1001] shut down completed (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 11:11:46,631] ERROR Exiting Kafka. (kafka.Kafka$)
[32mkafka              |[0m [2024-01-24 11:11:46,632] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-24 12:24:03,877] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-24 12:24:04,308] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-24 12:24:04,495] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-24 12:24:04,502] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 12:24:04,503] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 12:24:04,521] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:host.name=bc369d30dc03 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,526] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,529] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2205a05d (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-24 12:24:04,537] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-24 12:24:04,543] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 12:24:04,546] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 12:24:04,555] INFO Opening socket connection to server zookeeper/172.0.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 12:24:04,559] INFO Socket connection established, initiating session, client: /172.0.0.5:43444, server: zookeeper/172.0.0.3:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 12:24:04,576] INFO Session establishment complete on server zookeeper/172.0.0.3:2181, sessionid = 0x100010c5e840000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-24 12:24:04,579] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-24 12:24:04,665] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-24 12:24:04,822] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-24 12:24:04,826] INFO Cluster ID = MbiKeuBYR0-MqxHbhObjGQ (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 12:24:04,884] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 12:24:04,902] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-bc369d30dc03
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-24 12:24:04,969] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 12:24:04,977] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 12:24:04,987] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 12:24:04,987] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-24 12:24:05,080] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,089] INFO Skipping recovery for all logs in /kafka/kafka-logs-bc369d30dc03 since clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,190] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,201] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 99ms (1/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,204] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,208] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (2/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,211] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,213] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (3/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,217] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,223] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,225] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,227] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (5/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,229] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,231] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (6/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,235] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,239] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,242] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,244] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (8/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,246] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,252] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,274] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 188 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,276] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35/00000000000000000188.snapshot,188)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 12:24:05,290] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=188) with 1 segments in 38ms (10/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,293] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,295] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,298] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,301] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (12/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,304] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,307] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (13/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,312] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,315] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (14/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,319] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,322] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (15/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,326] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,329] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (16/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,332] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,335] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (17/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,339] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,342] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (18/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,345] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,347] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (19/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,351] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,354] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (20/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,358] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,360] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (21/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,367] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 2411 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,367] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-bc369d30dc03/coordinates-0/00000000000000002411.snapshot,2411)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-24 12:24:05,369] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2411) with 1 segments in 8ms (22/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,373] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,375] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (23/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,378] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,379] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (24/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,382] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,385] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (25/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,388] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,390] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (26/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,392] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,394] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (27/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,396] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,397] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (28/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,402] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,404] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (29/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,407] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,409] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (30/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,411] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,412] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (31/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,416] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,418] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (32/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,421] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,423] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (33/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,426] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,427] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (34/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,429] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,430] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (35/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,435] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,437] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (36/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,441] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,445] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (37/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,449] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,451] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (38/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,455] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,457] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (39/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,460] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,462] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (40/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,464] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,467] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (41/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,470] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,472] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (42/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,475] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,476] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (43/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,479] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,480] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (44/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,484] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,485] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (45/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,489] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,491] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (46/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,494] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,495] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (47/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,498] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,501] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (48/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,505] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,507] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (49/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,509] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,511] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (50/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,513] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bc369d30dc03] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-24 12:24:05,514] INFO Completed load of Log(dir=/kafka/kafka-logs-bc369d30dc03/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (51/51 loaded in /kafka/kafka-logs-bc369d30dc03) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,518] INFO Loaded 51 logs in 438ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,520] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,520] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-24 12:24:05,945] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 12:24:05,951] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 12:24:06,009] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 12:24:06,010] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-24 12:24:06,011] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-24 12:24:06,023] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 12:24:06,064] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 12:24:06,090] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,091] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,092] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,092] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,138] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-24 12:24:06,203] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 12:24:06,223] INFO Stat of the created znode at /brokers/ids/1001 is: 333,333,1706099046216,1706099046216,1,0,0,72058746674872320,237,0,333
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 12:24:06,223] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 333 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-24 12:24:06,303] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,310] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,310] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,338] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,355] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,393] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-24 12:24:06,394] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,397] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,402] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-24 12:24:06,462] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-24 12:24:06,495] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-24 12:24:06,525] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 12:24:06,541] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 12:24:06,555] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 12:24:06,556] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-24 12:24:06,562] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 12:24:06,562] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 12:24:06,562] INFO Kafka startTimeMs: 1706099046556 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-24 12:24:06,563] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-24 12:24:06,677] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, coordinates-0, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-24 12:24:06,687] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-24 12:24:06,702] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,712] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,713] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,716] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,719] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 2411 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,719] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,721] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,723] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,724] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,726] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,728] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,729] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,732] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,734] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,737] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,740] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,741] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,743] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,744] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,746] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,748] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,750] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,752] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,754] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,756] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,757] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,759] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,760] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,762] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,764] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,767] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,769] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,772] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,774] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,776] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,778] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,782] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,786] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,789] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,791] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 188 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,791] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,792] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,793] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,794] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,795] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,796] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,798] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,803] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,806] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,808] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,811] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-24 12:24:06,829] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,832] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,838] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,838] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,838] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,839] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,841] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,841] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,842] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,843] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,844] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,845] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,846] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,847] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,847] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,847] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,847] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,847] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,849] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,849] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,855] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 13 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,859] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,859] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,859] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,859] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,859] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,859] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,859] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,860] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 16 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,860] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,860] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,860] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,860] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,903] INFO Loaded member MemberMetadata(memberId=rdkafka-25c8d075-d354-4891-8ab9-6c285035751e, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 1. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 12:24:06,916] INFO Loaded member MemberMetadata(memberId=rdkafka-70f9fa21-70b9-431f-8ddb-e627d77cd73c, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 4. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 12:24:06,916] INFO Loaded member MemberMetadata(memberId=rdkafka-20334c10-f900-42d7-8b25-e110938a58b8, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 7. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 12:24:06,923] INFO Loaded member MemberMetadata(memberId=rdkafka-21d424a9-698c-4806-978c-5a59e17c9281, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 10. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-24 12:24:06,931] INFO [GroupCoordinator 1001]: Loading group metadata for web_consumer_group with generation 10 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:06,946] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 101 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 102 milliseconds for epoch 0, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,947] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 102 milliseconds for epoch 0, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 103 milliseconds for epoch 0, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 103 milliseconds for epoch 0, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 103 milliseconds for epoch 0, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 103 milliseconds for epoch 0, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 103 milliseconds for epoch 0, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 103 milliseconds for epoch 0, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,948] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 103 milliseconds for epoch 0, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,949] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 104 milliseconds for epoch 0, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-24 12:24:06,949] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 104 milliseconds for epoch 0, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-24 12:24:11,651] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 10 (__consumer_offsets-35) (reason: Adding new member rdkafka-abfbea29-798c-437e-a24b-03b21524cb78 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:51,949] INFO [GroupCoordinator 1001]: Member rdkafka-21d424a9-698c-4806-978c-5a59e17c9281 in group web_consumer_group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:51,967] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 11 (__consumer_offsets-35) with 2 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:51,976] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-0d597165-7bdd-4b94-81ec-836bdec6f16d] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:51,977] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 11 (__consumer_offsets-35) (reason: removing member rdkafka-0d597165-7bdd-4b94-81ec-836bdec6f16d on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:51,979] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-abfbea29-798c-437e-a24b-03b21524cb78] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-24 12:24:51,980] INFO [GroupCoordinator 1001]: Group web_consumer_group with generation 12 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
