Attaching to fastapi, kafka-producer, kafka-producer2, kafka, database, kafka-ui, zookeeper
[36mdatabase           |[0m The files belonging to this database system will be owned by user "postgres".
[36mdatabase           |[0m This user must also own the server process.
[36mdatabase           |[0m 
[36mdatabase           |[0m The database cluster will be initialized with locale "en_US.utf8".
[36mdatabase           |[0m The default database encoding has accordingly been set to "UTF8".
[36mdatabase           |[0m The default text search configuration will be set to "english".
[36mdatabase           |[0m 
[36mdatabase           |[0m Data page checksums are disabled.
[36mdatabase           |[0m 
[36mdatabase           |[0m fixing permissions on existing directory /var/lib/postgresql/data ... ok
[36mdatabase           |[0m creating subdirectories ... ok
[36mdatabase           |[0m selecting dynamic shared memory implementation ... posix
[36mdatabase           |[0m selecting default max_connections ... 100
[36mdatabase           |[0m selecting default shared_buffers ... 128MB
[36mdatabase           |[0m selecting default time zone ... Etc/UTC
[36mdatabase           |[0m creating configuration files ... ok
[36mdatabase           |[0m running bootstrap script ... ok
[36mdatabase           |[0m performing post-bootstrap initialization ... ok
[36mdatabase           |[0m syncing data to disk ... ok
[36mdatabase           |[0m 
[36mdatabase           |[0m initdb: warning: enabling "trust" authentication for local connections
[36mdatabase           |[0m initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
[36mdatabase           |[0m 
[36mdatabase           |[0m Success. You can now start the database server using:
[36mdatabase           |[0m 
[36mdatabase           |[0m     pg_ctl -D /var/lib/postgresql/data -l logfile start
[36mdatabase           |[0m 
[36mdatabase           |[0m waiting for server to start....2024-01-17 13:50:12.686 UTC [49] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-17 13:50:12.687 UTC [49] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-17 13:50:12.691 UTC [52] LOG:  database system was shut down at 2024-01-17 13:50:12 UTC
[36mdatabase           |[0m 2024-01-17 13:50:12.701 UTC [49] LOG:  database system is ready to accept connections
[36mdatabase           |[0m  done
[36mdatabase           |[0m server started
[36mdatabase           |[0m CREATE DATABASE
[36mdatabase           |[0m 
[36mdatabase           |[0m 
[36mdatabase           |[0m /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init.sql
[36mdatabase           |[0m You are now connected to database "pg" as user "pg".
[36mdatabase           |[0m CREATE TABLE
[36mdatabase           |[0m 
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-17 13:50:12.985 UTC [49] LOG:  received fast shutdown request
[36mdatabase           |[0m waiting for server to shut down....2024-01-17 13:50:12.986 UTC [49] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-17 13:50:12.992 UTC [49] LOG:  background worker "logical replication launcher" (PID 55) exited with exit code 1
[36mdatabase           |[0m 2024-01-17 13:50:12.993 UTC [50] LOG:  shutting down
[36mdatabase           |[0m 2024-01-17 13:50:12.994 UTC [50] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-17 13:50:13.028 UTC [50] LOG:  checkpoint complete: wrote 923 buffers (5.6%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.014 s, sync=0.016 s, total=0.035 s; sync files=302, longest=0.004 s, average=0.001 s; distance=4262 kB, estimate=4262 kB; lsn=0/1914480, redo lsn=0/1914480
[36mdatabase           |[0m 2024-01-17 13:50:13.035 UTC [49] LOG:  database system is shut down
[36mdatabase           |[0m  done
[36mdatabase           |[0m server stopped
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL init process complete; ready for start up.
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-17 13:50:13.104 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-17 13:50:13.104 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-17 13:50:13.104 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-17 13:50:13.106 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-17 13:50:13.110 UTC [68] LOG:  database system was shut down at 2024-01-17 13:50:13 UTC
[36mdatabase           |[0m 2024-01-17 13:50:13.114 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-17 13:53:42.189 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-17 13:53:42.190 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-17 13:53:42.191 UTC [1] LOG:  background worker "logical replication launcher" (PID 71) exited with exit code 1
[36mdatabase           |[0m 2024-01-17 13:53:42.193 UTC [66] LOG:  shutting down
[36mdatabase           |[0m 2024-01-17 13:53:42.194 UTC [66] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-17 13:53:42.199 UTC [66] LOG:  checkpoint complete: wrote 47 buffers (0.3%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.002 s, total=0.007 s; sync files=14, longest=0.001 s, average=0.001 s; distance=261 kB, estimate=261 kB; lsn=0/1955C60, redo lsn=0/1955C60
[36mdatabase           |[0m 2024-01-17 13:53:42.205 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-17 13:54:22.542 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-17 13:54:22.545 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-17 13:54:22.545 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-17 13:54:22.546 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-17 13:54:22.551 UTC [28] LOG:  database system was shut down at 2024-01-17 13:53:42 UTC
[36mdatabase           |[0m 2024-01-17 13:54:22.556 UTC [1] LOG:  database system is ready to accept connections
[36mdatabase           |[0m 2024-01-17 13:55:00.599 UTC [5731] LOG:  could not receive data from client: Connection reset by peer
[36mdatabase           |[0m 2024-01-17 13:55:00.599 UTC [5731] LOG:  unexpected EOF on client connection with an open transaction
[36mdatabase           |[0m 2024-01-17 13:55:01.034 UTC [1] LOG:  received fast shutdown request
[36mdatabase           |[0m 2024-01-17 13:55:01.035 UTC [1] LOG:  aborting any active transactions
[36mdatabase           |[0m 2024-01-17 13:55:01.036 UTC [1] LOG:  background worker "logical replication launcher" (PID 31) exited with exit code 1
[36mdatabase           |[0m 2024-01-17 13:55:01.038 UTC [26] LOG:  shutting down
[36mdatabase           |[0m 2024-01-17 13:55:01.039 UTC [26] LOG:  checkpoint starting: shutdown immediate
[36mdatabase           |[0m 2024-01-17 13:55:01.044 UTC [26] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.001 s, total=0.006 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/1955D10, redo lsn=0/1955D10
[36mdatabase           |[0m 2024-01-17 13:55:01.048 UTC [1] LOG:  database system is shut down
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-17 13:58:35.107 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-17 13:58:35.112 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-17 13:58:35.112 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-17 13:58:35.115 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-17 13:58:35.119 UTC [28] LOG:  database system was shut down at 2024-01-17 13:55:01 UTC
[36mdatabase           |[0m 2024-01-17 13:58:35.124 UTC [1] LOG:  database system is ready to accept connections
[33mfastapi            |[0m INFO:     Started server process [1]
[33mfastapi            |[0m INFO:     Waiting for application startup.
[33mfastapi            |[0m INFO:     Application startup complete.
[33mfastapi            |[0m INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
[33mfastapi            |[0m INFO:     ('172.0.0.1', 46082) - "WebSocket /ws" [accepted]
[33mfastapi            |[0m /app/main.py:120: RuntimeWarning: coroutine 'push_message' was never awaited
[33mfastapi            |[0m   _ = push_message()
[33mfastapi            |[0m RuntimeWarning: Enable tracemalloc to get the object allocation traceback
[33mfastapi            |[0m INFO:     connection open
[33mfastapi            |[0m ERROR:    Exception in ASGI application
[33mfastapi            |[0m Traceback (most recent call last):
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 254, in run_asgi
[33mfastapi            |[0m     result = await self.app(self.scope, self.asgi_receive, self.asgi_send)
[33mfastapi            |[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[33mfastapi            |[0m     return await self.app(scope, receive, send)
[33mfastapi            |[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/applications.py", line 1054, in __call__
[33mfastapi            |[0m     await super().__call__(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/applications.py", line 123, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/errors.py", line 151, in __call__
[33mfastapi            |[0m     await self.app(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[33mfastapi            |[0m     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 762, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 782, in app
[33mfastapi            |[0m     await route.handle(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 373, in handle
[33mfastapi            |[0m     await self.app(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 96, in app
[33mfastapi            |[0m     await wrap_app_handling_exceptions(app, session)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 94, in app
[33mfastapi            |[0m     await func(session)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/routing.py", line 360, in app
[33mfastapi            |[0m     await dependant.call(**values)
[33mfastapi            |[0m   File "/app/main.py", line 121, in websocket_endpoint
[33mfastapi            |[0m     await websocket.send_text(get_messages())
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/websockets.py", line 163, in send_text
[33mfastapi            |[0m     await self.send({"type": "websocket.send", "text": data})
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
[33mfastapi            |[0m     await self._send(message)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 50, in sender
[33mfastapi            |[0m     await send(message)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 344, in asgi_send
[33mfastapi            |[0m     await self.send(data)  # type: ignore[arg-type]
[33mfastapi            |[0m     ^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/websockets/legacy/protocol.py", line 665, in send
[33mfastapi            |[0m     opcode, data = prepare_data(fragment)
[33mfastapi            |[0m                    ^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/websockets/frames.py", line 371, in prepare_data
[33mfastapi            |[0m     raise TypeError("data must be str or bytes-like")
[33mfastapi            |[0m TypeError: data must be str or bytes-like
[33mfastapi            |[0m /usr/local/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:263: RuntimeWarning: coroutine 'push_message' was never awaited
[33mfastapi            |[0m   self.transport.close()
[33mfastapi            |[0m RuntimeWarning: Enable tracemalloc to get the object allocation traceback
[33mfastapi            |[0m INFO:     connection closed
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-17 13:50:12,888] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-17 13:50:13,232] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-17 13:50:13,307] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-17 13:50:13,310] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:50:13,311] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:50:13,326] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:host.name=a22cb18788de (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,330] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,331] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,331] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,331] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,332] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:50:13,336] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-17 13:50:13,340] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:50:13,342] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:50:13,348] INFO Opening socket connection to server zookeeper/172.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:50:13,353] INFO Socket connection established, initiating session, client: /172.0.0.3:55898, server: zookeeper/172.0.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:50:13,371] INFO Session establishment complete on server zookeeper/172.0.0.4:2181, sessionid = 0x100010180820000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:50:13,373] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:50:13,460] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-17 13:50:13,472] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[32mkafka              |[0m [2024-01-17 13:50:13,473] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-17 13:50:13,626] INFO Cluster ID = yNWr-cskTIiqrCUaiLRWZw (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:50:13,631] WARN No meta.properties file under dir /kafka/kafka-logs-a22cb18788de/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[32mkafka              |[0m [2024-01-17 13:50:13,703] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-a22cb18788de
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[35mkafka-producer     |[0m %3|1705499412.012|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[35mkafka-producer     |[0m %3|1705499413.019|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1705499662.919|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 4ms in state CONNECT)
[35mkafka-producer     |[0m %3|1705499663.914|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %6|1705499666.708|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 793ms in state APIVERSION_QUERY)
[35mkafka-producer     |[0m %3|1705499666.933|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 75ms in state CONNECT)
[35mkafka-producer     |[0m %3|1705499695.011|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 96ms in state CONNECT, 14 identical error(s) suppressed)
[35mkafka-producer     |[0m %3|1705499915.642|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[35mkafka-producer     |[0m %3|1705499916.641|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1705499411.944|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1705499412.943|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1705499662.837|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 13ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1705499663.823|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %6|1705499666.708|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 885ms in state APIVERSION_QUERY)
[34mkafka-producer2    |[0m %3|1705499667.158|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 199ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1705499694.884|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Name or service not known (after 58ms in state CONNECT, 14 identical error(s) suppressed)
[34mkafka-producer2    |[0m %3|1705499915.569|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 10ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1705499916.558|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.0.0.3:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-17 13:50:13,712] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-a22cb18788de
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-17 13:50:13,750] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:50:13,751] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:50:13,752] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:50:13,754] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:50:13,770] INFO Log directory /kafka/kafka-logs-a22cb18788de not found, creating it. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:13,792] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:13,796] INFO Attempting recovery for all logs in /kafka/kafka-logs-a22cb18788de since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:13,814] INFO Loaded 0 logs in 21ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:13,814] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:13,817] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:14,278] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-17 13:50:14,283] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-17 13:50:14,335] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:50:14,336] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-17 13:50:14,336] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-17 13:50:14,348] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:50:14,379] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:50:14,407] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,410] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,413] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,414] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,443] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-17 13:50:14,480] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:50:14,497] INFO Stat of the created znode at /brokers/ids/1001 is: 26,26,1705499414492,1705499414492,1,0,0,72058700000526336,237,0,26
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:50:14,498] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 26 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:50:14,558] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,565] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:50:14,566] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,566] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,580] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[32mkafka              |[0m [2024-01-17 13:50:14,583] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:14,589] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:14,611] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-17 13:50:14,613] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-17 13:50:14,613] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:14,616] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:14,618] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-17 13:50:14,663] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:50:14,710] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-17 13:50:14,740] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:50:14,761] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:50:14,766] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:50:14,767] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:50:14,777] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-17 13:50:14,777] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-17 13:50:14,778] INFO Kafka startTimeMs: 1705499414767 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-17 13:50:14,779] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:50:14,894] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:50:14,981] INFO Creating topic coordinates with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[32mkafka              |[0m [2024-01-17 13:50:15,110] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(coordinates-0) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-17 13:50:15,226] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:15,236] INFO Created log for partition coordinates-0 in /kafka/kafka-logs-a22cb18788de/coordinates-0 with properties {} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:15,242] INFO [Partition coordinates-0 broker=1001] No checkpointed highwatermark is found for partition coordinates-0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:15,243] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-17 13:50:49,624] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1001), 1 -> ArrayBuffer(1001), 2 -> ArrayBuffer(1001), 3 -> ArrayBuffer(1001), 4 -> ArrayBuffer(1001), 5 -> ArrayBuffer(1001), 6 -> ArrayBuffer(1001), 7 -> ArrayBuffer(1001), 8 -> ArrayBuffer(1001), 9 -> ArrayBuffer(1001), 10 -> ArrayBuffer(1001), 11 -> ArrayBuffer(1001), 12 -> ArrayBuffer(1001), 13 -> ArrayBuffer(1001), 14 -> ArrayBuffer(1001), 15 -> ArrayBuffer(1001), 16 -> ArrayBuffer(1001), 17 -> ArrayBuffer(1001), 18 -> ArrayBuffer(1001), 19 -> ArrayBuffer(1001), 20 -> ArrayBuffer(1001), 21 -> ArrayBuffer(1001), 22 -> ArrayBuffer(1001), 23 -> ArrayBuffer(1001), 24 -> ArrayBuffer(1001), 25 -> ArrayBuffer(1001), 26 -> ArrayBuffer(1001), 27 -> ArrayBuffer(1001), 28 -> ArrayBuffer(1001), 29 -> ArrayBuffer(1001), 30 -> ArrayBuffer(1001), 31 -> ArrayBuffer(1001), 32 -> ArrayBuffer(1001), 33 -> ArrayBuffer(1001), 34 -> ArrayBuffer(1001), 35 -> ArrayBuffer(1001), 36 -> ArrayBuffer(1001), 37 -> ArrayBuffer(1001), 38 -> ArrayBuffer(1001), 39 -> ArrayBuffer(1001), 40 -> ArrayBuffer(1001), 41 -> ArrayBuffer(1001), 42 -> ArrayBuffer(1001), 43 -> ArrayBuffer(1001), 44 -> ArrayBuffer(1001), 45 -> ArrayBuffer(1001), 46 -> ArrayBuffer(1001), 47 -> ArrayBuffer(1001), 48 -> ArrayBuffer(1001), 49 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[32mkafka              |[0m [2024-01-17 13:50:49,704] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-17 13:50:49,707] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,708] INFO Created log for partition __consumer_offsets-3 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,708] INFO [Partition __consumer_offsets-3 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,708] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,715] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,715] INFO Created log for partition __consumer_offsets-18 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,716] INFO [Partition __consumer_offsets-18 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,716] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,721] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,721] INFO Created log for partition __consumer_offsets-41 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,721] INFO [Partition __consumer_offsets-41 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,721] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,724] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,725] INFO Created log for partition __consumer_offsets-10 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,725] INFO [Partition __consumer_offsets-10 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,725] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,730] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,731] INFO Created log for partition __consumer_offsets-33 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,731] INFO [Partition __consumer_offsets-33 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,731] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,734] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,734] INFO Created log for partition __consumer_offsets-48 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,734] INFO [Partition __consumer_offsets-48 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,735] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,739] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,740] INFO Created log for partition __consumer_offsets-19 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,740] INFO [Partition __consumer_offsets-19 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,740] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,744] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,745] INFO Created log for partition __consumer_offsets-34 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,745] INFO [Partition __consumer_offsets-34 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,745] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,749] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,749] INFO Created log for partition __consumer_offsets-4 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,749] INFO [Partition __consumer_offsets-4 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,749] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,754] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,754] INFO Created log for partition __consumer_offsets-11 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,754] INFO [Partition __consumer_offsets-11 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,754] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,758] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,758] INFO Created log for partition __consumer_offsets-26 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,758] INFO [Partition __consumer_offsets-26 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,758] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,762] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,762] INFO Created log for partition __consumer_offsets-49 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,762] INFO [Partition __consumer_offsets-49 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,762] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,766] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,767] INFO Created log for partition __consumer_offsets-39 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,767] INFO [Partition __consumer_offsets-39 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,767] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,772] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,772] INFO Created log for partition __consumer_offsets-9 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,772] INFO [Partition __consumer_offsets-9 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,772] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,776] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,777] INFO Created log for partition __consumer_offsets-24 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,777] INFO [Partition __consumer_offsets-24 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,777] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,781] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,781] INFO Created log for partition __consumer_offsets-31 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,781] INFO [Partition __consumer_offsets-31 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,781] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,785] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,785] INFO Created log for partition __consumer_offsets-46 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,785] INFO [Partition __consumer_offsets-46 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,785] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,788] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,789] INFO Created log for partition __consumer_offsets-1 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,789] INFO [Partition __consumer_offsets-1 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,789] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,792] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,793] INFO Created log for partition __consumer_offsets-16 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,793] INFO [Partition __consumer_offsets-16 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,793] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,796] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,796] INFO Created log for partition __consumer_offsets-2 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,796] INFO [Partition __consumer_offsets-2 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,160 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,166 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,167 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,167 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,171 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,182 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,182 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,182 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,189 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,189 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=bd85893c07ee
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,189 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,189 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,189 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,190 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,190 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,190 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,192 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,192 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,192 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,192 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,192 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,192 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,192 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,194 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,194 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,194 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,201 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-17 13:50:12,206 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,354 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.3:55898
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,360 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.3:55898
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,362 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.1
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,369 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100010180820000 with negotiated timeout 18000 for client /172.0.0.3:55898
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,417 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010180820000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,425 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010180820000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,429 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010180820000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[33;1mzookeeper          |[0m 2024-01-17 13:50:13,619 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010180820000 type:create cxid:0x18 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[33;1mzookeeper          |[0m 2024-01-17 13:50:14,760 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x100010180820000 type:multi cxid:0x40 zxid:0x1f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-17 13:50:14,984 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010180820000 type:setData cxid:0x45 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/coordinates Error:KeeperErrorCode = NoNode for /config/topics/coordinates
[33;1mzookeeper          |[0m 2024-01-17 13:50:22,098 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.3:38814
[33;1mzookeeper          |[0m 2024-01-17 13:50:22,100 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.3:38814
[33;1mzookeeper          |[0m 2024-01-17 13:50:22,107 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100010180820001 with negotiated timeout 30000 for client /172.0.0.3:38814
[33;1mzookeeper          |[0m 2024-01-17 13:50:22,263 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x100010180820001
[33;1mzookeeper          |[0m 2024-01-17 13:50:22,264 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.3:38814 which had sessionid 0x100010180820001
[33;1mzookeeper          |[0m 2024-01-17 13:50:49,626 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010180820000 type:setData cxid:0x58 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,950 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,954 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,954 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,956 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,956 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,967 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,969 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,974 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,990 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,991 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=bd85893c07ee
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,991 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,991 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,992 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,992 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,992 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,992 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,995 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,995 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,995 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,995 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,995 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,995 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-17 13:54:22,995 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,010 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,010 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,010 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,020 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,025 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,984 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.2:53568
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,988 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.2:53568
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,988 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.90
[33;1mzookeeper          |[0m 2024-01-17 13:54:23,998 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100010554720000 with negotiated timeout 18000 for client /172.0.0.2:53568
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,055 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x1 zxid:0x91 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,067 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x2 zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,069 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x3 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,070 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x4 zxid:0x94 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,072 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x5 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,073 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x6 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,074 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x7 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,076 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x8 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,077 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0x9 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,078 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0xa zxid:0x9a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,079 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0xb zxid:0x9b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,080 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0xc zxid:0x9c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,081 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0xd zxid:0x9d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-17 13:54:24,083 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:create cxid:0xe zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-17 13:54:25,386 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x100010554720000 type:multi cxid:0x19 zxid:0x9f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/1001 Error:KeeperErrorCode = NodeExists for /brokers/ids/1001
[33;1mzookeeper          |[0m 2024-01-17 13:54:25,962 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x100010554720000
[33;1mzookeeper          |[0m 2024-01-17 13:54:25,963 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.2:53568 which had sessionid 0x100010554720000
[33;1mzookeeper          |[0m 2024-01-17 13:54:42,567 [myid:] - INFO  [SessionTracker:ZooKeeperServer@355] - Expiring session 0x100010180820000, timeout of 18000ms exceeded
[33;1mzookeeper          |[0m 2024-01-17 13:54:42,567 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x100010180820000
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,595 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,599 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,599 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,600 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,600 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,611 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,613 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,619 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=bd85893c07ee
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,626 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,628 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,628 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,628 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,628 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-91-generic
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,628 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,628 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,628 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,630 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,630 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,630 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,642 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-17 13:58:35,654 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,855 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.3:58290
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,860 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.3:58290
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,861 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.a2
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,872 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10001092f420000 with negotiated timeout 18000 for client /172.0.0.3:58290
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,938 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x1 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,950 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x2 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,952 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x3 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,953 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x4 zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,954 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x5 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,956 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x6 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,958 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x7 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,960 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x8 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,962 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0x9 zxid:0xab txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,964 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0xa zxid:0xac txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,965 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0xb zxid:0xad txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,966 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0xc zxid:0xae txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,967 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0xd zxid:0xaf txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-17 13:58:36,968 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:create cxid:0xe zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-17 13:58:38,558 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10001092f420000 type:multi cxid:0x6b zxid:0xb4 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-17 13:58:46,107 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.0.0.3:34626
[33;1mzookeeper          |[0m 2024-01-17 13:58:46,109 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.0.0.3:34626
[33;1mzookeeper          |[0m 2024-01-17 13:58:46,112 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10001092f420001 with negotiated timeout 30000 for client /172.0.0.3:34626
[33;1mzookeeper          |[0m 2024-01-17 13:58:46,394 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10001092f420001
[33;1mzookeeper          |[0m 2024-01-17 13:58:46,399 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.0.0.3:34626 which had sessionid 0x10001092f420001
[32mkafka              |[0m [2024-01-17 13:50:49,796] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,800] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,800] INFO Created log for partition __consumer_offsets-25 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,800] INFO [Partition __consumer_offsets-25 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,800] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,803] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,804] INFO Created log for partition __consumer_offsets-40 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,804] INFO [Partition __consumer_offsets-40 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,804] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,807] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,807] INFO Created log for partition __consumer_offsets-47 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,807] INFO [Partition __consumer_offsets-47 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,807] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,811] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,812] INFO Created log for partition __consumer_offsets-17 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,812] INFO [Partition __consumer_offsets-17 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,812] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,815] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,815] INFO Created log for partition __consumer_offsets-32 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,815] INFO [Partition __consumer_offsets-32 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,815] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,819] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,819] INFO Created log for partition __consumer_offsets-37 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,819] INFO [Partition __consumer_offsets-37 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,819] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,822] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,822] INFO Created log for partition __consumer_offsets-7 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,823] INFO [Partition __consumer_offsets-7 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,823] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,826] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,826] INFO Created log for partition __consumer_offsets-22 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,826] INFO [Partition __consumer_offsets-22 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,826] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,830] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,830] INFO Created log for partition __consumer_offsets-29 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,830] INFO [Partition __consumer_offsets-29 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,830] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,833] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,834] INFO Created log for partition __consumer_offsets-44 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,834] INFO [Partition __consumer_offsets-44 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,834] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,837] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,838] INFO Created log for partition __consumer_offsets-14 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,838] INFO [Partition __consumer_offsets-14 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,838] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,841] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,841] INFO Created log for partition __consumer_offsets-23 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,841] INFO [Partition __consumer_offsets-23 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,841] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,846] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,847] INFO Created log for partition __consumer_offsets-38 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,847] INFO [Partition __consumer_offsets-38 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,847] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,850] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,851] INFO Created log for partition __consumer_offsets-8 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,851] INFO [Partition __consumer_offsets-8 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,851] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,854] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,855] INFO Created log for partition __consumer_offsets-45 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,855] INFO [Partition __consumer_offsets-45 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,855] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,858] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,858] INFO Created log for partition __consumer_offsets-15 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,858] INFO [Partition __consumer_offsets-15 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,858] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,861] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,862] INFO Created log for partition __consumer_offsets-30 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,862] INFO [Partition __consumer_offsets-30 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,862] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,865] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,866] INFO Created log for partition __consumer_offsets-0 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,866] INFO [Partition __consumer_offsets-0 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,866] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,870] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,870] INFO Created log for partition __consumer_offsets-35 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,870] INFO [Partition __consumer_offsets-35 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,870] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,874] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,875] INFO Created log for partition __consumer_offsets-5 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,875] INFO [Partition __consumer_offsets-5 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,875] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,879] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,880] INFO Created log for partition __consumer_offsets-20 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,880] INFO [Partition __consumer_offsets-20 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,880] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,883] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,884] INFO Created log for partition __consumer_offsets-27 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,884] INFO [Partition __consumer_offsets-27 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,884] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,887] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,888] INFO Created log for partition __consumer_offsets-42 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,888] INFO [Partition __consumer_offsets-42 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,888] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,891] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,892] INFO Created log for partition __consumer_offsets-12 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,892] INFO [Partition __consumer_offsets-12 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,892] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,897] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,898] INFO Created log for partition __consumer_offsets-21 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,898] INFO [Partition __consumer_offsets-21 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,898] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,902] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,903] INFO Created log for partition __consumer_offsets-36 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,903] INFO [Partition __consumer_offsets-36 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,903] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,907] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,907] INFO Created log for partition __consumer_offsets-6 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,907] INFO [Partition __consumer_offsets-6 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,907] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,912] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,912] INFO Created log for partition __consumer_offsets-43 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,912] INFO [Partition __consumer_offsets-43 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,912] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,916] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,916] INFO Created log for partition __consumer_offsets-13 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,916] INFO [Partition __consumer_offsets-13 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,916] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,921] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:50:49,921] INFO Created log for partition __consumer_offsets-28 in /kafka/kafka-logs-a22cb18788de/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:50:49,921] INFO [Partition __consumer_offsets-28 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,921] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:50:49,923] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,924] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[36;1mkafka-ui           |[0m 13:50:12,362 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 13:50:12,398 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 13:50:12,399 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 13:50:12,406 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 13:50:13,389 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 13:50:13,495 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 13:50:13,495 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 13:50:13,525 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 13:50:13,525 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 13:50:13,525 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 13:50:13,526 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 13:50:13,526 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 13:50:13,527 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 13:50:13,527 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 13:50:13,527 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:13,593[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:13,689[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:13,696[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:13,697[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:13,698[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:16,680[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:17,513[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:17,584[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 3b14efb2-601e-436c-9706-a64153310481
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:17,803[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:18,205[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:18,226[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 5.33 seconds (process running for 6.831)
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:19,211[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:19,225[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1705499419-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,925] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:49,926] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,929] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,929] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,929] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,929] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,929] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:19,296[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:19,296[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:19,296[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705499419295
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:19,738[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:30,490[0;39m [31mWARN [0;39m [[34mparallel-3[0;39m] [33mo.h.v.i.p.j.JavaBeanExecutable[0;39m: HV000254: Missing parameter metadata for SerdeUsageDTO(String, int, String), which declares implicit or synthetic parameters. Automatic resolution of generic type information for method parameters may yield incorrect results if multiple parameters have the same erasure. To solve this, compile your code with the '-parameters' flag.
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,752[0;39m [31mWARN [0;39m [[34mparallel-6[0;39m] [33mo.h.v.i.p.j.JavaBeanExecutable[0;39m: HV000254: Missing parameter metadata for SeekDirectionDTO(String, int, String), which declares implicit or synthetic parameters. Automatic resolution of generic type information for method parameters may yield incorrect results if multiple parameters have the same erasure. To solve this, compile your code with the '-parameters' flag.
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,790[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Starting forward polling for ConsumerPosition(seekType=BEGINNING, topic=coordinates, seekTo=null)
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,802[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.c.ConsumerConfig[0;39m: ConsumerConfig values: 
[36;1mkafka-ui           |[0m 	allow.auto.create.topics = false
[36;1mkafka-ui           |[0m 	auto.commit.interval.ms = 5000
[36;1mkafka-ui           |[0m 	auto.offset.reset = earliest
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	check.crcs = true
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-consumer-1705499431791
[36;1mkafka-ui           |[0m 	client.rack = 
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 540000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	enable.auto.commit = false
[36;1mkafka-ui           |[0m 	exclude.internal.topics = true
[36;1mkafka-ui           |[0m 	fetch.max.bytes = 52428800
[36;1mkafka-ui           |[0m 	fetch.max.wait.ms = 500
[36;1mkafka-ui           |[0m 	fetch.min.bytes = 1
[36;1mkafka-ui           |[0m 	group.id = null
[36;1mkafka-ui           |[0m 	group.instance.id = null
[36;1mkafka-ui           |[0m 	heartbeat.interval.ms = 3000
[36;1mkafka-ui           |[0m 	interceptor.classes = []
[36;1mkafka-ui           |[0m 	internal.leave.group.on.close = true
[36;1mkafka-ui           |[0m 	internal.throw.on.fetch.stable.offset.unsupported = false
[36;1mkafka-ui           |[0m 	isolation.level = read_uncommitted
[36;1mkafka-ui           |[0m 	key.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 	max.partition.fetch.bytes = 1048576
[36;1mkafka-ui           |[0m 	max.poll.interval.ms = 300000
[36;1mkafka-ui           |[0m 	max.poll.records = 500
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	session.timeout.ms = 45000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,835[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,835[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,835[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705499431835
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,857[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.Metadata[0;39m: [Consumer clientId=kafka-ui-consumer-1705499431791, groupId=null] Cluster ID: yNWr-cskTIiqrCUaiLRWZw
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,871[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.Metadata[0;39m: [Consumer clientId=kafka-ui-consumer-1705499431791, groupId=null] Resetting the last seen epoch of partition coordinates-0 to 0 since the associated topicId changed from null to N7xrWy8_R3SBZNDX1IG-hg
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,880[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.c.KafkaConsumer[0;39m: [Consumer clientId=kafka-ui-consumer-1705499431791, groupId=null] Assigned to partition(s): coordinates-0
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,884[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.c.KafkaConsumer[0;39m: [Consumer clientId=kafka-ui-consumer-1705499431791, groupId=null] Seeking to offset 0 for partition coordinates-0
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,960[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: 4 records polled
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,975[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Polling finished
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,976[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,976[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,976[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:31,982[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.consumer for kafka-ui-consumer-1705499431791 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:48,224[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:50:48,252[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:51:18,223[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:51:18,252[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:51:48,223[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:51:48,246[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:52:18,223[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:52:18,242[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:52:48,223[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:52:48,251[0;39m [39mDEBUG[0;39m [[34mparallel-1[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:53:18,223[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:53:18,244[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:53:41,663[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705499419-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.admin.client for kafka-ui-admin-1705499419-1 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-17 13:53:41,665[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705499419-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-17 13:53:41,665[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705499419-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-17 13:53:41,665[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705499419-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m 13:54:23,262 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 13:54:23,307 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 13:54:23,308 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 13:54:23,315 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 13:54:24,183 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 13:54:24,280 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 13:54:24,280 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 13:54:24,315 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 13:54:24,315 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 13:54:24,315 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 13:54:24,316 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 13:54:24,316 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 13:54:24,317 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 13:54:24,317 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 13:54:24,317 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:24,401[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:24,510[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:24,520[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,930] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,931] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 6 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:24,521[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:24,522[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:27,429[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:28,565[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:28,718[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 073c48b8-6212-42ec-abc8-26a19aadb615
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:29,268[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:30,621[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:30,667[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 6.964 seconds (process running for 8.265)
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:31,839[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:31,850[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1705499671-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:36,879[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:36,884[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
[36;1mkafka-ui           |[0m java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.error(Operators.java:198)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Operators.complete(Operators.java:137)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
[36;1mkafka-ui           |[0m 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[36;1mkafka-ui           |[0m 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[36;1mkafka-ui           |[0m 	at java.base/java.lang.Thread.run(Thread.java:833)
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,932] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,933] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,933] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,933] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:49,933] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:50:52,577] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member rdkafka-8072abbf-8e05-429b-839e-80587bf53d92 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:52,583] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 1 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:52,591] INFO [GroupCoordinator 1001]: Assignment received from leader for group web_consumer_group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:53,803] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-8072abbf-8e05-429b-839e-80587bf53d92] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:53,803] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member rdkafka-8072abbf-8e05-429b-839e-80587bf53d92 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:50:53,804] INFO [GroupCoordinator 1001]: Group web_consumer_group with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:53:51,680] INFO Unable to read additional data from server sessionid 0x100010180820000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:53:52,400] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-17 13:53:52,401] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:53:52,402] INFO [KafkaServer id=1001] Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:53:52,848] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper: Temporary failure in name resolution
[32mkafka              |[0m 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAddressesFromNameService(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress$NameServiceAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-17 13:53:53,046] WARN Session 0x100010180820000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-17 13:53:53,149] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:53:54,148] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-17 13:53:54,191] WARN Session 0x100010180820000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-17 13:53:55,292] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[36;1mkafka-ui           |[0m 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
[36;1mkafka-ui           |[0m 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
[36;1mkafka-ui           |[0m 	... 16 common frames omitted
[36;1mkafka-ui           |[0m Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
[36;1mkafka-ui           |[0m 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
[36;1mkafka-ui           |[0m 	... 22 common frames omitted
[36;1mkafka-ui           |[0m [30m2024-01-17 13:54:36,886[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m 13:58:35,999 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 13:58:36,071 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 13:58:36,072 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 13:58:36,083 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 13:58:37,188 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 13:58:37,325 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 13:58:37,325 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 13:58:37,365 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 13:58:37,365 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 13:58:37,365 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 13:58:37,365 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 13:58:37,366 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 13:58:37,367 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 13:58:37,367 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 13:58:37,367 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:37,452[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:37,569[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:37,575[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:37,575[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:37,577[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:41,044[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:41,844[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:41,879[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 9b053c93-e28c-41ad-be1a-3a99e0871167
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:42,027[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:42,404[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:42,420[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 5.824 seconds (process running for 7.04)
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:43,120[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:43,131[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1705499923-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-17 13:53:55,470] WARN Session 0x100010180820000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-17 13:53:56,571] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-17 13:53:57,484] WARN Session 0x100010180820000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-17 13:53:58,585] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-17 13:53:59,505] WARN Session 0x100010180820000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m [2024-01-17 13:54:00,606] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
[32mkafka              |[0m java.net.UnknownHostException: zookeeper
[32mkafka              |[0m 	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
[32mkafka              |[0m 	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[32mkafka              |[0m [2024-01-17 13:54:01,473] WARN Session 0x100010180820000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
[32mkafka              |[0m 	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
[32mkafka              |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-17 13:54:23,445] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-17 13:54:23,812] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-17 13:54:23,920] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-17 13:54:23,924] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:54:23,925] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:54:23,947] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:host.name=a22cb18788de (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,954] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,955] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,955] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,957] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:23,962] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-17 13:54:23,969] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:54:23,972] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:54:23,978] INFO Opening socket connection to server zookeeper/172.0.0.5:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:54:23,983] INFO Socket connection established, initiating session, client: /172.0.0.2:53568, server: zookeeper/172.0.0.5:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:54:24,001] INFO Session establishment complete on server zookeeper/172.0.0.5:2181, sessionid = 0x100010554720000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:43,191[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:43,191[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:43,191[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705499923190
[36;1mkafka-ui           |[0m [30m2024-01-17 13:58:43,628[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:59:12,419[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-17 13:59:12,463[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[32mkafka              |[0m [2024-01-17 13:54:24,004] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:54:24,088] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-17 13:54:24,214] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-17 13:54:24,218] INFO Cluster ID = yNWr-cskTIiqrCUaiLRWZw (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:54:24,256] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-a22cb18788de
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-17 13:54:24,263] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-a22cb18788de
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-17 13:54:24,289] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:24,290] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:24,291] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:24,293] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:24,350] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,355] INFO Attempting recovery for all logs in /kafka/kafka-logs-a22cb18788de since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,422] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,423] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,449] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,458] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 90ms (1/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,461] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,461] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,465] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,468] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,470] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,470] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,473] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,475] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,478] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,478] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,480] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,483] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,484] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,485] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,486] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,489] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (5/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,491] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,491] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,493] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,500] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,502] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,503] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,505] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,508] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,510] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,511] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,513] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,516] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,521] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,521] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,524] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,528] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (9/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,530] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,531] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,543] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-17 13:54:24,554] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,555] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-a22cb18788de/__consumer_offsets-35/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-17 13:54:24,562] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 34ms (10/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,564] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,565] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,570] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,572] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (11/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,574] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,575] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,577] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,578] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (12/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,580] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,580] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,582] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,584] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (13/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,587] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,587] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,590] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,592] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (14/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,595] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,595] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,598] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,599] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (15/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,601] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,602] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,605] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,607] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (16/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,609] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,610] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,612] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,615] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (17/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,617] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,618] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,620] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,623] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (18/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,625] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,625] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,628] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,630] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (19/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,632] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,633] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,636] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,638] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (20/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,641] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,641] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,644] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,646] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (21/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,652] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,652] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,659] INFO [ProducerStateManager partition=coordinates-0] Writing producer snapshot at offset 44 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-17 13:54:24,664] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 44 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,664] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-a22cb18788de/coordinates-0/00000000000000000044.snapshot,44)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-17 13:54:24,666] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=44) with 1 segments in 20ms (22/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,668] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,668] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,670] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,672] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (23/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,673] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,673] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,675] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,676] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (24/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,678] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,678] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,680] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,681] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (25/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,682] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,682] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,684] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,687] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (26/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,689] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,689] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,692] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,694] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (27/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,696] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,696] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,699] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,701] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (28/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,703] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,703] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,705] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,707] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (29/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,709] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,709] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,711] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,712] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (30/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,714] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,714] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,716] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,717] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (31/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,719] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,719] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,721] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,723] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (32/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,725] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,726] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,728] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,730] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (33/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,732] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,732] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,734] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,736] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (34/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,739] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,739] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,742] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,743] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (35/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,745] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,747] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,750] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,751] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (36/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,753] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,753] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,758] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,759] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (37/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,761] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,761] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,764] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,766] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (38/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,768] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,769] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,771] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,773] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (39/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,775] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,775] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,777] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,778] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (40/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,780] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,781] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,783] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,784] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (41/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,786] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,786] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,789] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,790] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (42/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,792] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,792] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,794] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,796] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (43/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,797] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,798] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,799] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,801] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (44/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,802] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,802] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,804] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,805] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (45/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,807] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,807] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,810] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,811] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (46/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,813] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,813] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,815] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,816] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (47/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,818] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,818] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,821] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,822] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (48/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,823] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,824] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,825] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,827] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (49/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,828] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,829] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,830] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,832] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (50/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,833] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-a22cb18788de] Recovering unflushed segment 0 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,833] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,835] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:54:24,837] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (51/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,838] INFO Loaded 51 logs in 487ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,839] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:24,839] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:25,199] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-17 13:54:25,203] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-17 13:54:25,242] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:54:25,243] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-17 13:54:25,243] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-17 13:54:25,260] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:54:25,281] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:54:25,296] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,296] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,297] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,299] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,311] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-17 13:54:25,372] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:54:25,400] ERROR Error while creating ephemeral at /brokers/ids/1001, node already exists and owner '72058700000526336' does not match current session '72058716441149440' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[32mkafka              |[0m [2024-01-17 13:54:25,405] ERROR [KafkaServer id=1001] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
[32mkafka              |[0m 	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
[32mkafka              |[0m 	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
[32mkafka              |[0m 	at kafka.server.KafkaServer.startup(KafkaServer.scala:308)
[32mkafka              |[0m 	at kafka.Kafka$.main(Kafka.scala:109)
[32mkafka              |[0m 	at kafka.Kafka.main(Kafka.scala)
[32mkafka              |[0m [2024-01-17 13:54:25,407] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:54:25,408] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopping socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:54:25,412] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopped socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:54:25,421] INFO [ReplicaManager broker=1001] Shutting down (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-17 13:54:25,422] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-17 13:54:25,422] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-17 13:54:25,422] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-17 13:54:25,422] INFO [ReplicaFetcherManager on broker 1001] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-17 13:54:25,423] INFO [ReplicaFetcherManager on broker 1001] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-17 13:54:25,423] INFO [ReplicaAlterLogDirsManager on broker 1001] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-17 13:54:25,424] INFO [ReplicaAlterLogDirsManager on broker 1001] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-17 13:54:25,424] INFO [ExpirationReaper-1001-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,496] INFO [ExpirationReaper-1001-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,497] INFO [ExpirationReaper-1001-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,498] INFO [ExpirationReaper-1001-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,696] INFO [ExpirationReaper-1001-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,697] INFO [ExpirationReaper-1001-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,698] INFO [ExpirationReaper-1001-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,897] INFO [ExpirationReaper-1001-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,897] INFO [ExpirationReaper-1001-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,898] INFO [ExpirationReaper-1001-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,899] INFO [ExpirationReaper-1001-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,899] INFO [ExpirationReaper-1001-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:54:25,907] INFO [ReplicaManager broker=1001] Shut down completely (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-17 13:54:25,907] INFO [broker-1001-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:54:25,908] INFO [broker-1001-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:54:25,908] INFO [broker-1001-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:54:25,912] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[32mkafka              |[0m [2024-01-17 13:54:25,914] INFO Shutting down. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:25,959] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:54:25,960] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-17 13:54:25,960] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-17 13:54:25,960] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-17 13:54:25,961] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:54:26,064] INFO Session: 0x100010554720000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:54:26,064] INFO EventThread shut down for session: 0x100010554720000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:54:26,065] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:54:26,065] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,290] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,290] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,290] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,291] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,291] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,291] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,292] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,292] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,292] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,293] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,293] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:54:26,295] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutting down socket server (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:54:26,329] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutdown completed (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:54:26,330] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-17 13:54:26,330] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-17 13:54:26,331] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-17 13:54:26,334] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[32mkafka              |[0m [2024-01-17 13:54:26,359] INFO App info kafka.server for 1001 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-17 13:54:26,359] INFO [KafkaServer id=1001] shut down completed (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:54:26,360] ERROR Exiting Kafka. (kafka.Kafka$)
[32mkafka              |[0m [2024-01-17 13:54:26,360] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-17 13:58:36,264] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-17 13:58:36,725] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-17 13:58:36,807] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-17 13:58:36,810] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:58:36,811] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:58:36,825] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:host.name=a22cb18788de (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:os.version=5.15.0-91-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,829] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,832] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-17 13:58:36,835] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-17 13:58:36,840] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:58:36,843] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:58:36,850] INFO Opening socket connection to server zookeeper/172.0.0.5:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:58:36,854] INFO Socket connection established, initiating session, client: /172.0.0.3:58290, server: zookeeper/172.0.0.5:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:58:36,873] INFO Session establishment complete on server zookeeper/172.0.0.5:2181, sessionid = 0x10001092f420000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-17 13:58:36,875] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-17 13:58:36,973] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-17 13:58:37,107] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-17 13:58:37,113] INFO Cluster ID = yNWr-cskTIiqrCUaiLRWZw (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:58:37,165] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-a22cb18788de
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-17 13:58:37,174] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-a22cb18788de
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-17 13:58:37,220] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:58:37,221] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:58:37,223] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:58:37,224] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-17 13:58:37,308] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,313] INFO Skipping recovery for all logs in /kafka/kafka-logs-a22cb18788de since clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,382] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,390] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 66ms (1/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,393] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,395] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (2/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,397] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,399] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (3/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,402] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,404] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (4/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,407] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,410] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (5/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,412] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,415] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (6/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,417] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,418] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (7/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,420] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,422] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (8/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,424] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,426] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (9/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,451] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,453] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-a22cb18788de/__consumer_offsets-35/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-17 13:58:37,466] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 40ms (10/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,469] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,472] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,474] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,476] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (12/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,482] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,486] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (13/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,489] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,491] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (14/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,495] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,497] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (15/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,500] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,502] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (16/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,504] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,506] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (17/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,508] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,510] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (18/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,512] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,515] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (19/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,520] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,522] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (20/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,524] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,527] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (21/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,534] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 44 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,535] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-a22cb18788de/coordinates-0/00000000000000000044.snapshot,44)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-17 13:58:37,538] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=44) with 1 segments in 9ms (22/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,540] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,542] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (23/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,549] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,553] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (24/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,555] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,557] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (25/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,560] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,563] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (26/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,568] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,570] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (27/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,573] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,574] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (28/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,578] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,580] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (29/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,584] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,586] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (30/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,588] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,590] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (31/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,592] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,596] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (32/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,598] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,600] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (33/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,602] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,603] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (34/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,606] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,607] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (35/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,609] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,611] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (36/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,613] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,614] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (37/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,617] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,618] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (38/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,620] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,621] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (39/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,624] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,625] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (40/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,627] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,628] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (41/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,630] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,631] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (42/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,633] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,634] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (43/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,637] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,638] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (44/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,640] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,641] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (45/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,644] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,645] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (46/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,647] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,648] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (47/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,650] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,651] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (48/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,653] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,654] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (49/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,656] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,657] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (50/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,659] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-a22cb18788de] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-17 13:58:37,660] INFO Completed load of Log(dir=/kafka/kafka-logs-a22cb18788de/__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (51/51 loaded in /kafka/kafka-logs-a22cb18788de) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,663] INFO Loaded 51 logs in 355ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,664] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:37,664] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-17 13:58:38,069] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-17 13:58:38,074] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-17 13:58:38,119] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:58:38,120] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-17 13:58:38,120] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-17 13:58:38,127] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:58:38,171] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:58:38,188] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,189] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,190] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,190] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,203] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-17 13:58:38,247] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:58:38,266] INFO Stat of the created znode at /brokers/ids/1001 is: 177,177,1705499918259,1705499918259,1,0,0,72058732997115904,237,0,177
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:58:38,267] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 177 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-17 13:58:38,323] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,329] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,330] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,346] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,361] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,401] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-17 13:58:38,402] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,416] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-17 13:58:38,416] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,459] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-17 13:58:38,500] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-17 13:58:38,535] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:58:38,547] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:58:38,555] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:58:38,555] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-17 13:58:38,567] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-17 13:58:38,567] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-17 13:58:38,569] INFO Kafka startTimeMs: 1705499918555 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-17 13:58:38,570] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-17 13:58:38,656] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, coordinates-0, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-17 13:58:38,671] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,680] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,682] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,686] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,687] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-17 13:58:38,690] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 44 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,690] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,691] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,695] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,697] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,698] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,701] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,704] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,705] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,707] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,708] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,709] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,712] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,714] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,716] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,718] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,720] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,722] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,723] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,724] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,726] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,728] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,730] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,732] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,735] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,737] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,738] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,740] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,742] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,745] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,750] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,754] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,755] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,756] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,757] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,759] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 3 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,759] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,761] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,763] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,765] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,767] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,769] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,771] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,772] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,773] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,774] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,775] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-17 13:58:38,789] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,795] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,805] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,805] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,805] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,805] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,805] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,806] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,806] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,807] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,808] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,808] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,808] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,808] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,809] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,810] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,810] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,811] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,812] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,812] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,812] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,812] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,812] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,812] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,813] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,814] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 16 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,815] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,816] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,816] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,816] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,816] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,816] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,817] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,817] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,817] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,818] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,818] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,819] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,821] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,821] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,821] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,821] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,821] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 4 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,820] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,822] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,823] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,824] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,879] INFO Loaded member MemberMetadata(memberId=rdkafka-8072abbf-8e05-429b-839e-80587bf53d92, groupInstanceId=None, clientId=rdkafka, clientHost=/172.0.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ) in group web_consumer_group with generation 1. (kafka.coordinator.group.GroupMetadata$)
[32mkafka              |[0m [2024-01-17 13:58:38,892] INFO [GroupCoordinator 1001]: Loading group metadata for web_consumer_group with generation 2 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-17 13:58:38,893] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 70 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,895] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 72 milliseconds for epoch 0, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,895] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,895] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,896] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,896] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,896] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,896] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,896] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,896] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,897] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 73 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-17 13:58:38,897] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 73 milliseconds for epoch 0, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m creating topics: coordinates:1:1
