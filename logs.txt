Attaching to fastapi, kafka-producer, kafka-producer2, kafka-ui, database, zookeeper, kafka
[33mfastapi            |[0m INFO:     Started server process [1]
[33mfastapi            |[0m INFO:     Waiting for application startup.
[33mfastapi            |[0m INFO:     Application startup complete.
[33mfastapi            |[0m INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
[33mfastapi            |[0m INFO:     Shutting down
[33mfastapi            |[0m INFO:     Waiting for application shutdown.
[33mfastapi            |[0m INFO:     Application shutdown complete.
[33mfastapi            |[0m INFO:     Finished server process [1]
[33mfastapi            |[0m INFO:     Started server process [1]
[33mfastapi            |[0m INFO:     Waiting for application startup.
[33mfastapi            |[0m INFO:     Application startup complete.
[33mfastapi            |[0m INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
[33mfastapi            |[0m INFO:     172.23.0.1:39140 - "GET / HTTP/1.1" 200 OK
[33mfastapi            |[0m Received message: {"id": [95], "timestamp": 1705312425, "x": 0.0004827373665952558, "y": 0.0009647080361118557}
[33mfastapi            |[0m INFO:     172.23.0.1:57286 - "GET /see_messages HTTP/1.1" 500 Internal Server Error
[33mfastapi            |[0m ERROR:    Exception in ASGI application
[33mfastapi            |[0m Traceback (most recent call last):
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[33mfastapi            |[0m     result = await app(  # type: ignore[func-returns-value]
[33mfastapi            |[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[33mfastapi            |[0m     return await self.app(scope, receive, send)
[33mfastapi            |[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/applications.py", line 1054, in __call__
[33mfastapi            |[0m     await super().__call__(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/applications.py", line 123, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/errors.py", line 186, in __call__
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/errors.py", line 164, in __call__
[33mfastapi            |[0m     await self.app(scope, receive, _send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[33mfastapi            |[0m     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 762, in __call__
[33mfastapi            |[0m     await self.middleware_stack(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 782, in app
[33mfastapi            |[0m     await route.handle(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 297, in handle
[33mfastapi            |[0m     await self.app(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 77, in app
[33mfastapi            |[0m     await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
[33mfastapi            |[0m     raise exc
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[33mfastapi            |[0m     await app(scope, receive, sender)
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/starlette/routing.py", line 72, in app
[33mfastapi            |[0m     response = await func(request)
[33mfastapi            |[0m                ^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/routing.py", line 299, in app
[33mfastapi            |[0m     raise e
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/routing.py", line 294, in app
[33mfastapi            |[0m     raw_response = await run_endpoint_function(
[33mfastapi            |[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/usr/local/lib/python3.11/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
[33mfastapi            |[0m     return await dependant.call(**values)
[33mfastapi            |[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[33mfastapi            |[0m   File "/app/main.py", line 46, in see_messages
[33mfastapi            |[0m     push_data_to_database(messages)
[33mfastapi            |[0m   File "/app/main.py", line 60, in push_data_to_database
[33mfastapi            |[0m     (processed_data['id'], processed_data['timestamp'], processed_data['x'], processed_data['y']))
[33mfastapi            |[0m      ~~~~~~~~~~~~~~^^^^^^
[33mfastapi            |[0m TypeError: list indices must be integers or slices, not str
[33mfastapi            |[0m INFO:     172.23.0.1:57292 - "GET /favicon.ico HTTP/1.1" 404 Not Found
[36mdatabase           |[0m The files belonging to this database system will be owned by user "postgres".
[36mdatabase           |[0m This user must also own the server process.
[36mdatabase           |[0m 
[36mdatabase           |[0m The database cluster will be initialized with locale "en_US.utf8".
[36mdatabase           |[0m The default database encoding has accordingly been set to "UTF8".
[36mdatabase           |[0m The default text search configuration will be set to "english".
[36mdatabase           |[0m 
[36mdatabase           |[0m Data page checksums are disabled.
[36mdatabase           |[0m 
[36mdatabase           |[0m fixing permissions on existing directory /var/lib/postgresql/data ... ok
[36mdatabase           |[0m creating subdirectories ... ok
[36mdatabase           |[0m selecting dynamic shared memory implementation ... posix
[36mdatabase           |[0m selecting default max_connections ... 100
[36mdatabase           |[0m selecting default shared_buffers ... 128MB
[36mdatabase           |[0m selecting default time zone ... Etc/UTC
[36mdatabase           |[0m creating configuration files ... ok
[36mdatabase           |[0m running bootstrap script ... ok
[36mdatabase           |[0m performing post-bootstrap initialization ... ok
[36mdatabase           |[0m initdb: warning: enabling "trust" authentication for local connections
[36mdatabase           |[0m initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
[36mdatabase           |[0m syncing data to disk ... ok
[36mdatabase           |[0m 
[36mdatabase           |[0m 
[36mdatabase           |[0m Success. You can now start the database server using:
[36mdatabase           |[0m 
[36mdatabase           |[0m     pg_ctl -D /var/lib/postgresql/data -l logfile start
[36mdatabase           |[0m 
[36mdatabase           |[0m waiting for server to start....2024-01-15 09:53:46.418 UTC [47] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-15 09:53:46.419 UTC [47] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-15 09:53:46.426 UTC [50] LOG:  database system was shut down at 2024-01-15 09:53:46 UTC
[36mdatabase           |[0m 2024-01-15 09:53:46.437 UTC [47] LOG:  database system is ready to accept connections
[36mdatabase           |[0m  done
[36mdatabase           |[0m server started
[36mdatabase           |[0m CREATE DATABASE
[36mdatabase           |[0m 
[36mdatabase           |[0m 
[36mdatabase           |[0m /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init.sql
[36mdatabase           |[0m 2024-01-15 09:53:46.679 UTC [60] ERROR:  database "pg" already exists
[36mdatabase           |[0m 2024-01-15 09:53:46.679 UTC [60] STATEMENT:  CREATE DATABASE pg;
[36mdatabase           |[0m psql:/docker-entrypoint-initdb.d/init.sql:1: ERROR:  database "pg" already exists
[36mdatabase           |[0m 
[36mdatabase           |[0m PostgreSQL Database directory appears to contain a database; Skipping initialization
[36mdatabase           |[0m 
[36mdatabase           |[0m 2024-01-15 09:53:58.778 UTC [1] LOG:  starting PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
[36mdatabase           |[0m 2024-01-15 09:53:58.833 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
[36mdatabase           |[0m 2024-01-15 09:53:58.834 UTC [1] LOG:  listening on IPv6 address "::", port 5432
[36mdatabase           |[0m 2024-01-15 09:53:58.837 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
[36mdatabase           |[0m 2024-01-15 09:53:58.843 UTC [29] LOG:  database system was interrupted; last known up at 2024-01-15 09:53:46 UTC
[36mdatabase           |[0m 2024-01-15 09:53:58.897 UTC [29] LOG:  database system was not properly shut down; automatic recovery in progress
[36mdatabase           |[0m 2024-01-15 09:53:58.899 UTC [29] LOG:  redo starts at 0/14EAA68
[36mdatabase           |[0m 2024-01-15 09:53:58.906 UTC [29] LOG:  invalid record length at 0/1913068: expected at least 24, got 0
[36mdatabase           |[0m 2024-01-15 09:53:58.906 UTC [29] LOG:  redo done at 0/1913020 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s
[36mdatabase           |[0m 2024-01-15 09:53:58.909 UTC [27] LOG:  checkpoint starting: end-of-recovery immediate wait
[36mdatabase           |[0m 2024-01-15 09:53:58.949 UTC [27] LOG:  checkpoint complete: wrote 923 buffers (5.6%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.011 s, sync=0.028 s, total=0.042 s; sync files=301, longest=0.002 s, average=0.001 s; distance=4257 kB, estimate=4257 kB; lsn=0/1913068, redo lsn=0/1913068
[36mdatabase           |[0m 2024-01-15 09:53:58.956 UTC [1] LOG:  database system is ready to accept connections
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,780 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,785 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,785 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,785 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,789 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,795 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,795 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,796 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=ab6a22029ef3
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,800 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,802 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,802 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,802 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,802 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-71-generic
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,802 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,802 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,802 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,804 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,804 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,804 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,814 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-15 09:53:45,820 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,067 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.23.0.2:52486
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,073 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.23.0.2:52486
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,075 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.1
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,082 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c62b300000 with negotiated timeout 18000 for client /172.23.0.2:52486
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,130 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,136 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,140 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[33;1mzookeeper          |[0m 2024-01-15 09:53:47,296 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300000 type:create cxid:0x18 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[33;1mzookeeper          |[0m 2024-01-15 09:53:48,517 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000c62b300000 type:multi cxid:0x40 zxid:0x1f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m 2024-01-15 09:53:48,915 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300000 type:setData cxid:0x45 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/coordinates Error:KeeperErrorCode = NoNode for /config/topics/coordinates
[33;1mzookeeper          |[0m 2024-01-15 09:53:56,269 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.23.0.2:41208
[33;1mzookeeper          |[0m 2024-01-15 09:53:56,270 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.23.0.2:41208
[33;1mzookeeper          |[0m 2024-01-15 09:53:56,278 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c62b300001 with negotiated timeout 30000 for client /172.23.0.2:41208
[33;1mzookeeper          |[0m 2024-01-15 09:53:56,409 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c62b300001
[33;1mzookeeper          |[0m 2024-01-15 09:53:56,417 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.23.0.2:41208 which had sessionid 0x10000c62b300001
[36;1mkafka-ui           |[0m 09:53:46,331 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 09:53:46,378 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 09:53:46,379 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 09:53:46,390 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 09:53:47,213 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 09:53:47,322 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 09:53:47,323 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 09:53:47,363 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 09:53:47,363 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 09:53:47,363 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 09:53:47,363 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 09:53:47,364 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 09:53:47,365 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 09:53:47,365 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 09:53:47,365 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:47,427[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:47,547[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:47,551[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:47,551[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:47,552[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:50,327[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:51,259[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:51,295[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: 04ebd0c6-0f96-418d-a6eb-1345fee38060
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:51,462[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:51,920[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:51,940[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 5.183 seconds (process running for 6.459)
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:52,672[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:52,683[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1705312432-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[33;1mzookeeper          |[0m 2024-01-15 09:53:59,316 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c62b300000
[33;1mzookeeper          |[0m 2024-01-15 09:53:59,318 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.23.0.2:52486 which had sessionid 0x10000c62b300000
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,488 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.23.0.2:59802
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,493 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.23.0.2:59802
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,501 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c62b300002 with negotiated timeout 18000 for client /172.23.0.2:59802
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,573 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x1 zxid:0x2a txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,585 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x2 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,587 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x3 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,590 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x4 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,592 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x5 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,594 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x6 zxid:0x2f txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,597 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x7 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,603 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x8 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,606 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0x9 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,609 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0xa zxid:0x33 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,612 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0xb zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,615 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0xc zxid:0x35 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,617 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0xd zxid:0x36 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
[33;1mzookeeper          |[0m 2024-01-15 09:54:03,620 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:create cxid:0xe zxid:0x37 txntype:-1 reqpath:n/a Error Path:/config/ips Error:KeeperErrorCode = NodeExists for /config/ips
[33;1mzookeeper          |[0m 2024-01-15 09:54:04,875 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:multi cxid:0x34 zxid:0x3b txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[33;1mzookeeper          |[0m ZooKeeper JMX enabled by default
[33;1mzookeeper          |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,691 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,694 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,694 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,694 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,695 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,700 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,701 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,701 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=ab6a22029ef3
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[35mkafka-producer     |[0m %3|1705312425.948|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.23.0.2:9092 failed: Connection refused (after 0ms in state CONNECT)
[35mkafka-producer     |[0m %3|1705312426.949|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.23.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[35mkafka-producer     |[0m %6|1705312438.584|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Disconnected (after 9621ms in state UP)
[35mkafka-producer     |[0m %3|1705312438.962|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Connect to ipv4#172.23.0.2:9092 failed: Connection refused (after 13ms in state CONNECT)
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,705 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,706 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,706 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,707 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,707 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.15.0-71-generic
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,707 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,707 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,707 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,708 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,708 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,708 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,713 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[33;1mzookeeper          |[0m 2024-01-15 09:54:09,715 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[33;1mzookeeper          |[0m 2024-01-15 09:54:10,332 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.23.0.2:51344
[33;1mzookeeper          |[0m 2024-01-15 09:54:10,335 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@942] - Client attempting to renew session 0x10000c62b300002 at /172.23.0.2:51344
[33;1mzookeeper          |[0m 2024-01-15 09:54:10,337 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@694] - Established session 0x10000c62b300002 with negotiated timeout 18000 for client /172.23.0.2:51344
[33;1mzookeeper          |[0m 2024-01-15 09:54:13,231 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /172.23.0.2:51358
[33;1mzookeeper          |[0m 2024-01-15 09:54:13,232 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.23.0.2:51358
[33;1mzookeeper          |[0m 2024-01-15 09:54:13,232 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.3c
[33;1mzookeeper          |[0m 2024-01-15 09:54:13,244 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x10000c6888e0000 with negotiated timeout 30000 for client /172.23.0.2:51358
[33;1mzookeeper          |[0m 2024-01-15 09:54:13,383 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x10000c6888e0000
[33;1mzookeeper          |[0m 2024-01-15 09:54:13,391 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.23.0.2:51358 which had sessionid 0x10000c6888e0000
[33;1mzookeeper          |[0m 2024-01-15 09:54:59,630 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x10000c62b300002 type:setData cxid:0x43 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-15 09:53:46,531] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-15 09:53:46,937] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-15 09:53:47,017] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-15 09:53:47,020] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:53:47,021] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:53:47,036] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:host.name=41beed6ee22e (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[34mkafka-producer2    |[0m %3|1705312425.883|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.23.0.2:9092 failed: Connection refused (after 11ms in state CONNECT)
[34mkafka-producer2    |[0m %3|1705312426.871|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#172.23.0.2:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)
[34mkafka-producer2    |[0m %6|1705312438.581|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Disconnected (after 9635ms in state UP)
[34mkafka-producer2    |[0m %3|1705312438.872|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Connect to ipv4#172.23.0.2:9092 failed: Connection refused (after 0ms in state CONNECT)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:os.version=5.15.0-71-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,040] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,042] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:47,048] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-15 09:53:47,053] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:53:47,055] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:53:47,061] INFO Opening socket connection to server zookeeper/172.23.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:53:47,066] INFO Socket connection established, initiating session, client: /172.23.0.2:52486, server: zookeeper/172.23.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:53:47,083] INFO Session establishment complete on server zookeeper/172.23.0.4:2181, sessionid = 0x10000c62b300000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:53:47,086] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:53:47,160] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-15 09:53:47,171] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[32mkafka              |[0m [2024-01-15 09:53:47,171] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-15 09:53:47,302] INFO Cluster ID = zUqTHgv9TOW1Q9YKkMbrgw (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:53:47,306] WARN No meta.properties file under dir /kafka/kafka-logs-41beed6ee22e/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[32mkafka              |[0m [2024-01-15 09:53:47,364] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-41beed6ee22e
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:52,754[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:52,754[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:52,754[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705312432753
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:53,128[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:58,540[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705312432-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.admin.client for kafka-ui-admin-1705312432-1 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:58,550[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705312432-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:58,550[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705312432-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-15 09:53:58,550[0;39m [34mINFO [0;39m [[34mkafka-admin-client-thread | kafka-ui-admin-1705312432-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m 09:54:01,415 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
[36;1mkafka-ui           |[0m 09:54:01,449 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
[36;1mkafka-ui           |[0m 09:54:01,450 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
[36;1mkafka-ui           |[0m 09:54:01,454 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
[36;1mkafka-ui           |[0m 09:54:02,046 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
[36;1mkafka-ui           |[0m 09:54:02,154 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
[36;1mkafka-ui           |[0m 09:54:02,154 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
[36;1mkafka-ui           |[0m 09:54:02,184 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
[36;1mkafka-ui           |[0m 09:54:02,184 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
[36;1mkafka-ui           |[0m 09:54:02,184 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
[36;1mkafka-ui           |[0m 09:54:02,184 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
[36;1mkafka-ui           |[0m 09:54:02,184 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
[36;1mkafka-ui           |[0m 09:54:02,185 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
[36;1mkafka-ui           |[0m 09:54:02,185 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
[36;1mkafka-ui           |[0m 09:54:02,185 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m  _   _ ___    __             _                _          _  __      __ _
[36;1mkafka-ui           |[0m | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
[36;1mkafka-ui           |[0m | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
[36;1mkafka-ui           |[0m  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
[36;1mkafka-ui           |[0m                                  |_|                                             
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:02,247[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:02,332[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:02,336[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:02,336[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:02,337[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:05,510[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:06,257[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:06,295[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m Using generated security password: c42d5e72-9962-42dd-9cf7-7425fe2a1a77
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:06,461[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:06,901[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:06,921[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 5.295 seconds (process running for 5.843)
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:07,752[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:07,763[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-admin-1705312447-1
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 300000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retries = 2147483647
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-15 09:53:47,373] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-41beed6ee22e
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-15 09:53:47,414] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:53:47,415] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:53:47,416] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:53:47,418] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:53:47,440] INFO Log directory /kafka/kafka-logs-41beed6ee22e not found, creating it. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:47,461] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-41beed6ee22e) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:47,465] INFO Attempting recovery for all logs in /kafka/kafka-logs-41beed6ee22e since no clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:47,502] INFO Loaded 0 logs in 40ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:47,505] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:47,540] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:47,962] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-15 09:53:47,965] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-15 09:53:48,003] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:48,004] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-15 09:53:48,004] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-15 09:53:48,014] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:48,048] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-15 09:53:48,070] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,071] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,072] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,073] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,098] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-15 09:53:48,140] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-15 09:53:48,169] INFO Stat of the created znode at /brokers/ids/1001 is: 26,26,1705312428152,1705312428152,1,0,0,72058445166018560,237,0,26
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:07,832[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:07,832[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:07,832[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705312447831
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:08,273[0;39m [39mDEBUG[0;39m [[34mparallel-4[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:36,401[0;39m [31mWARN [0;39m [[34mparallel-3[0;39m] [33mo.h.v.i.p.j.JavaBeanExecutable[0;39m: HV000254: Missing parameter metadata for SerdeUsageDTO(String, int, String), which declares implicit or synthetic parameters. Automatic resolution of generic type information for method parameters may yield incorrect results if multiple parameters have the same erasure. To solve this, compile your code with the '-parameters' flag.
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:36,918[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:36,955[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,371[0;39m [31mWARN [0;39m [[34mparallel-1[0;39m] [33mo.h.v.i.p.j.JavaBeanExecutable[0;39m: HV000254: Missing parameter metadata for SeekDirectionDTO(String, int, String), which declares implicit or synthetic parameters. Automatic resolution of generic type information for method parameters may yield incorrect results if multiple parameters have the same erasure. To solve this, compile your code with the '-parameters' flag.
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,422[0;39m [39mDEBUG[0;39m [[34mboundedElastic-2[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Starting forward polling for ConsumerPosition(seekType=BEGINNING, topic=coordinates, seekTo=null)
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,432[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.c.ConsumerConfig[0;39m: ConsumerConfig values: 
[36;1mkafka-ui           |[0m 	allow.auto.create.topics = false
[36;1mkafka-ui           |[0m 	auto.commit.interval.ms = 5000
[36;1mkafka-ui           |[0m 	auto.offset.reset = earliest
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	check.crcs = true
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-consumer-1705312477423
[36;1mkafka-ui           |[0m 	client.rack = 
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 540000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	enable.auto.commit = false
[36;1mkafka-ui           |[0m 	exclude.internal.topics = true
[36;1mkafka-ui           |[0m 	fetch.max.bytes = 52428800
[36;1mkafka-ui           |[0m 	fetch.max.wait.ms = 500
[36;1mkafka-ui           |[0m 	fetch.min.bytes = 1
[36;1mkafka-ui           |[0m 	group.id = null
[36;1mkafka-ui           |[0m 	group.instance.id = null
[36;1mkafka-ui           |[0m 	heartbeat.interval.ms = 3000
[36;1mkafka-ui           |[0m 	interceptor.classes = []
[36;1mkafka-ui           |[0m 	internal.leave.group.on.close = true
[36;1mkafka-ui           |[0m 	internal.throw.on.fetch.stable.offset.unsupported = false
[36;1mkafka-ui           |[0m 	isolation.level = read_uncommitted
[36;1mkafka-ui           |[0m 	key.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 	max.partition.fetch.bytes = 1048576
[36;1mkafka-ui           |[0m 	max.poll.interval.ms = 300000
[36;1mkafka-ui           |[0m 	max.poll.records = 500
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	session.timeout.ms = 45000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,462[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,462[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,462[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705312477462
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,480[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.Metadata[0;39m: [Consumer clientId=kafka-ui-consumer-1705312477423, groupId=null] Cluster ID: zUqTHgv9TOW1Q9YKkMbrgw
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,490[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.Metadata[0;39m: [Consumer clientId=kafka-ui-consumer-1705312477423, groupId=null] Resetting the last seen epoch of partition coordinates-0 to 0 since the associated topicId changed from null to zvBjyaWDSmSrffEV2jzK9g
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,501[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.c.KafkaConsumer[0;39m: [Consumer clientId=kafka-ui-consumer-1705312477423, groupId=null] Assigned to partition(s): coordinates-0
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,505[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.c.KafkaConsumer[0;39m: [Consumer clientId=kafka-ui-consumer-1705312477423, groupId=null] Seeking to offset 0 for partition coordinates-0
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,589[0;39m [39mDEBUG[0;39m [[34mboundedElastic-2[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: 4 records polled
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,604[0;39m [39mDEBUG[0;39m [[34mboundedElastic-2[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Polling finished
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,605[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,606[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,606[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:37,611[0;39m [34mINFO [0;39m [[34mboundedElastic-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.consumer for kafka-ui-consumer-1705312477423 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,408[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Starting forward polling for ConsumerPosition(seekType=BEGINNING, topic=coordinates, seekTo=null)
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,409[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.c.ConsumerConfig[0;39m: ConsumerConfig values: 
[36;1mkafka-ui           |[0m 	allow.auto.create.topics = false
[36;1mkafka-ui           |[0m 	auto.commit.interval.ms = 5000
[36;1mkafka-ui           |[0m 	auto.offset.reset = earliest
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	check.crcs = true
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-consumer-1705312484409
[36;1mkafka-ui           |[0m 	client.rack = 
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 540000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	enable.auto.commit = false
[36;1mkafka-ui           |[0m 	exclude.internal.topics = true
[36;1mkafka-ui           |[0m 	fetch.max.bytes = 52428800
[36;1mkafka-ui           |[0m 	fetch.max.wait.ms = 500
[36;1mkafka-ui           |[0m 	fetch.min.bytes = 1
[36;1mkafka-ui           |[0m 	group.id = null
[36;1mkafka-ui           |[0m 	group.instance.id = null
[36;1mkafka-ui           |[0m 	heartbeat.interval.ms = 3000
[36;1mkafka-ui           |[0m 	interceptor.classes = []
[36;1mkafka-ui           |[0m 	internal.leave.group.on.close = true
[36;1mkafka-ui           |[0m 	internal.throw.on.fetch.stable.offset.unsupported = false
[36;1mkafka-ui           |[0m 	isolation.level = read_uncommitted
[36;1mkafka-ui           |[0m 	key.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 	max.partition.fetch.bytes = 1048576
[36;1mkafka-ui           |[0m 	max.poll.interval.ms = 300000
[36;1mkafka-ui           |[0m 	max.poll.records = 500
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	session.timeout.ms = 45000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,415[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,415[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,416[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705312484415
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,425[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.Metadata[0;39m: [Consumer clientId=kafka-ui-consumer-1705312484409, groupId=null] Cluster ID: zUqTHgv9TOW1Q9YKkMbrgw
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,428[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,429[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,429[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,431[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.consumer for kafka-ui-consumer-1705312484409 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,432[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Polling finished due to thread interruption
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,445[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Starting forward polling for ConsumerPosition(seekType=BEGINNING, topic=coordinates, seekTo=null)
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,445[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.c.ConsumerConfig[0;39m: ConsumerConfig values: 
[36;1mkafka-ui           |[0m 	allow.auto.create.topics = false
[36;1mkafka-ui           |[0m 	auto.commit.interval.ms = 5000
[36;1mkafka-ui           |[0m 	auto.offset.reset = earliest
[36;1mkafka-ui           |[0m 	bootstrap.servers = [kafka:9092]
[36;1mkafka-ui           |[0m 	check.crcs = true
[36;1mkafka-ui           |[0m 	client.dns.lookup = use_all_dns_ips
[36;1mkafka-ui           |[0m 	client.id = kafka-ui-consumer-1705312484445
[36;1mkafka-ui           |[0m 	client.rack = 
[36;1mkafka-ui           |[0m 	connections.max.idle.ms = 540000
[36;1mkafka-ui           |[0m 	default.api.timeout.ms = 60000
[36;1mkafka-ui           |[0m 	enable.auto.commit = false
[36;1mkafka-ui           |[0m 	exclude.internal.topics = true
[36;1mkafka-ui           |[0m 	fetch.max.bytes = 52428800
[36;1mkafka-ui           |[0m 	fetch.max.wait.ms = 500
[36;1mkafka-ui           |[0m 	fetch.min.bytes = 1
[36;1mkafka-ui           |[0m 	group.id = null
[36;1mkafka-ui           |[0m 	group.instance.id = null
[36;1mkafka-ui           |[0m 	heartbeat.interval.ms = 3000
[36;1mkafka-ui           |[0m 	interceptor.classes = []
[36;1mkafka-ui           |[0m 	internal.leave.group.on.close = true
[36;1mkafka-ui           |[0m 	internal.throw.on.fetch.stable.offset.unsupported = false
[36;1mkafka-ui           |[0m 	isolation.level = read_uncommitted
[36;1mkafka-ui           |[0m 	key.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 	max.partition.fetch.bytes = 1048576
[36;1mkafka-ui           |[0m 	max.poll.interval.ms = 300000
[36;1mkafka-ui           |[0m 	max.poll.records = 500
[36;1mkafka-ui           |[0m 	metadata.max.age.ms = 300000
[36;1mkafka-ui           |[0m 	metric.reporters = []
[36;1mkafka-ui           |[0m 	metrics.num.samples = 2
[36;1mkafka-ui           |[0m 	metrics.recording.level = INFO
[36;1mkafka-ui           |[0m 	metrics.sample.window.ms = 30000
[36;1mkafka-ui           |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[36;1mkafka-ui           |[0m 	receive.buffer.bytes = 65536
[36;1mkafka-ui           |[0m 	reconnect.backoff.max.ms = 1000
[36;1mkafka-ui           |[0m 	reconnect.backoff.ms = 50
[36;1mkafka-ui           |[0m 	request.timeout.ms = 30000
[36;1mkafka-ui           |[0m 	retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.client.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.jaas.config = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mkafka-ui           |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mkafka-ui           |[0m 	sasl.kerberos.service.name = null
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.callback.handler.class = null
[36;1mkafka-ui           |[0m 	sasl.login.class = null
[36;1mkafka-ui           |[0m 	sasl.login.connect.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.read.timeout.ms = null
[36;1mkafka-ui           |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mkafka-ui           |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mkafka-ui           |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.login.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.mechanism = GSSAPI
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.clock.skew.seconds = 30
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.audience = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.expected.issuer = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.jwks.endpoint.url = null
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.scope.claim.name = scope
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.sub.claim.name = sub
[36;1mkafka-ui           |[0m 	sasl.oauthbearer.token.endpoint.url = null
[36;1mkafka-ui           |[0m 	security.protocol = PLAINTEXT
[36;1mkafka-ui           |[0m 	security.providers = null
[36;1mkafka-ui           |[0m 	send.buffer.bytes = 131072
[36;1mkafka-ui           |[0m 	session.timeout.ms = 45000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.max.ms = 30000
[36;1mkafka-ui           |[0m 	socket.connection.setup.timeout.ms = 10000
[36;1mkafka-ui           |[0m 	ssl.cipher.suites = null
[36;1mkafka-ui           |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[36;1mkafka-ui           |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mkafka-ui           |[0m 	ssl.engine.factory.class = null
[36;1mkafka-ui           |[0m 	ssl.key.password = null
[36;1mkafka-ui           |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mkafka-ui           |[0m 	ssl.keystore.certificate.chain = null
[36;1mkafka-ui           |[0m 	ssl.keystore.key = null
[36;1mkafka-ui           |[0m 	ssl.keystore.location = null
[36;1mkafka-ui           |[0m 	ssl.keystore.password = null
[36;1mkafka-ui           |[0m 	ssl.keystore.type = JKS
[36;1mkafka-ui           |[0m 	ssl.protocol = TLSv1.3
[36;1mkafka-ui           |[0m 	ssl.provider = null
[36;1mkafka-ui           |[0m 	ssl.secure.random.implementation = null
[36;1mkafka-ui           |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mkafka-ui           |[0m 	ssl.truststore.certificates = null
[36;1mkafka-ui           |[0m 	ssl.truststore.location = null
[36;1mkafka-ui           |[0m 	ssl.truststore.password = null
[36;1mkafka-ui           |[0m 	ssl.truststore.type = JKS
[36;1mkafka-ui           |[0m 	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer
[36;1mkafka-ui           |[0m 
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,448[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.3.1
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,448[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: e23c59d00e687ff5
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,448[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1705312484448
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,460[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.Metadata[0;39m: [Consumer clientId=kafka-ui-consumer-1705312484445, groupId=null] Cluster ID: zUqTHgv9TOW1Q9YKkMbrgw
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,476[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.Metadata[0;39m: [Consumer clientId=kafka-ui-consumer-1705312484445, groupId=null] Resetting the last seen epoch of partition coordinates-0 to 0 since the associated topicId changed from null to zvBjyaWDSmSrffEV2jzK9g
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,482[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.c.KafkaConsumer[0;39m: [Consumer clientId=kafka-ui-consumer-1705312484445, groupId=null] Assigned to partition(s): coordinates-0
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,483[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.c.KafkaConsumer[0;39m: [Consumer clientId=kafka-ui-consumer-1705312484445, groupId=null] Seeking to offset 0 for partition coordinates-0
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,491[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: 6 records polled
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,496[0;39m [39mDEBUG[0;39m [[34mboundedElastic-1[0;39m] [33mc.p.k.u.e.ForwardRecordEmitter[0;39m: Polling finished
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,496[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics scheduler closed
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,496[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,496[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.m.Metrics[0;39m: Metrics reporters closed
[36;1mkafka-ui           |[0m [30m2024-01-15 09:54:44,498[0;39m [34mINFO [0;39m [[34mboundedElastic-1[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: App info kafka.consumer for kafka-ui-consumer-1705312484445 unregistered
[36;1mkafka-ui           |[0m [30m2024-01-15 09:55:06,917[0;39m [39mDEBUG[0;39m [[34mparallel-5[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:55:06,957[0;39m [39mDEBUG[0;39m [[34mparallel-6[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:55:36,918[0;39m [39mDEBUG[0;39m [[34mparallel-7[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
[36;1mkafka-ui           |[0m [30m2024-01-15 09:55:36,948[0;39m [39mDEBUG[0;39m [[34mparallel-8[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-15 09:53:48,170] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 26 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-15 09:53:48,257] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,264] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,270] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-15 09:53:48,272] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,282] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:48,295] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[32mkafka              |[0m [2024-01-15 09:53:48,310] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:48,350] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-15 09:53:48,351] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:48,351] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-15 09:53:48,365] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-15 09:53:48,367] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:48,407] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:48,451] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-15 09:53:48,477] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:48,486] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:48,499] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:48,500] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:48,505] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-15 09:53:48,506] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-15 09:53:48,506] INFO Kafka startTimeMs: 1705312428500 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-15 09:53:48,508] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:53:48,615] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-15 09:53:48,912] INFO Creating topic coordinates with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[32mkafka              |[0m [2024-01-15 09:53:49,010] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(coordinates-0) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-15 09:53:49,068] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:53:49,073] INFO Created log for partition coordinates-0 in /kafka/kafka-logs-41beed6ee22e/coordinates-0 with properties {} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:49,074] INFO [Partition coordinates-0 broker=1001] No checkpointed highwatermark is found for partition coordinates-0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:53:49,075] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-15 09:53:58,524] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-15 09:53:58,535] INFO [KafkaServer id=1001] shutting down (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:53:58,552] INFO [KafkaServer id=1001] Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:53:58,574] INFO [KafkaServer id=1001] Controlled shutdown succeeded (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:53:58,578] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-15 09:53:58,578] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-15 09:53:58,579] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-15 09:53:58,579] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopping socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:58,588] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Stopped socket server request processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:53:58,589] INFO [data-plane Kafka Request Handler on Broker 1001], shutting down (kafka.server.KafkaRequestHandlerPool)
[32mkafka              |[0m [2024-01-15 09:53:58,595] INFO [data-plane Kafka Request Handler on Broker 1001], shut down completely (kafka.server.KafkaRequestHandlerPool)
[32mkafka              |[0m [2024-01-15 09:53:58,604] INFO [ExpirationReaper-1001-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,621] INFO [ExpirationReaper-1001-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,621] INFO [ExpirationReaper-1001-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,622] INFO [KafkaApi-1001] Shutdown complete. (kafka.server.KafkaApis)
[32mkafka              |[0m [2024-01-15 09:53:58,622] INFO [ExpirationReaper-1001-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,666] INFO [ExpirationReaper-1001-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,666] INFO [ExpirationReaper-1001-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,668] INFO [TransactionCoordinator id=1001] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:58,669] INFO [ProducerId Manager 1001]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-15 09:53:58,670] INFO [Transaction State Manager 1001]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[32mkafka              |[0m [2024-01-15 09:53:58,670] INFO [Transaction Marker Channel Manager 1001]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-15 09:53:58,670] INFO [Transaction Marker Channel Manager 1001]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-15 09:53:58,670] INFO [Transaction Marker Channel Manager 1001]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-15 09:53:58,671] INFO [TransactionCoordinator id=1001] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:58,672] INFO [GroupCoordinator 1001]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:58,672] INFO [ExpirationReaper-1001-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,675] INFO [ExpirationReaper-1001-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,676] INFO [ExpirationReaper-1001-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,676] INFO [ExpirationReaper-1001-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,680] INFO [ExpirationReaper-1001-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,680] INFO [ExpirationReaper-1001-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,681] INFO [GroupCoordinator 1001]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:53:58,682] INFO [ReplicaManager broker=1001] Shutting down (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-15 09:53:58,683] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-15 09:53:58,683] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-15 09:53:58,683] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-15 09:53:58,683] INFO [ReplicaFetcherManager on broker 1001] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-15 09:53:58,684] INFO [ReplicaFetcherManager on broker 1001] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-15 09:53:58,685] INFO [ReplicaAlterLogDirsManager on broker 1001] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-15 09:53:58,685] INFO [ReplicaAlterLogDirsManager on broker 1001] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[32mkafka              |[0m [2024-01-15 09:53:58,685] INFO [ExpirationReaper-1001-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,880] INFO [ExpirationReaper-1001-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,880] INFO [ExpirationReaper-1001-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:58,881] INFO [ExpirationReaper-1001-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,081] INFO [ExpirationReaper-1001-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,081] INFO [ExpirationReaper-1001-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,081] INFO [ExpirationReaper-1001-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,281] INFO [ExpirationReaper-1001-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,281] INFO [ExpirationReaper-1001-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,281] INFO [ExpirationReaper-1001-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,283] INFO [ExpirationReaper-1001-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,284] INFO [ExpirationReaper-1001-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:53:59,292] INFO [ReplicaManager broker=1001] Shut down completely (kafka.server.ReplicaManager)
[32mkafka              |[0m [2024-01-15 09:53:59,292] INFO [broker-1001-to-controller-send-thread]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-15 09:53:59,293] INFO [broker-1001-to-controller-send-thread]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-15 09:53:59,293] INFO [broker-1001-to-controller-send-thread]: Stopped (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-15 09:53:59,294] INFO Broker to controller channel manager for alterIsrChannel shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[32mkafka              |[0m [2024-01-15 09:53:59,295] INFO Shutting down. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:59,302] INFO [ProducerStateManager partition=coordinates-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-15 09:53:59,311] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:53:59,315] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-15 09:53:59,315] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-15 09:53:59,315] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-15 09:53:59,316] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:53:59,418] INFO Session: 0x10000c62b300000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:53:59,419] INFO EventThread shut down for session: 0x10000c62b300000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:53:59,419] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:53:59,420] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:00,417] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:00,417] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:00,418] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,417] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,417] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,417] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,420] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,420] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,420] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,423] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,423] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:01,425] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutting down socket server (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:01,444] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Shutdown completed (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:01,444] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-15 09:54:01,444] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-15 09:54:01,445] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[32mkafka              |[0m [2024-01-15 09:54:01,446] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[32mkafka              |[0m [2024-01-15 09:54:01,447] INFO App info kafka.server for 1001 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-15 09:54:01,449] INFO [KafkaServer id=1001] shut down completed (kafka.server.KafkaServer)
[32mkafka              |[0m waiting for kafka to be ready
[32mkafka              |[0m [Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'inter.broker.listener.name' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_HOME from broker config
[32mkafka              |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listeners' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m Excluding KAFKA_VERSION from broker config
[32mkafka              |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'listener.security.protocol.map' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[32mkafka              |[0m [2024-01-15 09:54:03,039] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[32mkafka              |[0m [2024-01-15 09:54:03,328] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[32mkafka              |[0m [2024-01-15 09:54:03,420] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[32mkafka              |[0m [2024-01-15 09:54:03,424] INFO starting (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:54:03,424] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:54:03,445] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:54:03,451] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,451] INFO Client environment:host.name=41beed6ee22e (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,451] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,451] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,451] INFO Client environment:java.home=/usr/local/openjdk-11 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.8.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/opt/kafka/bin/../libs/connect-file-2.8.1.jar:/opt/kafka/bin/../libs/connect-json-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.8.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.8.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.8.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.8.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/opt/kafka/bin/../libs/jline-3.12.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.8.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.8.1.jar:/opt/kafka/bin/../libs/kafka-metadata-2.8.1.jar:/opt/kafka/bin/../libs/kafka-raft-2.8.1.jar:/opt/kafka/bin/../libs/kafka-shell-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.8.1.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.13-2.8.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/opt/kafka/bin/../libs/scala-library-2.13.5.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.5.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.1.jar:/opt/kafka/bin/../libs/zookeeper-3.5.9.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.9.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.9-1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:os.version=5.15.0-71-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,452] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,455] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@44be0077 (org.apache.zookeeper.ZooKeeper)
[32mkafka              |[0m [2024-01-15 09:54:03,460] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[32mkafka              |[0m [2024-01-15 09:54:03,467] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:54:03,470] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:54:03,483] INFO Opening socket connection to server zookeeper/172.23.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:54:03,489] INFO Socket connection established, initiating session, client: /172.23.0.2:59802, server: zookeeper/172.23.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:54:03,504] INFO Session establishment complete on server zookeeper/172.23.0.4:2181, sessionid = 0x10000c62b300002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:54:03,508] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[32mkafka              |[0m [2024-01-15 09:54:03,628] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[32mkafka              |[0m [2024-01-15 09:54:03,767] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[32mkafka              |[0m [2024-01-15 09:54:03,772] INFO Cluster ID = zUqTHgv9TOW1Q9YKkMbrgw (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:54:03,816] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-41beed6ee22e
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-15 09:54:03,823] INFO KafkaConfig values: 
[32mkafka              |[0m 	advertised.host.name = null
[32mkafka              |[0m 	advertised.listeners = INSIDE://kafka:9092,OUTSIDE://localhost:9093
[32mkafka              |[0m 	advertised.port = null
[32mkafka              |[0m 	alter.config.policy.class.name = null
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mkafka              |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	authorizer.class.name = 
[32mkafka              |[0m 	auto.create.topics.enable = true
[32mkafka              |[0m 	auto.leader.rebalance.enable = true
[32mkafka              |[0m 	background.threads = 10
[32mkafka              |[0m 	broker.heartbeat.interval.ms = 2000
[32mkafka              |[0m 	broker.id = -1
[32mkafka              |[0m 	broker.id.generation.enable = true
[32mkafka              |[0m 	broker.rack = null
[32mkafka              |[0m 	broker.session.timeout.ms = 9000
[32mkafka              |[0m 	client.quota.callback.class = null
[32mkafka              |[0m 	compression.type = producer
[32mkafka              |[0m 	connection.failed.authentication.delay.ms = 100
[32mkafka              |[0m 	connections.max.idle.ms = 600000
[32mkafka              |[0m 	connections.max.reauth.ms = 0
[32mkafka              |[0m 	control.plane.listener.name = null
[32mkafka              |[0m 	controlled.shutdown.enable = true
[32mkafka              |[0m 	controlled.shutdown.max.retries = 3
[32mkafka              |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mkafka              |[0m 	controller.listener.names = null
[32mkafka              |[0m 	controller.quorum.append.linger.ms = 25
[32mkafka              |[0m 	controller.quorum.election.backoff.max.ms = 1000
[32mkafka              |[0m 	controller.quorum.election.timeout.ms = 1000
[32mkafka              |[0m 	controller.quorum.fetch.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.request.timeout.ms = 2000
[32mkafka              |[0m 	controller.quorum.retry.backoff.ms = 20
[32mkafka              |[0m 	controller.quorum.voters = []
[32mkafka              |[0m 	controller.quota.window.num = 11
[32mkafka              |[0m 	controller.quota.window.size.seconds = 1
[32mkafka              |[0m 	controller.socket.timeout.ms = 30000
[32mkafka              |[0m 	create.topic.policy.class.name = null
[32mkafka              |[0m 	default.replication.factor = 1
[32mkafka              |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mkafka              |[0m 	delegation.token.expiry.time.ms = 86400000
[32mkafka              |[0m 	delegation.token.master.key = null
[32mkafka              |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mkafka              |[0m 	delegation.token.secret.key = null
[32mkafka              |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mkafka              |[0m 	delete.topic.enable = true
[32mkafka              |[0m 	fetch.max.bytes = 57671680
[32mkafka              |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	group.initial.rebalance.delay.ms = 0
[32mkafka              |[0m 	group.max.session.timeout.ms = 1800000
[32mkafka              |[0m 	group.max.size = 2147483647
[32mkafka              |[0m 	group.min.session.timeout.ms = 6000
[32mkafka              |[0m 	host.name = 
[32mkafka              |[0m 	initial.broker.registration.timeout.ms = 60000
[32mkafka              |[0m 	inter.broker.listener.name = INSIDE
[32mkafka              |[0m 	inter.broker.protocol.version = 2.8-IV1
[32mkafka              |[0m 	kafka.metrics.polling.interval.secs = 10
[32mkafka              |[0m 	kafka.metrics.reporters = []
[32mkafka              |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka              |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka              |[0m 	listener.security.protocol.map = INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
[32mkafka              |[0m 	listeners = INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093
[32mkafka              |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka              |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka              |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka              |[0m 	log.cleaner.enable = true
[32mkafka              |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mkafka              |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka              |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka              |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[32mkafka              |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka              |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mkafka              |[0m 	log.cleaner.threads = 1
[32mkafka              |[0m 	log.cleanup.policy = [delete]
[32mkafka              |[0m 	log.dir = /tmp/kafka-logs
[32mkafka              |[0m 	log.dirs = /kafka/kafka-logs-41beed6ee22e
[32mkafka              |[0m 	log.flush.interval.messages = 9223372036854775807
[32mkafka              |[0m 	log.flush.interval.ms = null
[32mkafka              |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mkafka              |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mkafka              |[0m 	log.index.interval.bytes = 4096
[32mkafka              |[0m 	log.index.size.max.bytes = 10485760
[32mkafka              |[0m 	log.message.downconversion.enable = true
[32mkafka              |[0m 	log.message.format.version = 2.8-IV1
[32mkafka              |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka              |[0m 	log.message.timestamp.type = CreateTime
[32mkafka              |[0m 	log.preallocate = false
[32mkafka              |[0m 	log.retention.bytes = -1
[32mkafka              |[0m 	log.retention.check.interval.ms = 300000
[32mkafka              |[0m 	log.retention.hours = 168
[32mkafka              |[0m 	log.retention.minutes = null
[32mkafka              |[0m 	log.retention.ms = null
[32mkafka              |[0m 	log.roll.hours = 168
[32mkafka              |[0m 	log.roll.jitter.hours = 0
[32mkafka              |[0m 	log.roll.jitter.ms = null
[32mkafka              |[0m 	log.roll.ms = null
[32mkafka              |[0m 	log.segment.bytes = 1073741824
[32mkafka              |[0m 	log.segment.delete.delay.ms = 60000
[32mkafka              |[0m 	max.connection.creation.rate = 2147483647
[32mkafka              |[0m 	max.connections = 2147483647
[32mkafka              |[0m 	max.connections.per.ip = 2147483647
[32mkafka              |[0m 	max.connections.per.ip.overrides = 
[32mkafka              |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mkafka              |[0m 	message.max.bytes = 1048588
[32mkafka              |[0m 	metadata.log.dir = null
[32mkafka              |[0m 	metric.reporters = []
[32mkafka              |[0m 	metrics.num.samples = 2
[32mkafka              |[0m 	metrics.recording.level = INFO
[32mkafka              |[0m 	metrics.sample.window.ms = 30000
[32mkafka              |[0m 	min.insync.replicas = 1
[32mkafka              |[0m 	node.id = -1
[32mkafka              |[0m 	num.io.threads = 8
[32mkafka              |[0m 	num.network.threads = 3
[32mkafka              |[0m 	num.partitions = 1
[32mkafka              |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka              |[0m 	num.replica.alter.log.dirs.threads = null
[32mkafka              |[0m 	num.replica.fetchers = 1
[32mkafka              |[0m 	offset.metadata.max.bytes = 4096
[32mkafka              |[0m 	offsets.commit.required.acks = -1
[32mkafka              |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka              |[0m 	offsets.load.buffer.size = 5242880
[32mkafka              |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka              |[0m 	offsets.retention.minutes = 10080
[32mkafka              |[0m 	offsets.topic.compression.codec = 0
[32mkafka              |[0m 	offsets.topic.num.partitions = 50
[32mkafka              |[0m 	offsets.topic.replication.factor = 1
[32mkafka              |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka              |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mkafka              |[0m 	password.encoder.iterations = 4096
[32mkafka              |[0m 	password.encoder.key.length = 128
[32mkafka              |[0m 	password.encoder.keyfactory.algorithm = null
[32mkafka              |[0m 	password.encoder.old.secret = null
[32mkafka              |[0m 	password.encoder.secret = null
[32mkafka              |[0m 	port = 9092
[32mkafka              |[0m 	principal.builder.class = null
[32mkafka              |[0m 	process.roles = []
[32mkafka              |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka              |[0m 	queued.max.request.bytes = -1
[32mkafka              |[0m 	queued.max.requests = 500
[32mkafka              |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka              |[0m 	quota.producer.default = 9223372036854775807
[32mkafka              |[0m 	quota.window.num = 11
[32mkafka              |[0m 	quota.window.size.seconds = 1
[32mkafka              |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka              |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka              |[0m 	replica.fetch.min.bytes = 1
[32mkafka              |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka              |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka              |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka              |[0m 	replica.lag.time.max.ms = 30000
[32mkafka              |[0m 	replica.selector.class = null
[32mkafka              |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka              |[0m 	replica.socket.timeout.ms = 30000
[32mkafka              |[0m 	replication.quota.window.num = 11
[32mkafka              |[0m 	replication.quota.window.size.seconds = 1
[32mkafka              |[0m 	request.timeout.ms = 30000
[32mkafka              |[0m 	reserved.broker.max.id = 1000
[32mkafka              |[0m 	sasl.client.callback.handler.class = null
[32mkafka              |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka              |[0m 	sasl.jaas.config = null
[32mkafka              |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka              |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka              |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka              |[0m 	sasl.kerberos.service.name = null
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka              |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.callback.handler.class = null
[32mkafka              |[0m 	sasl.login.class = null
[32mkafka              |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mkafka              |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mkafka              |[0m 	sasl.login.refresh.window.factor = 0.8
[32mkafka              |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mkafka              |[0m 	sasl.mechanism.controller.protocol = GSSAPI
[32mkafka              |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka              |[0m 	sasl.server.callback.handler.class = null
[32mkafka              |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka              |[0m 	security.providers = null
[32mkafka              |[0m 	socket.connection.setup.timeout.max.ms = 30000
[32mkafka              |[0m 	socket.connection.setup.timeout.ms = 10000
[32mkafka              |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka              |[0m 	socket.request.max.bytes = 104857600
[32mkafka              |[0m 	socket.send.buffer.bytes = 102400
[32mkafka              |[0m 	ssl.cipher.suites = []
[32mkafka              |[0m 	ssl.client.auth = none
[32mkafka              |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[32mkafka              |[0m 	ssl.endpoint.identification.algorithm = https
[32mkafka              |[0m 	ssl.engine.factory.class = null
[32mkafka              |[0m 	ssl.key.password = null
[32mkafka              |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka              |[0m 	ssl.keystore.certificate.chain = null
[32mkafka              |[0m 	ssl.keystore.key = null
[32mkafka              |[0m 	ssl.keystore.location = null
[32mkafka              |[0m 	ssl.keystore.password = null
[32mkafka              |[0m 	ssl.keystore.type = JKS
[32mkafka              |[0m 	ssl.principal.mapping.rules = DEFAULT
[32mkafka              |[0m 	ssl.protocol = TLSv1.3
[32mkafka              |[0m 	ssl.provider = null
[32mkafka              |[0m 	ssl.secure.random.implementation = null
[32mkafka              |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka              |[0m 	ssl.truststore.certificates = null
[32mkafka              |[0m 	ssl.truststore.location = null
[32mkafka              |[0m 	ssl.truststore.password = null
[32mkafka              |[0m 	ssl.truststore.type = JKS
[32mkafka              |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
[32mkafka              |[0m 	transaction.max.timeout.ms = 900000
[32mkafka              |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mkafka              |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mkafka              |[0m 	transaction.state.log.min.isr = 1
[32mkafka              |[0m 	transaction.state.log.num.partitions = 50
[32mkafka              |[0m 	transaction.state.log.replication.factor = 1
[32mkafka              |[0m 	transaction.state.log.segment.bytes = 104857600
[32mkafka              |[0m 	transactional.id.expiration.ms = 604800000
[32mkafka              |[0m 	unclean.leader.election.enable = false
[32mkafka              |[0m 	zookeeper.clientCnxnSocket = null
[32mkafka              |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka              |[0m 	zookeeper.connection.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.max.in.flight.requests = 10
[32mkafka              |[0m 	zookeeper.session.timeout.ms = 18000
[32mkafka              |[0m 	zookeeper.set.acl = false
[32mkafka              |[0m 	zookeeper.ssl.cipher.suites = null
[32mkafka              |[0m 	zookeeper.ssl.client.enable = false
[32mkafka              |[0m 	zookeeper.ssl.crl.enable = false
[32mkafka              |[0m 	zookeeper.ssl.enabled.protocols = null
[32mkafka              |[0m 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
[32mkafka              |[0m 	zookeeper.ssl.keystore.location = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.password = null
[32mkafka              |[0m 	zookeeper.ssl.keystore.type = null
[32mkafka              |[0m 	zookeeper.ssl.ocsp.enable = false
[32mkafka              |[0m 	zookeeper.ssl.protocol = TLSv1.2
[32mkafka              |[0m 	zookeeper.ssl.truststore.location = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.password = null
[32mkafka              |[0m 	zookeeper.ssl.truststore.type = null
[32mkafka              |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka              |[0m  (kafka.server.KafkaConfig)
[32mkafka              |[0m [2024-01-15 09:54:03,850] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:03,851] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:03,852] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:03,853] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mkafka              |[0m [2024-01-15 09:54:03,904] INFO Loading logs from log dirs ArraySeq(/kafka/kafka-logs-41beed6ee22e) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:03,906] INFO Skipping recovery for all logs in /kafka/kafka-logs-41beed6ee22e since clean shutdown file was found (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:03,981] INFO [Log partition=coordinates-0, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:03,983] INFO [ProducerStateManager partition=coordinates-0] Loading producer state from snapshot file 'SnapshotFile(/kafka/kafka-logs-41beed6ee22e/coordinates-0/00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
[32mkafka              |[0m [2024-01-15 09:54:03,998] INFO Completed load of Log(dir=/kafka/kafka-logs-41beed6ee22e/coordinates-0, topic=coordinates, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 84ms (1/1 loaded in /kafka/kafka-logs-41beed6ee22e) (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:04,001] INFO Loaded 1 logs in 97ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:04,002] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:04,003] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:04,397] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-15 09:54:04,400] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-15 09:54:04,434] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:04,435] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[32mkafka              |[0m [2024-01-15 09:54:04,435] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[32mkafka              |[0m [2024-01-15 09:54:04,442] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:04,461] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-15 09:54:04,476] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,477] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,478] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,479] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,491] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mkafka              |[0m [2024-01-15 09:54:04,536] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-15 09:54:04,546] INFO Stat of the created znode at /brokers/ids/1001 is: 56,56,1705312444543,1705312444543,1,0,0,72058445166018562,237,0,56
[32mkafka              |[0m  (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-15 09:54:04,547] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: INSIDE://kafka:9092,OUTSIDE://localhost:9093, czxid (broker epoch): 56 (kafka.zk.KafkaZkClient)
[32mkafka              |[0m [2024-01-15 09:54:04,605] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,613] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,617] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,635] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:04,643] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:04,681] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[32mkafka              |[0m [2024-01-15 09:54:04,682] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:04,686] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:04,703] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[32mkafka              |[0m [2024-01-15 09:54:04,731] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka              |[0m [2024-01-15 09:54:04,842] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mkafka              |[0m [2024-01-15 09:54:04,887] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:04,895] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(INSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:04,903] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(OUTSIDE) (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:04,904] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
[32mkafka              |[0m [2024-01-15 09:54:04,922] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-15 09:54:04,922] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-15 09:54:04,922] INFO Kafka startTimeMs: 1705312444904 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka              |[0m [2024-01-15 09:54:04,925] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[32mkafka              |[0m [2024-01-15 09:54:04,975] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker kafka:9092 (id: 1001 rack: null) (kafka.server.BrokerToControllerRequestThread)
[32mkafka              |[0m [2024-01-15 09:54:04,995] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(coordinates-0) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-15 09:54:05,016] INFO [Partition coordinates-0 broker=1001] Log loaded for partition coordinates-0 with initial high watermark 2 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:08,567] INFO Unable to read additional data from server sessionid 0x10000c62b300002, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:54:10,329] INFO Opening socket connection to server zookeeper/172.23.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:54:10,330] INFO Socket connection established, initiating session, client: /172.23.0.2:51344, server: zookeeper/172.23.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m [2024-01-15 09:54:10,337] INFO Session establishment complete on server zookeeper/172.23.0.4:2181, sessionid = 0x10000c62b300002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[32mkafka              |[0m creating topics: coordinates:1:1
[32mkafka              |[0m [2024-01-15 09:54:59,623] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1001), 1 -> ArrayBuffer(1001), 2 -> ArrayBuffer(1001), 3 -> ArrayBuffer(1001), 4 -> ArrayBuffer(1001), 5 -> ArrayBuffer(1001), 6 -> ArrayBuffer(1001), 7 -> ArrayBuffer(1001), 8 -> ArrayBuffer(1001), 9 -> ArrayBuffer(1001), 10 -> ArrayBuffer(1001), 11 -> ArrayBuffer(1001), 12 -> ArrayBuffer(1001), 13 -> ArrayBuffer(1001), 14 -> ArrayBuffer(1001), 15 -> ArrayBuffer(1001), 16 -> ArrayBuffer(1001), 17 -> ArrayBuffer(1001), 18 -> ArrayBuffer(1001), 19 -> ArrayBuffer(1001), 20 -> ArrayBuffer(1001), 21 -> ArrayBuffer(1001), 22 -> ArrayBuffer(1001), 23 -> ArrayBuffer(1001), 24 -> ArrayBuffer(1001), 25 -> ArrayBuffer(1001), 26 -> ArrayBuffer(1001), 27 -> ArrayBuffer(1001), 28 -> ArrayBuffer(1001), 29 -> ArrayBuffer(1001), 30 -> ArrayBuffer(1001), 31 -> ArrayBuffer(1001), 32 -> ArrayBuffer(1001), 33 -> ArrayBuffer(1001), 34 -> ArrayBuffer(1001), 35 -> ArrayBuffer(1001), 36 -> ArrayBuffer(1001), 37 -> ArrayBuffer(1001), 38 -> ArrayBuffer(1001), 39 -> ArrayBuffer(1001), 40 -> ArrayBuffer(1001), 41 -> ArrayBuffer(1001), 42 -> ArrayBuffer(1001), 43 -> ArrayBuffer(1001), 44 -> ArrayBuffer(1001), 45 -> ArrayBuffer(1001), 46 -> ArrayBuffer(1001), 47 -> ArrayBuffer(1001), 48 -> ArrayBuffer(1001), 49 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[32mkafka              |[0m [2024-01-15 09:54:59,735] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[32mkafka              |[0m [2024-01-15 09:54:59,740] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,743] INFO Created log for partition __consumer_offsets-3 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,743] INFO [Partition __consumer_offsets-3 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,743] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,747] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,748] INFO Created log for partition __consumer_offsets-18 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,748] INFO [Partition __consumer_offsets-18 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,748] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,751] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,752] INFO Created log for partition __consumer_offsets-41 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,752] INFO [Partition __consumer_offsets-41 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,752] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,755] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,756] INFO Created log for partition __consumer_offsets-10 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,756] INFO [Partition __consumer_offsets-10 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,756] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,761] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,761] INFO Created log for partition __consumer_offsets-33 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,761] INFO [Partition __consumer_offsets-33 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,762] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,765] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,766] INFO Created log for partition __consumer_offsets-48 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,766] INFO [Partition __consumer_offsets-48 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,766] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,769] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,770] INFO Created log for partition __consumer_offsets-19 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,770] INFO [Partition __consumer_offsets-19 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,770] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,773] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,774] INFO Created log for partition __consumer_offsets-34 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,774] INFO [Partition __consumer_offsets-34 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,774] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,778] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,778] INFO Created log for partition __consumer_offsets-4 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,778] INFO [Partition __consumer_offsets-4 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,778] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,781] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,782] INFO Created log for partition __consumer_offsets-11 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,782] INFO [Partition __consumer_offsets-11 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,782] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,785] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,785] INFO Created log for partition __consumer_offsets-26 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,786] INFO [Partition __consumer_offsets-26 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,786] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,789] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,789] INFO Created log for partition __consumer_offsets-49 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,789] INFO [Partition __consumer_offsets-49 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,789] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,794] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,794] INFO Created log for partition __consumer_offsets-39 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,794] INFO [Partition __consumer_offsets-39 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,794] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,798] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,798] INFO Created log for partition __consumer_offsets-9 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,798] INFO [Partition __consumer_offsets-9 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,798] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,801] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,802] INFO Created log for partition __consumer_offsets-24 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,802] INFO [Partition __consumer_offsets-24 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,802] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,805] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,806] INFO Created log for partition __consumer_offsets-31 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,806] INFO [Partition __consumer_offsets-31 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,806] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,810] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,811] INFO Created log for partition __consumer_offsets-46 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,811] INFO [Partition __consumer_offsets-46 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,811] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,814] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,815] INFO Created log for partition __consumer_offsets-1 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,815] INFO [Partition __consumer_offsets-1 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,815] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,818] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,819] INFO Created log for partition __consumer_offsets-16 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,819] INFO [Partition __consumer_offsets-16 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,819] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,822] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,823] INFO Created log for partition __consumer_offsets-2 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,823] INFO [Partition __consumer_offsets-2 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,823] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,828] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,828] INFO Created log for partition __consumer_offsets-25 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,828] INFO [Partition __consumer_offsets-25 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,829] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,832] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,832] INFO Created log for partition __consumer_offsets-40 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,833] INFO [Partition __consumer_offsets-40 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,833] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,836] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,836] INFO Created log for partition __consumer_offsets-47 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,836] INFO [Partition __consumer_offsets-47 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,836] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,840] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,840] INFO Created log for partition __consumer_offsets-17 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,841] INFO [Partition __consumer_offsets-17 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,841] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,846] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,846] INFO Created log for partition __consumer_offsets-32 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,846] INFO [Partition __consumer_offsets-32 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,846] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,850] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,850] INFO Created log for partition __consumer_offsets-37 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,850] INFO [Partition __consumer_offsets-37 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,850] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,854] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,854] INFO Created log for partition __consumer_offsets-7 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,854] INFO [Partition __consumer_offsets-7 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,854] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,858] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,859] INFO Created log for partition __consumer_offsets-22 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,859] INFO [Partition __consumer_offsets-22 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,859] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,863] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,863] INFO Created log for partition __consumer_offsets-29 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,864] INFO [Partition __consumer_offsets-29 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,864] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,867] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,867] INFO Created log for partition __consumer_offsets-44 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,867] INFO [Partition __consumer_offsets-44 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,867] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,871] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,871] INFO Created log for partition __consumer_offsets-14 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,871] INFO [Partition __consumer_offsets-14 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,871] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,875] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,876] INFO Created log for partition __consumer_offsets-23 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,876] INFO [Partition __consumer_offsets-23 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,876] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,880] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,880] INFO Created log for partition __consumer_offsets-38 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,881] INFO [Partition __consumer_offsets-38 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,881] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,884] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,884] INFO Created log for partition __consumer_offsets-8 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,884] INFO [Partition __consumer_offsets-8 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,884] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,887] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,888] INFO Created log for partition __consumer_offsets-45 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,888] INFO [Partition __consumer_offsets-45 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,888] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,891] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,892] INFO Created log for partition __consumer_offsets-15 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,892] INFO [Partition __consumer_offsets-15 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,892] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,896] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,896] INFO Created log for partition __consumer_offsets-30 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,896] INFO [Partition __consumer_offsets-30 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,896] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,899] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,899] INFO Created log for partition __consumer_offsets-0 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,899] INFO [Partition __consumer_offsets-0 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,899] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,902] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,903] INFO Created log for partition __consumer_offsets-35 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,903] INFO [Partition __consumer_offsets-35 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,903] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,906] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,906] INFO Created log for partition __consumer_offsets-5 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,906] INFO [Partition __consumer_offsets-5 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,906] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,909] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,910] INFO Created log for partition __consumer_offsets-20 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,910] INFO [Partition __consumer_offsets-20 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,910] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,913] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,914] INFO Created log for partition __consumer_offsets-27 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,914] INFO [Partition __consumer_offsets-27 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,914] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,917] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,917] INFO Created log for partition __consumer_offsets-42 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,917] INFO [Partition __consumer_offsets-42 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,917] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,920] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,921] INFO Created log for partition __consumer_offsets-12 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,921] INFO [Partition __consumer_offsets-12 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,921] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,924] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,925] INFO Created log for partition __consumer_offsets-21 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,925] INFO [Partition __consumer_offsets-21 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,925] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,929] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,929] INFO Created log for partition __consumer_offsets-36 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,929] INFO [Partition __consumer_offsets-36 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,929] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,933] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,934] INFO Created log for partition __consumer_offsets-6 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,934] INFO [Partition __consumer_offsets-6 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,934] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,937] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,938] INFO Created log for partition __consumer_offsets-43 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,938] INFO [Partition __consumer_offsets-43 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,938] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,942] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,942] INFO Created log for partition __consumer_offsets-13 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,942] INFO [Partition __consumer_offsets-13 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,942] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,946] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-41beed6ee22e] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mkafka              |[0m [2024-01-15 09:54:59,947] INFO Created log for partition __consumer_offsets-28 in /kafka/kafka-logs-41beed6ee22e/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[32mkafka              |[0m [2024-01-15 09:54:59,947] INFO [Partition __consumer_offsets-28 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,947] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[32mkafka              |[0m [2024-01-15 09:54:59,949] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,950] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,951] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupCoordinator 1001]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:54:59,952] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,955] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,956] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,957] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 7 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,958] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 7 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:54:59,959] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[32mkafka              |[0m [2024-01-15 09:55:00,635] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member rdkafka-ef9152dc-08bb-40ac-bd66-f2fed62014d6 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:55:00,642] INFO [GroupCoordinator 1001]: Stabilized group web_consumer_group generation 1 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:55:00,647] INFO [GroupCoordinator 1001]: Assignment received from leader for group web_consumer_group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:55:00,792] INFO [GroupCoordinator 1001]: Member[group.instance.id None, member.id rdkafka-ef9152dc-08bb-40ac-bd66-f2fed62014d6] in group web_consumer_group has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:55:00,793] INFO [GroupCoordinator 1001]: Preparing to rebalance group web_consumer_group in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member rdkafka-ef9152dc-08bb-40ac-bd66-f2fed62014d6 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[32mkafka              |[0m [2024-01-15 09:55:00,794] INFO [GroupCoordinator 1001]: Group web_consumer_group with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
